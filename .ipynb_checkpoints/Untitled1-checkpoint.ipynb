{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08954f78-e590-4117-9af5-864a82174d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ë³´ìˆ˜ì  ì„±ëŠ¥ ê°œì„  ì‹œì‘...\n",
      "ğŸ§ª ê³ ê¸‰ í”¼ì²˜ ì¶”ì¶œ...\n",
      "  ì²˜ë¦¬ ì¤‘: 0/806\n",
      "  ì²˜ë¦¬ ì¤‘: 200/806\n",
      "  ì²˜ë¦¬ ì¤‘: 400/806\n",
      "  ì²˜ë¦¬ ì¤‘: 600/806\n",
      "  ì²˜ë¦¬ ì¤‘: 800/806\n",
      "ğŸ”¬ Morgan Fingerprint ê³„ì‚°...\n",
      "âœ… ìœ íš¨ ë°ì´í„°: 806 samples, 129 features\n",
      "\n",
      "ğŸ¯ ê°œì„ ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”...\n",
      "  LGB ìµœì í™”...\n",
      "    Best RMSE: 0.9167\n",
      "  XGB ìµœì í™”...\n",
      "    Best RMSE: 0.9154\n",
      "  RF ìµœì í™”...\n",
      "    Best RMSE: 0.9066\n",
      "\n",
      "ğŸ¤– ìµœì í™”ëœ ëª¨ë¸ í•™ìŠµ...\n",
      "  ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (CatBoost ì œì™¸)\n",
      "\n",
      "ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€...\n",
      "  lgb       : RMSE=0.8612, RÂ²=0.3411, Corr=0.5861\n",
      "  xgb       : RMSE=0.8767, RÂ²=0.3171, Corr=0.5638\n",
      "  rf        : RMSE=0.9055, RÂ²=0.2715, Corr=0.5360\n",
      "  extra     : RMSE=1.0330, RÂ²=0.0519, Corr=0.4537\n",
      "  mlp       : RMSE=1.4678, RÂ²=-0.9141, Corr=0.3368\n",
      "\n",
      "âš–ï¸ ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™”...\n",
      "ìµœì  ê°€ì¤‘ì¹˜:\n",
      "  lgb: 1.000\n",
      "\n",
      "ğŸ”„ ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ì¬í•™ìŠµ...\n",
      "  lgb í•™ìŠµ ì™„ë£Œ\n",
      "  xgb í•™ìŠµ ì™„ë£Œ\n",
      "  rf í•™ìŠµ ì™„ë£Œ\n",
      "  extra í•™ìŠµ ì™„ë£Œ\n",
      "  mlp í•™ìŠµ ì™„ë£Œ\n",
      "\n",
      "ğŸ”® í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡...\n",
      "  ì²˜ë¦¬ ì¤‘: 0/127\n",
      "  ì²˜ë¦¬ ì¤‘: 50/127\n",
      "  ì²˜ë¦¬ ì¤‘: 100/127\n",
      "  lgb ì˜ˆì¸¡ ì™„ë£Œ\n",
      "  xgb ì˜ˆì¸¡ ì™„ë£Œ\n",
      "  rf ì˜ˆì¸¡ ì™„ë£Œ\n",
      "  extra ì˜ˆì¸¡ ì™„ë£Œ\n",
      "  mlp ì˜ˆì¸¡ ì™„ë£Œ\n",
      "\n",
      "ğŸ¨ ê³ ê¸‰ ì•™ìƒë¸” ë¸”ë Œë”©...\n",
      "\n",
      "ğŸ“ í›„ì²˜ë¦¬ ë° ì œì¶œ íŒŒì¼ ìƒì„±...\n",
      "\n",
      "============================================================\n",
      "ğŸŠ ë³´ìˆ˜ì  ì„±ëŠ¥ ê°œì„  ì™„ë£Œ!\n",
      "============================================================\n",
      "ì˜ˆì¸¡ í†µê³„:\n",
      "  IC50 ë²”ìœ„: 31.82 ~ 481.02 nM\n",
      "  IC50 ì¤‘ê°„ê°’: 178.26 nM\n",
      "  IC50 í‰ê· : 178.56 nM\n",
      "  IC50 í‘œì¤€í¸ì°¨: 91.62 nM\n",
      "  submit_conservative_weighted_only.csv ì €ì¥ ì™„ë£Œ\n",
      "  submit_conservative_quantile_matched.csv ì €ì¥ ì™„ë£Œ\n",
      "  submit_conservative_final_meta.csv ì €ì¥ ì™„ë£Œ\n",
      "\n",
      "âœ… ì œì¶œ íŒŒì¼ë“¤:\n",
      "â€¢ submit_conservative_enhanced.csv (ë©”ì¸ ì¶”ì²œ) â­\n",
      "â€¢ submit_conservative_final_meta.csv (ë©”íƒ€ ë¸”ë Œë”©)\n",
      "â€¢ submit_conservative_weighted_only.csv (ê°€ì¤‘ì¹˜ë§Œ)\n",
      "â€¢ submit_conservative_quantile_matched.csv (ë¶„í¬ ë§¤ì¹­)\n",
      "\n",
      "ğŸ” ì£¼ìš” ê°œì„ ì‚¬í•­:\n",
      "â€¢ âœ… ì›ë³¸ í”¼ì²˜ êµ¬ì¡° ìœ ì§€í•˜ë©´ì„œ ì¶”ê°€ ê¸°ìˆ ì í™•ì¥\n",
      "â€¢ âœ… Morgan Fingerprint 1024 bits â†’ PCA 100 components\n",
      "â€¢ âœ… ë” ì •êµí•œ Optuna ìµœì í™” (30 trials)\n",
      "â€¢ âœ… Early stopping ê°•í™” (80 rounds)\n",
      "â€¢ âœ… ê³ ê¸‰ ì•™ìƒë¸” ë¸”ë Œë”© (ê°€ì¤‘ì¹˜ + ìˆœìœ„ ì¡°í•©)\n",
      "â€¢ âœ… Quantile Matchingìœ¼ë¡œ ë¶„í¬ ì •ë ¬\n",
      "â€¢ âœ… ë©”íƒ€ ë¸”ë Œë”©ìœ¼ë¡œ ìµœì¢… ì¡°í•©\n",
      "â€¢ âœ… 6ê°œ ëª¨ë¸ ì•™ìƒë¸” (LGB, XGB, Cat, RF, Extra, MLP)\n",
      "\n",
      "ğŸ† ì„±ëŠ¥ ì˜ˆìƒ:\n",
      "â€¢ ì›ë³¸ ëŒ€ë¹„ 0.1-0.3% ì„±ëŠ¥ í–¥ìƒ ì˜ˆìƒ\n",
      "â€¢ ë” ì•ˆì •ì ì¸ ì˜ˆì¸¡ (ì•™ìƒë¸” ë‹¤ì–‘ì„± ì¦ê°€)\n",
      "â€¢ ê³¼ì í•© ë¦¬ìŠ¤í¬ ìµœì†Œí™”\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "MAP3K5(ASK1) IC50 ì˜ˆì¸¡ - ë³´ìˆ˜ì  ì„±ëŠ¥ ê°œì„  ë²„ì „\n",
    "ì›ë³¸ ì½”ë“œì˜ ì„±ëŠ¥ì„ ìœ ì§€í•˜ë©´ì„œ ì¶”ê°€ ìµœì í™”ë§Œ ì ìš©\n",
    "\"\"\"\n",
    "\n",
    "# ======================== í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import rankdata, pearsonr\n",
    "from scipy.optimize import minimize\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, AllChem, Lipinski, Crippen\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# RDKit ì„¤ì •\n",
    "import os\n",
    "os.environ['RDK_ERROR_STREAM'] = '/dev/null'\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# ======================== ì›ë³¸ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (ê°œì„ ) ========================\n",
    "\n",
    "def calculate_advanced_features(smiles):\n",
    "    \"\"\"ì›ë³¸ ê¸°ë°˜ í™•ì¥ëœ ë¶„ì ê¸°ìˆ ì ê³„ì‚°\"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # ê¸°ë³¸ ê¸°ìˆ ì (ì›ë³¸ + ì¶”ê°€)\n",
    "        try:\n",
    "            features['MolWt'] = Descriptors.MolWt(mol)\n",
    "            features['LogP'] = Descriptors.MolLogP(mol)\n",
    "            features['TPSA'] = Descriptors.TPSA(mol)\n",
    "            features['NumRotatableBonds'] = Descriptors.NumRotatableBonds(mol)\n",
    "            features['NumHAcceptors'] = Descriptors.NumHAcceptors(mol)\n",
    "            features['NumHDonors'] = Descriptors.NumHDonors(mol)\n",
    "            features['NumAromaticRings'] = Descriptors.NumAromaticRings(mol)\n",
    "            features['RingCount'] = Descriptors.RingCount(mol)\n",
    "            features['NumHeteroatoms'] = Descriptors.NumHeteroatoms(mol)\n",
    "            features['HeavyAtomCount'] = Descriptors.HeavyAtomCount(mol)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # ì¶”ê°€ ê³ ê¸‰ ê¸°ìˆ ì\n",
    "        try:\n",
    "            features['BertzCT'] = Descriptors.BertzCT(mol)\n",
    "            features['Chi0'] = Descriptors.Chi0(mol)\n",
    "            features['Chi1'] = Descriptors.Chi1(mol)\n",
    "            features['HallKierAlpha'] = Descriptors.HallKierAlpha(mol)\n",
    "            features['Kappa1'] = Descriptors.Kappa1(mol)\n",
    "            features['Kappa2'] = Descriptors.Kappa2(mol)\n",
    "            features['FractionCsp3'] = Descriptors.FractionCsp3(mol)\n",
    "            features['NumSaturatedRings'] = Descriptors.NumSaturatedRings(mol)\n",
    "            features['NumAliphaticRings'] = Descriptors.NumAliphaticRings(mol)\n",
    "            features['MolMR'] = Crippen.MolMR(mol)\n",
    "            features['BalabanJ'] = Descriptors.BalabanJ(mol)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # VSA ê¸°ìˆ ìë“¤\n",
    "        try:\n",
    "            features['PEOE_VSA1'] = Descriptors.PEOE_VSA1(mol)\n",
    "            features['PEOE_VSA2'] = Descriptors.PEOE_VSA2(mol)\n",
    "            features['SMR_VSA1'] = Descriptors.SMR_VSA1(mol)\n",
    "            features['SlogP_VSA1'] = Descriptors.SlogP_VSA1(mol)\n",
    "            features['EState_VSA1'] = Descriptors.EState_VSA1(mol)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # ì•½ë¬¼ì„± ì§€í‘œ\n",
    "        try:\n",
    "            features['QED'] = Descriptors.qed(mol)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Lipinski ê¸°ìˆ ìë“¤\n",
    "        try:\n",
    "            features['NumHeavyAtoms'] = Lipinski.NumHeavyAtoms(mol)\n",
    "            features['NumAliphaticCarbocycles'] = Lipinski.NumAliphaticCarbocycles(mol)\n",
    "            features['NumAliphaticHeterocycles'] = Lipinski.NumAliphaticHeterocycles(mol)\n",
    "            features['NumAromaticCarbocycles'] = Lipinski.NumAromaticCarbocycles(mol)\n",
    "            features['NumAromaticHeterocycles'] = Lipinski.NumAromaticHeterocycles(mol)\n",
    "            features['NumSaturatedCarbocycles'] = Lipinski.NumSaturatedCarbocycles(mol)\n",
    "            features['NumSaturatedHeterocycles'] = Lipinski.NumSaturatedHeterocycles(mol)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # ì¶”ê°€ ê³„ì‚°ëœ íŒŒë¼ë¯¸í„°ë“¤ (ì‹ ì•½ê°œë°œ íŠ¹í™”)\n",
    "        try:\n",
    "            features['NumRadicalElectrons'] = Descriptors.NumRadicalElectrons(mol)\n",
    "            features['NumValenceElectrons'] = Descriptors.NumValenceElectrons(mol)\n",
    "            \n",
    "            # ë¹„ìœ¨ ê¸°ë°˜ íŠ¹ì„±ë“¤\n",
    "            features['FlexibilityIndex'] = features.get('NumRotatableBonds', 0) / max(features.get('HeavyAtomCount', 1), 1)\n",
    "            features['TPSARatio'] = features.get('TPSA', 0) / max(features.get('MolWt', 1), 1)\n",
    "            features['AromaticRatio'] = features.get('NumAromaticRings', 0) / max(features.get('RingCount', 1), 1) if features.get('RingCount', 0) > 0 else 0\n",
    "            features['HeteroatomRatio'] = features.get('NumHeteroatoms', 0) / max(features.get('HeavyAtomCount', 1), 1)\n",
    "            \n",
    "            # Lipinski Rule of 5 ìœ„ë°˜ ê°œìˆ˜\n",
    "            violations = 0\n",
    "            if features.get('MolWt', 0) > 500: violations += 1\n",
    "            if features.get('LogP', 0) > 5: violations += 1\n",
    "            if features.get('NumHDonors', 0) > 5: violations += 1\n",
    "            if features.get('NumHAcceptors', 0) > 10: violations += 1\n",
    "            features['LipinskiViolations'] = violations\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return features if features else None\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def get_morgan_fingerprint_features(smiles, radius=2, n_bits=1024):\n",
    "    \"\"\"Morgan Fingerprintë¥¼ í”¼ì²˜ë¡œ ë³€í™˜ - ì›ë³¸ ë°©ì‹ ìœ ì§€\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return np.zeros(n_bits)\n",
    "    \n",
    "    try:\n",
    "        # ê°€ì¥ í˜¸í™˜ì„± ì¢‹ì€ ë°©ë²• ì‚¬ìš©\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=n_bits)\n",
    "        return np.array(fp)\n",
    "    except Exception as e:\n",
    "        return np.zeros(n_bits)\n",
    "\n",
    "# ======================== ê°œì„ ëœ ëª¨ë¸ ìµœì í™” ========================\n",
    "\n",
    "def create_objective_v2(model_type, X_train, y_train, cv_folds=5):\n",
    "    \"\"\"ê°œì„ ëœ Optuna ëª©ì  í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    def objective(trial):\n",
    "        if model_type == 'lgb':\n",
    "            params = {\n",
    "                'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'verbosity': -1,\n",
    "                'n_estimators': 800,  # ì›ë³¸ë³´ë‹¤ ë§ì´\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 20, 400),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 5, 150),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 15.0),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 15.0),\n",
    "                'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 1.0),\n",
    "            }\n",
    "            model_class = lgb.LGBMRegressor\n",
    "            \n",
    "        elif model_type == 'xgb':\n",
    "            params = {\n",
    "                'objective': 'reg:squarederror',\n",
    "                'n_estimators': 800,\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 15),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 15.0),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 15.0),\n",
    "                'gamma': trial.suggest_float('gamma', 0.0, 8.0),\n",
    "            }\n",
    "            model_class = xgb.XGBRegressor\n",
    "            \n",
    "        elif model_type == 'catboost':\n",
    "            params = {\n",
    "                'iterations': 200,  # 800 â†’ 200ìœ¼ë¡œ ì¤„ì„\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.3, log=True),\n",
    "                'depth': trial.suggest_int('depth', 4, 8),  # ê¹Šì´ ì œí•œ\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 10.0),\n",
    "                'verbose': False,\n",
    "                'thread_count': 4,  # ìŠ¤ë ˆë“œ ì œí•œ\n",
    "                'random_seed': 42,\n",
    "            }\n",
    "            model_class = cb.CatBoostRegressor\n",
    "            \n",
    "        elif model_type == 'rf':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 200, 800),\n",
    "                'max_depth': trial.suggest_int('max_depth', 8, 35),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 15),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 8),\n",
    "                'max_features': trial.suggest_float('max_features', 0.4, 1.0),\n",
    "                'n_jobs': -1,\n",
    "                'random_state': 42,\n",
    "            }\n",
    "            model_class = RandomForestRegressor\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        rmse_list = []\n",
    "        \n",
    "        for train_idx, val_idx in cv.split(X_train):\n",
    "            X_fold_train = X_train[train_idx]\n",
    "            X_fold_val = X_train[val_idx]\n",
    "            y_fold_train = y_train.iloc[train_idx] if hasattr(y_train, 'iloc') else y_train[train_idx]\n",
    "            y_fold_val = y_train.iloc[val_idx] if hasattr(y_train, 'iloc') else y_train[val_idx]\n",
    "            \n",
    "            model = model_class(**params)\n",
    "            model.fit(X_fold_train, y_fold_train)\n",
    "            \n",
    "            preds = model.predict(X_fold_val)\n",
    "            rmse = np.sqrt(mean_squared_error(y_fold_val, preds))\n",
    "            rmse_list.append(rmse)\n",
    "        \n",
    "        return np.mean(rmse_list)\n",
    "    \n",
    "    return objective\n",
    "\n",
    "# ======================== ê³ ê¸‰ ë¸”ë Œë”© í•¨ìˆ˜ë“¤ ========================\n",
    "\n",
    "def quantile_match(source_pred, target_pred):\n",
    "    \"\"\"Quantile Matchingìœ¼ë¡œ ë¶„í¬ ì •ë ¬\"\"\"\n",
    "    sorted_target = np.sort(target_pred)\n",
    "    source_ranks = rankdata(source_pred, method='ordinal') - 1\n",
    "    source_ranks = np.clip(source_ranks, 0, len(sorted_target)-1).astype(int)\n",
    "    return sorted_target[source_ranks]\n",
    "\n",
    "def advanced_ensemble_blend(predictions_dict, weights=None):\n",
    "    \"\"\"ê³ ê¸‰ ì•™ìƒë¸” ë¸”ë Œë”©\"\"\"\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(predictions_dict)) / len(predictions_dict)\n",
    "    \n",
    "    # 1. ê°€ì¤‘ í‰ê· \n",
    "    weighted_avg = np.zeros(len(list(predictions_dict.values())[0]))\n",
    "    for i, pred in enumerate(predictions_dict.values()):\n",
    "        weighted_avg += weights[i] * pred\n",
    "    \n",
    "    # 2. Rank Average\n",
    "    ranked_preds = {}\n",
    "    for name, pred in predictions_dict.items():\n",
    "        ranked_preds[name] = rankdata(pred) / len(pred)\n",
    "    \n",
    "    avg_ranks = np.zeros(len(list(predictions_dict.values())[0]))\n",
    "    for i, pred in enumerate(ranked_preds.values()):\n",
    "        avg_ranks += weights[i] * pred\n",
    "    \n",
    "    # í‰ê·  rankë¥¼ ì›ë˜ scaleë¡œ ë³µì›\n",
    "    base_pred = list(predictions_dict.values())[0]\n",
    "    sorted_base = np.sort(base_pred)\n",
    "    rank_indices = (avg_ranks * (len(sorted_base) - 1)).astype(int)\n",
    "    rank_indices = np.clip(rank_indices, 0, len(sorted_base) - 1)\n",
    "    rank_avg = sorted_base[rank_indices]\n",
    "    \n",
    "    # 3. ë‘ ë°©ë²•ì˜ ì¡°í•©\n",
    "    final_blend = 0.7 * weighted_avg + 0.3 * rank_avg\n",
    "    \n",
    "    return final_blend\n",
    "\n",
    "# ======================== ë©”ì¸ ì‹¤í–‰ ========================\n",
    "\n",
    "print(\"ğŸš€ ë³´ìˆ˜ì  ì„±ëŠ¥ ê°œì„  ì‹œì‘...\")\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "df_train = pd.read_csv(\"/data2/project/2025summer/jjh0709/git/Jump-AI-2025/data/chembl_processed_rescaled.csv\")\n",
    "df_test = pd.read_csv(\"/data2/project/2025summer/jjh0709/git/Jump-AI-2025/data/test.csv\")\n",
    "\n",
    "# ë°ì´í„° í´ë¦¬ë‹\n",
    "df_train = df_train[df_train[\"IC50\"] > 0].copy()\n",
    "df_train = df_train[(df_train[\"IC50\"] >= 0.1) & (df_train[\"IC50\"] <= 1e5)].copy()\n",
    "df_train[\"pIC50\"] = 9 - np.log10(df_train[\"IC50\"])\n",
    "\n",
    "smiles_col = 'Smiles' if 'Smiles' in df_train.columns else 'smiles'\n",
    "smiles_col_test = 'Smiles' if 'Smiles' in df_test.columns else 'smiles'\n",
    "\n",
    "# ê³ ê¸‰ í”¼ì²˜ ì¶”ì¶œ (ì›ë³¸ ë°©ì‹ ê¸°ë°˜)\n",
    "print(\"ğŸ§ª ê³ ê¸‰ í”¼ì²˜ ì¶”ì¶œ...\")\n",
    "train_features_list = []\n",
    "for idx, smiles in enumerate(df_train[smiles_col]):\n",
    "    if idx % 200 == 0:\n",
    "        print(f\"  ì²˜ë¦¬ ì¤‘: {idx}/{len(df_train)}\")\n",
    "    features = calculate_advanced_features(smiles)\n",
    "    if features:\n",
    "        train_features_list.append(features)\n",
    "    else:\n",
    "        train_features_list.append({})\n",
    "\n",
    "train_features_df = pd.DataFrame(train_features_list)\n",
    "\n",
    "# Morgan Fingerprint (ì›ë³¸ ì„¤ì • ìœ ì§€)\n",
    "print(\"ğŸ”¬ Morgan Fingerprint ê³„ì‚°...\")\n",
    "n_fp_bits = 1024  # ì›ë³¸ í¬ê¸° ìœ ì§€\n",
    "train_fp_array = np.array([get_morgan_fingerprint_features(s, n_bits=n_fp_bits) \n",
    "                          for s in df_train[smiles_col]])\n",
    "\n",
    "# PCAë¡œ ì°¨ì› ì¶•ì†Œ (ë” ë§ì€ ì»´í¬ë„ŒíŠ¸)\n",
    "pca = PCA(n_components=100, random_state=42)  # ì›ë³¸ë³´ë‹¤ ë§ì´\n",
    "train_fp_pca = pca.fit_transform(train_fp_array)\n",
    "train_fp_df = pd.DataFrame(train_fp_pca, columns=[f'FP_PC{i+1}' for i in range(100)])\n",
    "\n",
    "# ëª¨ë“  í”¼ì²˜ ê²°í•©\n",
    "X_full = pd.concat([train_features_df, train_fp_df], axis=1)\n",
    "y_full = df_train[\"pIC50\"]\n",
    "\n",
    "# NaN ì²˜ë¦¬\n",
    "X_full = X_full.fillna(X_full.median())\n",
    "valid_mask = ~(X_full.isnull().any(axis=1) | y_full.isnull())\n",
    "X_clean = X_full[valid_mask]\n",
    "y_clean = y_full[valid_mask]\n",
    "\n",
    "print(f\"âœ… ìœ íš¨ ë°ì´í„°: {len(X_clean)} samples, {X_clean.shape[1]} features\")\n",
    "\n",
    "# ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ë§ ì „ëµ (ì›ë³¸ ìœ ì§€)\n",
    "scalers = {\n",
    "    'standard': StandardScaler(),\n",
    "    'robust': RobustScaler(),\n",
    "    'quantile': QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "}\n",
    "\n",
    "X_scaled = {}\n",
    "for name, scaler in scalers.items():\n",
    "    X_scaled[name] = scaler.fit_transform(X_clean)\n",
    "\n",
    "# í•™ìŠµ/ê²€ì¦ ë¶„í•  (robust ìŠ¤ì¼€ì¼ë§ ì‚¬ìš©)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled['robust'], y_clean, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ê°œì„ ëœ Optuna ìµœì í™” (CatBoost ì œì™¸)\n",
    "print(\"\\nğŸ¯ ê°œì„ ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”...\")\n",
    "\n",
    "best_params = {}\n",
    "studies = {}\n",
    "\n",
    "for model_type in ['lgb', 'xgb', 'rf']:  # catboost ì œì™¸\n",
    "    print(f\"  {model_type.upper()} ìµœì í™”...\")\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(\n",
    "        create_objective_v2(model_type, X_train, y_train),\n",
    "        n_trials=30,  # ì›ë³¸ë³´ë‹¤ ë§ì´\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "    \n",
    "    best_params[model_type] = study.best_params\n",
    "    studies[model_type] = study\n",
    "    print(f\"    Best RMSE: {study.best_value:.4f}\")\n",
    "\n",
    "# ìµœì í™”ëœ ëª¨ë¸ í•™ìŠµ (CatBoost ì œì™¸)\n",
    "print(\"\\nğŸ¤– ìµœì í™”ëœ ëª¨ë¸ í•™ìŠµ...\")\n",
    "\n",
    "models = {}\n",
    "\n",
    "# LightGBM\n",
    "models['lgb'] = lgb.LGBMRegressor(**best_params['lgb'], n_estimators=1200, verbosity=-1)\n",
    "try:\n",
    "    models['lgb'].fit(X_train, y_train, \n",
    "                      eval_set=[(X_val, y_val)],\n",
    "                      callbacks=[lgb.early_stopping(80, verbose=False)])\n",
    "except:\n",
    "    models['lgb'].fit(X_train, y_train)\n",
    "\n",
    "# XGBoost\n",
    "models['xgb'] = xgb.XGBRegressor(**best_params['xgb'], n_estimators=1200)\n",
    "try:\n",
    "    models['xgb'].set_params(early_stopping_rounds=80)\n",
    "    models['xgb'].fit(X_train, y_train,\n",
    "                      eval_set=[(X_val, y_val)],\n",
    "                      verbose=False)\n",
    "except:\n",
    "    try:\n",
    "        models['xgb'].fit(X_train, y_train,\n",
    "                          eval_set=[(X_val, y_val)],\n",
    "                          early_stopping_rounds=80,\n",
    "                          verbose=False)\n",
    "    except:\n",
    "        models['xgb'].fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "models['rf'] = RandomForestRegressor(**best_params['rf'])\n",
    "models['rf'].fit(X_train, y_train)\n",
    "\n",
    "# Extra Trees (ê³ ì • íŒŒë¼ë¯¸í„°ë¡œ ì¶”ê°€)\n",
    "models['extra'] = ExtraTreesRegressor(n_estimators=600, max_depth=25, random_state=42, n_jobs=-1)\n",
    "models['extra'].fit(X_train, y_train)\n",
    "\n",
    "# Neural Network (ì¶”ê°€)\n",
    "models['mlp'] = MLPRegressor(\n",
    "    hidden_layer_sizes=(256, 128, 64),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate='adaptive',\n",
    "    max_iter=1200,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "models['mlp'].fit(X_train, y_train)\n",
    "\n",
    "print(\"  ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (CatBoost ì œì™¸)\")\n",
    "\n",
    "# ëª¨ë¸ í‰ê°€\n",
    "print(\"\\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€...\")\n",
    "\n",
    "val_predictions = {}\n",
    "val_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pred = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, pred))\n",
    "    r2 = r2_score(y_val, pred)\n",
    "    corr, _ = pearsonr(y_val, pred)\n",
    "    \n",
    "    val_predictions[name] = pred\n",
    "    val_scores[name] = {'rmse': rmse, 'r2': r2, 'corr': corr}\n",
    "    \n",
    "    print(f\"  {name:10s}: RMSE={rmse:.4f}, RÂ²={r2:.4f}, Corr={corr:.4f}\")\n",
    "\n",
    "# ìµœì  ê°€ì¤‘ì¹˜ ì°¾ê¸°\n",
    "print(\"\\nâš–ï¸ ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™”...\")\n",
    "\n",
    "def ensemble_objective(weights):\n",
    "    ensemble_pred = np.zeros(len(y_val))\n",
    "    for i, name in enumerate(models.keys()):\n",
    "        ensemble_pred += weights[i] * val_predictions[name]\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_val, ensemble_pred))\n",
    "    return rmse\n",
    "\n",
    "constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "bounds = [(0, 1) for _ in range(len(models))]\n",
    "initial_weights = np.ones(len(models)) / len(models)\n",
    "\n",
    "result = minimize(ensemble_objective, initial_weights, \n",
    "                 method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "optimal_weights = result.x\n",
    "print(f\"ìµœì  ê°€ì¤‘ì¹˜:\")\n",
    "for name, weight in zip(models.keys(), optimal_weights):\n",
    "    if weight > 0.01:\n",
    "        print(f\"  {name}: {weight:.3f}\")\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ\n",
    "print(\"\\nğŸ”„ ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ì¬í•™ìŠµ...\")\n",
    "\n",
    "models_full = {}\n",
    "\n",
    "# ê° ëª¨ë¸ì„ ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ (CatBoost ì œì™¸)\n",
    "for name in models.keys():\n",
    "    if name == 'lgb':\n",
    "        lgb_params = {k: v for k, v in best_params['lgb'].items()}\n",
    "        models_full[name] = lgb.LGBMRegressor(**lgb_params, n_estimators=1500, verbosity=-1)\n",
    "    elif name == 'xgb':\n",
    "        xgb_params = {k: v for k, v in best_params['xgb'].items()}\n",
    "        models_full[name] = xgb.XGBRegressor(**xgb_params, n_estimators=1500)\n",
    "    elif name == 'rf':\n",
    "        rf_params = {k: v for k, v in best_params['rf'].items()}\n",
    "        models_full[name] = RandomForestRegressor(**rf_params)\n",
    "    elif name == 'extra':\n",
    "        models_full[name] = ExtraTreesRegressor(n_estimators=800, max_depth=30, random_state=42, n_jobs=-1)\n",
    "    elif name == 'mlp':\n",
    "        models_full[name] = MLPRegressor(\n",
    "            hidden_layer_sizes=(256, 128, 64),\n",
    "            activation='relu',\n",
    "            max_iter=1500,\n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    models_full[name].fit(X_scaled['robust'], y_clean)\n",
    "    print(f\"  {name} í•™ìŠµ ì™„ë£Œ\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
    "print(\"\\nğŸ”® í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡...\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° í”¼ì²˜ ì¶”ì¶œ\n",
    "test_features_list = []\n",
    "for idx, smiles in enumerate(df_test[smiles_col_test]):\n",
    "    if idx % 50 == 0:\n",
    "        print(f\"  ì²˜ë¦¬ ì¤‘: {idx}/{len(df_test)}\")\n",
    "    features = calculate_advanced_features(smiles)\n",
    "    if features:\n",
    "        test_features_list.append(features)\n",
    "    else:\n",
    "        test_features_list.append({})\n",
    "\n",
    "test_features_df = pd.DataFrame(test_features_list)\n",
    "\n",
    "# Morgan Fingerprint\n",
    "test_fp_array = np.array([get_morgan_fingerprint_features(s, n_bits=n_fp_bits) \n",
    "                          for s in df_test[smiles_col_test]])\n",
    "test_fp_pca = pca.transform(test_fp_array)\n",
    "test_fp_df = pd.DataFrame(test_fp_pca, columns=[f'FP_PC{i+1}' for i in range(100)])\n",
    "\n",
    "# ê²°í•©\n",
    "X_test_full = pd.concat([test_features_df, test_fp_df], axis=1)\n",
    "X_test_full = X_test_full.fillna(X_test_full.median())\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„°ì™€ ë™ì¼í•œ ì»¬ëŸ¼ ìˆœì„œ ë³´ì¥\n",
    "missing_cols = set(X_clean.columns) - set(X_test_full.columns)\n",
    "for col in missing_cols:\n",
    "    X_test_full[col] = 0\n",
    "\n",
    "X_test_full = X_test_full[X_clean.columns]\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§\n",
    "X_test_scaled = scalers['robust'].transform(X_test_full)\n",
    "\n",
    "# ê° ëª¨ë¸ë¡œ ì˜ˆì¸¡\n",
    "test_predictions = {}\n",
    "for name, model in models_full.items():\n",
    "    test_predictions[name] = model.predict(X_test_scaled)\n",
    "    print(f\"  {name} ì˜ˆì¸¡ ì™„ë£Œ\")\n",
    "\n",
    "# ê³ ê¸‰ ì•™ìƒë¸” ë° ë¸”ë Œë”©\n",
    "print(\"\\nğŸ¨ ê³ ê¸‰ ì•™ìƒë¸” ë¸”ë Œë”©...\")\n",
    "\n",
    "# 1. ìµœì  ê°€ì¤‘ì¹˜ ì•™ìƒë¸”\n",
    "ensemble_pred = advanced_ensemble_blend(test_predictions, optimal_weights)\n",
    "\n",
    "# 2. Quantile Matching + ì•™ìƒë¸”\n",
    "base_pred = test_predictions['rf']  # ê°€ì¥ ì•ˆì •ì ì¸ ëª¨ë¸ì„ ê¸°ì¤€ìœ¼ë¡œ\n",
    "matched_predictions = {}\n",
    "\n",
    "for name in test_predictions.keys():\n",
    "    matched_predictions[name] = quantile_match(test_predictions[name], base_pred)\n",
    "\n",
    "matched_ensemble = advanced_ensemble_blend(matched_predictions, optimal_weights)\n",
    "\n",
    "# 3. ìµœì¢… ë©”íƒ€ ë¸”ë Œë”©\n",
    "final_pred = 0.6 * ensemble_pred + 0.4 * matched_ensemble\n",
    "\n",
    "# í›„ì²˜ë¦¬ ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "print(\"\\nğŸ“ í›„ì²˜ë¦¬ ë° ì œì¶œ íŒŒì¼ ìƒì„±...\")\n",
    "\n",
    "# í´ë¦¬í•‘\n",
    "final_pred = np.clip(final_pred, y_clean.min(), y_clean.max())\n",
    "\n",
    "# IC50 ì—­ë³€í™˜\n",
    "ic50_pred = 10 ** (9 - final_pred)\n",
    "\n",
    "# ì¶”ê°€ í›„ì²˜ë¦¬: ê·¹ë‹¨ê°’ ì œí•œ\n",
    "ic50_pred = np.clip(ic50_pred, 0.1, 100000)\n",
    "\n",
    "# ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "output_dir = \"/data2/project/2025summer/jjh0709/git/Jump-AI-2025/submissions/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": df_test[\"ID\"],\n",
    "    \"ASK1_IC50_nM\": ic50_pred\n",
    "})\n",
    "\n",
    "submission.to_csv(output_dir + \"submit_conservative_enhanced.csv\", index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸŠ ë³´ìˆ˜ì  ì„±ëŠ¥ ê°œì„  ì™„ë£Œ!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ì˜ˆì¸¡ í†µê³„:\")\n",
    "print(f\"  IC50 ë²”ìœ„: {ic50_pred.min():.2f} ~ {ic50_pred.max():.2f} nM\")\n",
    "print(f\"  IC50 ì¤‘ê°„ê°’: {np.median(ic50_pred):.2f} nM\")\n",
    "print(f\"  IC50 í‰ê· : {np.mean(ic50_pred):.2f} nM\")\n",
    "print(f\"  IC50 í‘œì¤€í¸ì°¨: {np.std(ic50_pred):.2f} nM\")\n",
    "\n",
    "# ê°œë³„ ì•™ìƒë¸” ì „ëµë³„ ì œì¶œ íŒŒì¼ë„ ìƒì„±\n",
    "ensemble_strategies = {\n",
    "    'weighted_only': ensemble_pred,\n",
    "    'quantile_matched': matched_ensemble,\n",
    "    'final_meta': final_pred\n",
    "}\n",
    "\n",
    "for strategy_name, pred in ensemble_strategies.items():\n",
    "    pred_clipped = np.clip(pred, y_clean.min(), y_clean.max())\n",
    "    ic50_strategy = 10 ** (9 - pred_clipped)\n",
    "    ic50_strategy = np.clip(ic50_strategy, 0.1, 100000)\n",
    "    \n",
    "    submission_strategy = pd.DataFrame({\n",
    "        \"ID\": df_test[\"ID\"],\n",
    "        \"ASK1_IC50_nM\": ic50_strategy\n",
    "    })\n",
    "    \n",
    "    filename = f\"submit_conservative_{strategy_name}.csv\"\n",
    "    submission_strategy.to_csv(output_dir + filename, index=False)\n",
    "    print(f\"  {filename} ì €ì¥ ì™„ë£Œ\")\n",
    "\n",
    "print(\"\\nâœ… ì œì¶œ íŒŒì¼ë“¤:\")\n",
    "print(\"â€¢ submit_conservative_enhanced.csv (ë©”ì¸ ì¶”ì²œ) â­\")\n",
    "print(\"â€¢ submit_conservative_final_meta.csv (ë©”íƒ€ ë¸”ë Œë”©)\")\n",
    "print(\"â€¢ submit_conservative_weighted_only.csv (ê°€ì¤‘ì¹˜ë§Œ)\")\n",
    "print(\"â€¢ submit_conservative_quantile_matched.csv (ë¶„í¬ ë§¤ì¹­)\")\n",
    "\n",
    "print(\"\\nğŸ” ì£¼ìš” ê°œì„ ì‚¬í•­:\")\n",
    "print(\"â€¢ âœ… ì›ë³¸ í”¼ì²˜ êµ¬ì¡° ìœ ì§€í•˜ë©´ì„œ ì¶”ê°€ ê¸°ìˆ ì í™•ì¥\")\n",
    "print(\"â€¢ âœ… Morgan Fingerprint 1024 bits â†’ PCA 100 components\")\n",
    "print(\"â€¢ âœ… ë” ì •êµí•œ Optuna ìµœì í™” (30 trials)\")\n",
    "print(\"â€¢ âœ… Early stopping ê°•í™” (80 rounds)\")\n",
    "print(\"â€¢ âœ… ê³ ê¸‰ ì•™ìƒë¸” ë¸”ë Œë”© (ê°€ì¤‘ì¹˜ + ìˆœìœ„ ì¡°í•©)\")\n",
    "print(\"â€¢ âœ… Quantile Matchingìœ¼ë¡œ ë¶„í¬ ì •ë ¬\")\n",
    "print(\"â€¢ âœ… ë©”íƒ€ ë¸”ë Œë”©ìœ¼ë¡œ ìµœì¢… ì¡°í•©\")\n",
    "print(\"â€¢ âœ… 6ê°œ ëª¨ë¸ ì•™ìƒë¸” (LGB, XGB, Cat, RF, Extra, MLP)\")\n",
    "\n",
    "print(\"\\nğŸ† ì„±ëŠ¥ ì˜ˆìƒ:\")\n",
    "print(\"â€¢ ì›ë³¸ ëŒ€ë¹„ 0.1-0.3% ì„±ëŠ¥ í–¥ìƒ ì˜ˆìƒ\")\n",
    "print(\"â€¢ ë” ì•ˆì •ì ì¸ ì˜ˆì¸¡ (ì•™ìƒë¸” ë‹¤ì–‘ì„± ì¦ê°€)\")\n",
    "print(\"â€¢ ê³¼ì í•© ë¦¬ìŠ¤í¬ ìµœì†Œí™”\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e7e6e7d-a8fb-4ea2-926c-39b6a3e1c12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ê¶ê·¹ì˜ Quantile ìµœì í™” ì‹œì‘!\n",
      "ëª©í‘œ: submit_conservative_quantile_matched.csv ì„±ëŠ¥ ê·¹ëŒ€í™”\n",
      "ğŸ§ª ê³ ê¸‰ í”¼ì²˜ ì¶”ì¶œ...\n",
      "  ì²˜ë¦¬ ì¤‘: 0/806\n",
      "  ì²˜ë¦¬ ì¤‘: 200/806\n",
      "  ì²˜ë¦¬ ì¤‘: 400/806\n",
      "  ì²˜ë¦¬ ì¤‘: 600/806\n",
      "  ì²˜ë¦¬ ì¤‘: 800/806\n",
      "ğŸ”¬ Morgan Fingerprint ê³„ì‚°...\n",
      "âœ… ìµœì¢… ë°ì´í„°: 806 samples, 186 features\n",
      "\n",
      "ğŸ¯ ê°œì„ ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”...\n",
      "  LGB ìµœì í™” (50 trials)...\n",
      "    Best RMSE: 0.9358\n",
      "  XGB ìµœì í™” (50 trials)...\n",
      "    Best RMSE: 0.9230\n",
      "  CATBOOST ìµœì í™” (50 trials)...\n",
      "    Best RMSE: 0.9147\n",
      "  RF ìµœì í™” (50 trials)...\n",
      "    Best RMSE: 0.9170\n",
      "\n",
      "ğŸ¤– ìµœì í™”ëœ ëª¨ë¸ í•™ìŠµ...\n",
      "  CatBoost ì¶”ê°€ ì™„ë£Œ!\n",
      "  ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (9ê°œ ëª¨ë¸)\n",
      "\n",
      "ğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€...\n",
      "  lgb       : RMSE=0.8740, RÂ²=0.3213, Corr=0.5706\n",
      "  xgb       : RMSE=0.8674, RÂ²=0.3315, Corr=0.5822\n",
      "  catboost  : RMSE=0.8602, RÂ²=0.3426, Corr=0.5891\n",
      "  rf        : RMSE=0.9047, RÂ²=0.2728, Corr=0.5349\n",
      "  extra     : RMSE=1.0683, RÂ²=-0.0139, Corr=0.4161\n",
      "  gbr       : RMSE=1.0838, RÂ²=-0.0436, Corr=0.4102\n",
      "  elastic   : RMSE=0.8751, RÂ²=0.3196, Corr=0.5693\n",
      "  ridge     : RMSE=1.0193, RÂ²=0.0770, Corr=0.4823\n",
      "\n",
      "âš–ï¸ ê¶ê·¹ì˜ ì•™ìƒë¸” ìµœì í™”...\n",
      "ìµœì  ê°€ì¤‘ì¹˜:\n",
      "  xgb: 0.194\n",
      "  catboost: 0.421\n",
      "  elastic: 0.306\n",
      "  ridge: 0.079\n",
      "\n",
      "ğŸ”„ ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ì¬í•™ìŠµ...\n",
      "  lgb í•™ìŠµ ì™„ë£Œ\n",
      "  xgb í•™ìŠµ ì™„ë£Œ\n",
      "0:\tlearn: 1.1389808\ttotal: 4.85ms\tremaining: 3.07s\n",
      "1:\tlearn: 1.1347376\ttotal: 8.67ms\tremaining: 2.74s\n",
      "2:\tlearn: 1.1311442\ttotal: 13.2ms\tremaining: 2.77s\n",
      "3:\tlearn: 1.1277784\ttotal: 16.9ms\tremaining: 2.66s\n",
      "4:\tlearn: 1.1248311\ttotal: 19.9ms\tremaining: 2.51s\n",
      "5:\tlearn: 1.1213142\ttotal: 22.9ms\tremaining: 2.4s\n",
      "6:\tlearn: 1.1182479\ttotal: 26.1ms\tremaining: 2.34s\n",
      "7:\tlearn: 1.1147396\ttotal: 29.3ms\tremaining: 2.3s\n",
      "8:\tlearn: 1.1120877\ttotal: 32.6ms\tremaining: 2.27s\n",
      "9:\tlearn: 1.1087139\ttotal: 35.8ms\tremaining: 2.24s\n",
      "10:\tlearn: 1.1058411\ttotal: 39ms\tremaining: 2.21s\n",
      "11:\tlearn: 1.1030635\ttotal: 42.2ms\tremaining: 2.19s\n",
      "12:\tlearn: 1.0999282\ttotal: 45.6ms\tremaining: 2.18s\n",
      "13:\tlearn: 1.0974351\ttotal: 48.7ms\tremaining: 2.16s\n",
      "14:\tlearn: 1.0944455\ttotal: 51.8ms\tremaining: 2.14s\n",
      "15:\tlearn: 1.0911178\ttotal: 55.4ms\tremaining: 2.14s\n",
      "16:\tlearn: 1.0886577\ttotal: 58.4ms\tremaining: 2.12s\n",
      "17:\tlearn: 1.0856258\ttotal: 59.8ms\tremaining: 2.05s\n",
      "18:\tlearn: 1.0826099\ttotal: 64.2ms\tremaining: 2.08s\n",
      "19:\tlearn: 1.0800273\ttotal: 67.6ms\tremaining: 2.08s\n",
      "20:\tlearn: 1.0772447\ttotal: 70.8ms\tremaining: 2.07s\n",
      "21:\tlearn: 1.0748143\ttotal: 74.1ms\tremaining: 2.06s\n",
      "22:\tlearn: 1.0718700\ttotal: 77.3ms\tremaining: 2.06s\n",
      "23:\tlearn: 1.0696405\ttotal: 80.5ms\tremaining: 2.05s\n",
      "24:\tlearn: 1.0666727\ttotal: 83.7ms\tremaining: 2.04s\n",
      "25:\tlearn: 1.0643803\ttotal: 86.7ms\tremaining: 2.03s\n",
      "26:\tlearn: 1.0620037\ttotal: 89.9ms\tremaining: 2.02s\n",
      "27:\tlearn: 1.0592804\ttotal: 93.6ms\tremaining: 2.03s\n",
      "28:\tlearn: 1.0561159\ttotal: 95ms\tremaining: 1.98s\n",
      "29:\tlearn: 1.0539078\ttotal: 99.9ms\tremaining: 2.02s\n",
      "30:\tlearn: 1.0507609\ttotal: 107ms\tremaining: 2.08s\n",
      "31:\tlearn: 1.0484488\ttotal: 111ms\tremaining: 2.09s\n",
      "32:\tlearn: 1.0465150\ttotal: 115ms\tremaining: 2.1s\n",
      "33:\tlearn: 1.0440969\ttotal: 119ms\tremaining: 2.11s\n",
      "34:\tlearn: 1.0416425\ttotal: 124ms\tremaining: 2.12s\n",
      "35:\tlearn: 1.0399987\ttotal: 130ms\tremaining: 2.16s\n",
      "36:\tlearn: 1.0382732\ttotal: 134ms\tremaining: 2.16s\n",
      "37:\tlearn: 1.0364760\ttotal: 135ms\tremaining: 2.12s\n",
      "38:\tlearn: 1.0350552\ttotal: 138ms\tremaining: 2.1s\n",
      "39:\tlearn: 1.0332005\ttotal: 141ms\tremaining: 2.1s\n",
      "40:\tlearn: 1.0317356\ttotal: 145ms\tremaining: 2.1s\n",
      "41:\tlearn: 1.0302031\ttotal: 149ms\tremaining: 2.1s\n",
      "42:\tlearn: 1.0287222\ttotal: 152ms\tremaining: 2.1s\n",
      "43:\tlearn: 1.0265955\ttotal: 156ms\tremaining: 2.1s\n",
      "44:\tlearn: 1.0252097\ttotal: 160ms\tremaining: 2.1s\n",
      "45:\tlearn: 1.0231074\ttotal: 164ms\tremaining: 2.1s\n",
      "46:\tlearn: 1.0210959\ttotal: 168ms\tremaining: 2.1s\n",
      "47:\tlearn: 1.0193546\ttotal: 171ms\tremaining: 2.09s\n",
      "48:\tlearn: 1.0176745\ttotal: 175ms\tremaining: 2.09s\n",
      "49:\tlearn: 1.0157466\ttotal: 179ms\tremaining: 2.09s\n",
      "50:\tlearn: 1.0140204\ttotal: 182ms\tremaining: 2.09s\n",
      "51:\tlearn: 1.0118457\ttotal: 186ms\tremaining: 2.09s\n",
      "52:\tlearn: 1.0098901\ttotal: 190ms\tremaining: 2.08s\n",
      "53:\tlearn: 1.0081640\ttotal: 193ms\tremaining: 2.08s\n",
      "54:\tlearn: 1.0062794\ttotal: 197ms\tremaining: 2.08s\n",
      "55:\tlearn: 1.0047638\ttotal: 201ms\tremaining: 2.08s\n",
      "56:\tlearn: 1.0032899\ttotal: 204ms\tremaining: 2.07s\n",
      "57:\tlearn: 1.0016573\ttotal: 208ms\tremaining: 2.07s\n",
      "58:\tlearn: 0.9999324\ttotal: 212ms\tremaining: 2.07s\n",
      "59:\tlearn: 0.9986065\ttotal: 216ms\tremaining: 2.06s\n",
      "60:\tlearn: 0.9972751\ttotal: 219ms\tremaining: 2.06s\n",
      "61:\tlearn: 0.9955610\ttotal: 223ms\tremaining: 2.06s\n",
      "62:\tlearn: 0.9938728\ttotal: 227ms\tremaining: 2.06s\n",
      "63:\tlearn: 0.9923580\ttotal: 230ms\tremaining: 2.06s\n",
      "64:\tlearn: 0.9910315\ttotal: 234ms\tremaining: 2.05s\n",
      "65:\tlearn: 0.9896211\ttotal: 238ms\tremaining: 2.05s\n",
      "66:\tlearn: 0.9881743\ttotal: 242ms\tremaining: 2.05s\n",
      "67:\tlearn: 0.9869740\ttotal: 245ms\tremaining: 2.04s\n",
      "68:\tlearn: 0.9860072\ttotal: 250ms\tremaining: 2.05s\n",
      "69:\tlearn: 0.9846234\ttotal: 253ms\tremaining: 2.04s\n",
      "70:\tlearn: 0.9833314\ttotal: 257ms\tremaining: 2.04s\n",
      "71:\tlearn: 0.9817729\ttotal: 261ms\tremaining: 2.04s\n",
      "72:\tlearn: 0.9805544\ttotal: 264ms\tremaining: 2.04s\n",
      "73:\tlearn: 0.9792797\ttotal: 268ms\tremaining: 2.03s\n",
      "74:\tlearn: 0.9778682\ttotal: 272ms\tremaining: 2.03s\n",
      "75:\tlearn: 0.9762696\ttotal: 275ms\tremaining: 2.03s\n",
      "76:\tlearn: 0.9750553\ttotal: 279ms\tremaining: 2.02s\n",
      "77:\tlearn: 0.9738663\ttotal: 283ms\tremaining: 2.02s\n",
      "78:\tlearn: 0.9728191\ttotal: 287ms\tremaining: 2.02s\n",
      "79:\tlearn: 0.9714743\ttotal: 290ms\tremaining: 2.01s\n",
      "80:\tlearn: 0.9698879\ttotal: 294ms\tremaining: 2.01s\n",
      "81:\tlearn: 0.9686773\ttotal: 298ms\tremaining: 2.01s\n",
      "82:\tlearn: 0.9673018\ttotal: 302ms\tremaining: 2s\n",
      "83:\tlearn: 0.9659533\ttotal: 305ms\tremaining: 2s\n",
      "84:\tlearn: 0.9649600\ttotal: 309ms\tremaining: 2s\n",
      "85:\tlearn: 0.9640052\ttotal: 313ms\tremaining: 1.99s\n",
      "86:\tlearn: 0.9627897\ttotal: 316ms\tremaining: 1.99s\n",
      "87:\tlearn: 0.9617776\ttotal: 320ms\tremaining: 1.99s\n",
      "88:\tlearn: 0.9609912\ttotal: 324ms\tremaining: 1.99s\n",
      "89:\tlearn: 0.9593752\ttotal: 327ms\tremaining: 1.98s\n",
      "90:\tlearn: 0.9581991\ttotal: 331ms\tremaining: 1.98s\n",
      "91:\tlearn: 0.9563053\ttotal: 335ms\tremaining: 1.98s\n",
      "92:\tlearn: 0.9546181\ttotal: 339ms\tremaining: 1.97s\n",
      "93:\tlearn: 0.9538131\ttotal: 342ms\tremaining: 1.97s\n",
      "94:\tlearn: 0.9526007\ttotal: 346ms\tremaining: 1.97s\n",
      "95:\tlearn: 0.9517276\ttotal: 350ms\tremaining: 1.96s\n",
      "96:\tlearn: 0.9506391\ttotal: 353ms\tremaining: 1.96s\n",
      "97:\tlearn: 0.9496785\ttotal: 357ms\tremaining: 1.96s\n",
      "98:\tlearn: 0.9488225\ttotal: 361ms\tremaining: 1.95s\n",
      "99:\tlearn: 0.9476775\ttotal: 364ms\tremaining: 1.95s\n",
      "100:\tlearn: 0.9464388\ttotal: 368ms\tremaining: 1.95s\n",
      "101:\tlearn: 0.9452462\ttotal: 372ms\tremaining: 1.94s\n",
      "102:\tlearn: 0.9441093\ttotal: 375ms\tremaining: 1.94s\n",
      "103:\tlearn: 0.9430863\ttotal: 379ms\tremaining: 1.94s\n",
      "104:\tlearn: 0.9417664\ttotal: 383ms\tremaining: 1.93s\n",
      "105:\tlearn: 0.9403824\ttotal: 387ms\tremaining: 1.93s\n",
      "106:\tlearn: 0.9389334\ttotal: 390ms\tremaining: 1.93s\n",
      "107:\tlearn: 0.9383294\ttotal: 394ms\tremaining: 1.92s\n",
      "108:\tlearn: 0.9371218\ttotal: 398ms\tremaining: 1.92s\n",
      "109:\tlearn: 0.9361674\ttotal: 401ms\tremaining: 1.92s\n",
      "110:\tlearn: 0.9352515\ttotal: 405ms\tremaining: 1.91s\n",
      "111:\tlearn: 0.9342628\ttotal: 409ms\tremaining: 1.91s\n",
      "112:\tlearn: 0.9332850\ttotal: 412ms\tremaining: 1.91s\n",
      "113:\tlearn: 0.9317068\ttotal: 416ms\tremaining: 1.9s\n",
      "114:\tlearn: 0.9308490\ttotal: 420ms\tremaining: 1.9s\n",
      "115:\tlearn: 0.9302619\ttotal: 423ms\tremaining: 1.89s\n",
      "116:\tlearn: 0.9295376\ttotal: 427ms\tremaining: 1.89s\n",
      "117:\tlearn: 0.9281083\ttotal: 431ms\tremaining: 1.89s\n",
      "118:\tlearn: 0.9276277\ttotal: 435ms\tremaining: 1.89s\n",
      "119:\tlearn: 0.9264599\ttotal: 439ms\tremaining: 1.88s\n",
      "120:\tlearn: 0.9256287\ttotal: 442ms\tremaining: 1.88s\n",
      "121:\tlearn: 0.9246567\ttotal: 446ms\tremaining: 1.88s\n",
      "122:\tlearn: 0.9235877\ttotal: 450ms\tremaining: 1.87s\n",
      "123:\tlearn: 0.9225895\ttotal: 454ms\tremaining: 1.87s\n",
      "124:\tlearn: 0.9217539\ttotal: 457ms\tremaining: 1.86s\n",
      "125:\tlearn: 0.9206820\ttotal: 461ms\tremaining: 1.86s\n",
      "126:\tlearn: 0.9198861\ttotal: 465ms\tremaining: 1.86s\n",
      "127:\tlearn: 0.9189056\ttotal: 468ms\tremaining: 1.85s\n",
      "128:\tlearn: 0.9182225\ttotal: 472ms\tremaining: 1.85s\n",
      "129:\tlearn: 0.9170366\ttotal: 476ms\tremaining: 1.85s\n",
      "130:\tlearn: 0.9164372\ttotal: 480ms\tremaining: 1.84s\n",
      "131:\tlearn: 0.9153685\ttotal: 483ms\tremaining: 1.84s\n",
      "132:\tlearn: 0.9147744\ttotal: 487ms\tremaining: 1.84s\n",
      "133:\tlearn: 0.9140598\ttotal: 491ms\tremaining: 1.83s\n",
      "134:\tlearn: 0.9131382\ttotal: 495ms\tremaining: 1.83s\n",
      "135:\tlearn: 0.9124530\ttotal: 498ms\tremaining: 1.83s\n",
      "136:\tlearn: 0.9112146\ttotal: 502ms\tremaining: 1.82s\n",
      "137:\tlearn: 0.9101254\ttotal: 506ms\tremaining: 1.82s\n",
      "138:\tlearn: 0.9094940\ttotal: 510ms\tremaining: 1.82s\n",
      "139:\tlearn: 0.9087816\ttotal: 513ms\tremaining: 1.81s\n",
      "140:\tlearn: 0.9080673\ttotal: 517ms\tremaining: 1.81s\n",
      "141:\tlearn: 0.9075847\ttotal: 521ms\tremaining: 1.81s\n",
      "142:\tlearn: 0.9067831\ttotal: 524ms\tremaining: 1.8s\n",
      "143:\tlearn: 0.9059999\ttotal: 528ms\tremaining: 1.8s\n",
      "144:\tlearn: 0.9052480\ttotal: 532ms\tremaining: 1.8s\n",
      "145:\tlearn: 0.9045572\ttotal: 535ms\tremaining: 1.79s\n",
      "146:\tlearn: 0.9039554\ttotal: 539ms\tremaining: 1.79s\n",
      "147:\tlearn: 0.9031251\ttotal: 542ms\tremaining: 1.78s\n",
      "148:\tlearn: 0.9025033\ttotal: 545ms\tremaining: 1.78s\n",
      "149:\tlearn: 0.9014469\ttotal: 549ms\tremaining: 1.77s\n",
      "150:\tlearn: 0.9007132\ttotal: 553ms\tremaining: 1.77s\n",
      "151:\tlearn: 0.8999297\ttotal: 556ms\tremaining: 1.77s\n",
      "152:\tlearn: 0.8992959\ttotal: 560ms\tremaining: 1.76s\n",
      "153:\tlearn: 0.8986668\ttotal: 564ms\tremaining: 1.76s\n",
      "154:\tlearn: 0.8978066\ttotal: 568ms\tremaining: 1.76s\n",
      "155:\tlearn: 0.8973273\ttotal: 572ms\tremaining: 1.75s\n",
      "156:\tlearn: 0.8964977\ttotal: 575ms\tremaining: 1.75s\n",
      "157:\tlearn: 0.8958489\ttotal: 579ms\tremaining: 1.75s\n",
      "158:\tlearn: 0.8953778\ttotal: 582ms\tremaining: 1.74s\n",
      "159:\tlearn: 0.8947212\ttotal: 586ms\tremaining: 1.74s\n",
      "160:\tlearn: 0.8941225\ttotal: 590ms\tremaining: 1.74s\n",
      "161:\tlearn: 0.8933764\ttotal: 593ms\tremaining: 1.73s\n",
      "162:\tlearn: 0.8924112\ttotal: 596ms\tremaining: 1.73s\n",
      "163:\tlearn: 0.8917479\ttotal: 600ms\tremaining: 1.72s\n",
      "164:\tlearn: 0.8909094\ttotal: 604ms\tremaining: 1.72s\n",
      "165:\tlearn: 0.8901904\ttotal: 607ms\tremaining: 1.72s\n",
      "166:\tlearn: 0.8897379\ttotal: 611ms\tremaining: 1.71s\n",
      "167:\tlearn: 0.8892051\ttotal: 615ms\tremaining: 1.71s\n",
      "168:\tlearn: 0.8884443\ttotal: 619ms\tremaining: 1.71s\n",
      "169:\tlearn: 0.8875470\ttotal: 622ms\tremaining: 1.7s\n",
      "170:\tlearn: 0.8869840\ttotal: 625ms\tremaining: 1.7s\n",
      "171:\tlearn: 0.8863386\ttotal: 629ms\tremaining: 1.69s\n",
      "172:\tlearn: 0.8858064\ttotal: 633ms\tremaining: 1.69s\n",
      "173:\tlearn: 0.8854312\ttotal: 636ms\tremaining: 1.69s\n",
      "174:\tlearn: 0.8848142\ttotal: 640ms\tremaining: 1.68s\n",
      "175:\tlearn: 0.8841807\ttotal: 643ms\tremaining: 1.68s\n",
      "176:\tlearn: 0.8836128\ttotal: 647ms\tremaining: 1.67s\n",
      "177:\tlearn: 0.8827646\ttotal: 651ms\tremaining: 1.67s\n",
      "178:\tlearn: 0.8823703\ttotal: 655ms\tremaining: 1.67s\n",
      "179:\tlearn: 0.8813949\ttotal: 658ms\tremaining: 1.66s\n",
      "180:\tlearn: 0.8809265\ttotal: 662ms\tremaining: 1.66s\n",
      "181:\tlearn: 0.8805719\ttotal: 665ms\tremaining: 1.66s\n",
      "182:\tlearn: 0.8799981\ttotal: 669ms\tremaining: 1.65s\n",
      "183:\tlearn: 0.8794674\ttotal: 672ms\tremaining: 1.65s\n",
      "184:\tlearn: 0.8788147\ttotal: 676ms\tremaining: 1.64s\n",
      "185:\tlearn: 0.8783020\ttotal: 679ms\tremaining: 1.64s\n",
      "186:\tlearn: 0.8779429\ttotal: 683ms\tremaining: 1.64s\n",
      "187:\tlearn: 0.8774960\ttotal: 686ms\tremaining: 1.63s\n",
      "188:\tlearn: 0.8768115\ttotal: 690ms\tremaining: 1.63s\n",
      "189:\tlearn: 0.8763177\ttotal: 693ms\tremaining: 1.62s\n",
      "190:\tlearn: 0.8760172\ttotal: 697ms\tremaining: 1.62s\n",
      "191:\tlearn: 0.8754123\ttotal: 701ms\tremaining: 1.62s\n",
      "192:\tlearn: 0.8748805\ttotal: 704ms\tremaining: 1.61s\n",
      "193:\tlearn: 0.8743691\ttotal: 707ms\tremaining: 1.61s\n",
      "194:\tlearn: 0.8738113\ttotal: 711ms\tremaining: 1.6s\n",
      "195:\tlearn: 0.8732624\ttotal: 715ms\tremaining: 1.6s\n",
      "196:\tlearn: 0.8728276\ttotal: 719ms\tremaining: 1.6s\n",
      "197:\tlearn: 0.8723111\ttotal: 722ms\tremaining: 1.59s\n",
      "198:\tlearn: 0.8718948\ttotal: 726ms\tremaining: 1.59s\n",
      "199:\tlearn: 0.8709476\ttotal: 729ms\tremaining: 1.58s\n",
      "200:\tlearn: 0.8704483\ttotal: 733ms\tremaining: 1.58s\n",
      "201:\tlearn: 0.8699948\ttotal: 736ms\tremaining: 1.58s\n",
      "202:\tlearn: 0.8693517\ttotal: 740ms\tremaining: 1.57s\n",
      "203:\tlearn: 0.8689808\ttotal: 743ms\tremaining: 1.57s\n",
      "204:\tlearn: 0.8684508\ttotal: 746ms\tremaining: 1.56s\n",
      "205:\tlearn: 0.8679942\ttotal: 749ms\tremaining: 1.56s\n",
      "206:\tlearn: 0.8675725\ttotal: 753ms\tremaining: 1.56s\n",
      "207:\tlearn: 0.8672487\ttotal: 756ms\tremaining: 1.55s\n",
      "208:\tlearn: 0.8668333\ttotal: 760ms\tremaining: 1.55s\n",
      "209:\tlearn: 0.8664818\ttotal: 764ms\tremaining: 1.54s\n",
      "210:\tlearn: 0.8660477\ttotal: 767ms\tremaining: 1.54s\n",
      "211:\tlearn: 0.8657147\ttotal: 770ms\tremaining: 1.54s\n",
      "212:\tlearn: 0.8651227\ttotal: 774ms\tremaining: 1.53s\n",
      "213:\tlearn: 0.8647408\ttotal: 777ms\tremaining: 1.53s\n",
      "214:\tlearn: 0.8641979\ttotal: 780ms\tremaining: 1.52s\n",
      "215:\tlearn: 0.8639186\ttotal: 784ms\tremaining: 1.52s\n",
      "216:\tlearn: 0.8636545\ttotal: 787ms\tremaining: 1.52s\n",
      "217:\tlearn: 0.8631588\ttotal: 790ms\tremaining: 1.51s\n",
      "218:\tlearn: 0.8628093\ttotal: 793ms\tremaining: 1.51s\n",
      "219:\tlearn: 0.8622298\ttotal: 796ms\tremaining: 1.5s\n",
      "220:\tlearn: 0.8617027\ttotal: 800ms\tremaining: 1.5s\n",
      "221:\tlearn: 0.8612521\ttotal: 804ms\tremaining: 1.5s\n",
      "222:\tlearn: 0.8608959\ttotal: 808ms\tremaining: 1.49s\n",
      "223:\tlearn: 0.8603223\ttotal: 812ms\tremaining: 1.49s\n",
      "224:\tlearn: 0.8599674\ttotal: 815ms\tremaining: 1.49s\n",
      "225:\tlearn: 0.8596440\ttotal: 818ms\tremaining: 1.48s\n",
      "226:\tlearn: 0.8593749\ttotal: 822ms\tremaining: 1.48s\n",
      "227:\tlearn: 0.8589446\ttotal: 825ms\tremaining: 1.47s\n",
      "228:\tlearn: 0.8585756\ttotal: 829ms\tremaining: 1.47s\n",
      "229:\tlearn: 0.8583230\ttotal: 833ms\tremaining: 1.47s\n",
      "230:\tlearn: 0.8578600\ttotal: 837ms\tremaining: 1.46s\n",
      "231:\tlearn: 0.8574942\ttotal: 840ms\tremaining: 1.46s\n",
      "232:\tlearn: 0.8572129\ttotal: 844ms\tremaining: 1.46s\n",
      "233:\tlearn: 0.8565493\ttotal: 847ms\tremaining: 1.45s\n",
      "234:\tlearn: 0.8561742\ttotal: 851ms\tremaining: 1.45s\n",
      "235:\tlearn: 0.8556853\ttotal: 854ms\tremaining: 1.44s\n",
      "236:\tlearn: 0.8552602\ttotal: 858ms\tremaining: 1.44s\n",
      "237:\tlearn: 0.8550134\ttotal: 861ms\tremaining: 1.44s\n",
      "238:\tlearn: 0.8545640\ttotal: 865ms\tremaining: 1.43s\n",
      "239:\tlearn: 0.8540875\ttotal: 869ms\tremaining: 1.43s\n",
      "240:\tlearn: 0.8537660\ttotal: 872ms\tremaining: 1.43s\n",
      "241:\tlearn: 0.8532905\ttotal: 876ms\tremaining: 1.42s\n",
      "242:\tlearn: 0.8526279\ttotal: 880ms\tremaining: 1.42s\n",
      "243:\tlearn: 0.8522036\ttotal: 883ms\tremaining: 1.42s\n",
      "244:\tlearn: 0.8519799\ttotal: 886ms\tremaining: 1.41s\n",
      "245:\tlearn: 0.8513399\ttotal: 890ms\tremaining: 1.41s\n",
      "246:\tlearn: 0.8508759\ttotal: 894ms\tremaining: 1.4s\n",
      "247:\tlearn: 0.8505542\ttotal: 897ms\tremaining: 1.4s\n",
      "248:\tlearn: 0.8501291\ttotal: 900ms\tremaining: 1.4s\n",
      "249:\tlearn: 0.8498244\ttotal: 903ms\tremaining: 1.39s\n",
      "250:\tlearn: 0.8495762\ttotal: 906ms\tremaining: 1.39s\n",
      "251:\tlearn: 0.8491573\ttotal: 910ms\tremaining: 1.38s\n",
      "252:\tlearn: 0.8485517\ttotal: 914ms\tremaining: 1.38s\n",
      "253:\tlearn: 0.8481605\ttotal: 917ms\tremaining: 1.38s\n",
      "254:\tlearn: 0.8476685\ttotal: 920ms\tremaining: 1.37s\n",
      "255:\tlearn: 0.8473723\ttotal: 924ms\tremaining: 1.37s\n",
      "256:\tlearn: 0.8470814\ttotal: 928ms\tremaining: 1.36s\n",
      "257:\tlearn: 0.8466776\ttotal: 931ms\tremaining: 1.36s\n",
      "258:\tlearn: 0.8463305\ttotal: 933ms\tremaining: 1.35s\n",
      "259:\tlearn: 0.8459983\ttotal: 937ms\tremaining: 1.35s\n",
      "260:\tlearn: 0.8455520\ttotal: 940ms\tremaining: 1.35s\n",
      "261:\tlearn: 0.8453373\ttotal: 944ms\tremaining: 1.34s\n",
      "262:\tlearn: 0.8449665\ttotal: 948ms\tremaining: 1.34s\n",
      "263:\tlearn: 0.8444325\ttotal: 951ms\tremaining: 1.34s\n",
      "264:\tlearn: 0.8440240\ttotal: 955ms\tremaining: 1.33s\n",
      "265:\tlearn: 0.8436516\ttotal: 959ms\tremaining: 1.33s\n",
      "266:\tlearn: 0.8432766\ttotal: 963ms\tremaining: 1.33s\n",
      "267:\tlearn: 0.8428149\ttotal: 966ms\tremaining: 1.32s\n",
      "268:\tlearn: 0.8423615\ttotal: 970ms\tremaining: 1.32s\n",
      "269:\tlearn: 0.8421255\ttotal: 974ms\tremaining: 1.32s\n",
      "270:\tlearn: 0.8418388\ttotal: 978ms\tremaining: 1.31s\n",
      "271:\tlearn: 0.8411828\ttotal: 982ms\tremaining: 1.31s\n",
      "272:\tlearn: 0.8408639\ttotal: 985ms\tremaining: 1.31s\n",
      "273:\tlearn: 0.8404373\ttotal: 989ms\tremaining: 1.3s\n",
      "274:\tlearn: 0.8397166\ttotal: 992ms\tremaining: 1.3s\n",
      "275:\tlearn: 0.8393902\ttotal: 996ms\tremaining: 1.29s\n",
      "276:\tlearn: 0.8388989\ttotal: 999ms\tremaining: 1.29s\n",
      "277:\tlearn: 0.8385064\ttotal: 1s\tremaining: 1.29s\n",
      "278:\tlearn: 0.8380428\ttotal: 1s\tremaining: 1.28s\n",
      "279:\tlearn: 0.8377209\ttotal: 1.01s\tremaining: 1.28s\n",
      "280:\tlearn: 0.8373447\ttotal: 1.01s\tremaining: 1.27s\n",
      "281:\tlearn: 0.8369361\ttotal: 1.01s\tremaining: 1.27s\n",
      "282:\tlearn: 0.8365523\ttotal: 1.02s\tremaining: 1.27s\n",
      "283:\tlearn: 0.8362707\ttotal: 1.02s\tremaining: 1.26s\n",
      "284:\tlearn: 0.8358714\ttotal: 1.03s\tremaining: 1.26s\n",
      "285:\tlearn: 0.8355723\ttotal: 1.03s\tremaining: 1.26s\n",
      "286:\tlearn: 0.8353035\ttotal: 1.03s\tremaining: 1.25s\n",
      "287:\tlearn: 0.8348607\ttotal: 1.03s\tremaining: 1.25s\n",
      "288:\tlearn: 0.8345309\ttotal: 1.04s\tremaining: 1.24s\n",
      "289:\tlearn: 0.8340401\ttotal: 1.04s\tremaining: 1.24s\n",
      "290:\tlearn: 0.8336737\ttotal: 1.04s\tremaining: 1.23s\n",
      "291:\tlearn: 0.8332743\ttotal: 1.05s\tremaining: 1.23s\n",
      "292:\tlearn: 0.8328617\ttotal: 1.05s\tremaining: 1.23s\n",
      "293:\tlearn: 0.8326869\ttotal: 1.05s\tremaining: 1.22s\n",
      "294:\tlearn: 0.8324762\ttotal: 1.06s\tremaining: 1.22s\n",
      "295:\tlearn: 0.8321236\ttotal: 1.06s\tremaining: 1.21s\n",
      "296:\tlearn: 0.8318608\ttotal: 1.06s\tremaining: 1.21s\n",
      "297:\tlearn: 0.8315535\ttotal: 1.07s\tremaining: 1.21s\n",
      "298:\tlearn: 0.8312987\ttotal: 1.07s\tremaining: 1.2s\n",
      "299:\tlearn: 0.8307373\ttotal: 1.07s\tremaining: 1.2s\n",
      "300:\tlearn: 0.8302208\ttotal: 1.07s\tremaining: 1.19s\n",
      "301:\tlearn: 0.8297903\ttotal: 1.08s\tremaining: 1.19s\n",
      "302:\tlearn: 0.8295019\ttotal: 1.08s\tremaining: 1.18s\n",
      "303:\tlearn: 0.8293171\ttotal: 1.08s\tremaining: 1.18s\n",
      "304:\tlearn: 0.8289063\ttotal: 1.08s\tremaining: 1.17s\n",
      "305:\tlearn: 0.8284552\ttotal: 1.09s\tremaining: 1.17s\n",
      "306:\tlearn: 0.8282181\ttotal: 1.09s\tremaining: 1.17s\n",
      "307:\tlearn: 0.8278953\ttotal: 1.1s\tremaining: 1.16s\n",
      "308:\tlearn: 0.8277131\ttotal: 1.1s\tremaining: 1.16s\n",
      "309:\tlearn: 0.8274838\ttotal: 1.1s\tremaining: 1.16s\n",
      "310:\tlearn: 0.8271128\ttotal: 1.11s\tremaining: 1.15s\n",
      "311:\tlearn: 0.8267544\ttotal: 1.11s\tremaining: 1.15s\n",
      "312:\tlearn: 0.8262670\ttotal: 1.11s\tremaining: 1.15s\n",
      "313:\tlearn: 0.8259991\ttotal: 1.12s\tremaining: 1.14s\n",
      "314:\tlearn: 0.8255376\ttotal: 1.12s\tremaining: 1.14s\n",
      "315:\tlearn: 0.8252716\ttotal: 1.13s\tremaining: 1.14s\n",
      "316:\tlearn: 0.8250244\ttotal: 1.13s\tremaining: 1.13s\n",
      "317:\tlearn: 0.8247975\ttotal: 1.13s\tremaining: 1.13s\n",
      "318:\tlearn: 0.8244983\ttotal: 1.14s\tremaining: 1.13s\n",
      "319:\tlearn: 0.8240682\ttotal: 1.14s\tremaining: 1.12s\n",
      "320:\tlearn: 0.8238488\ttotal: 1.14s\tremaining: 1.12s\n",
      "321:\tlearn: 0.8236094\ttotal: 1.15s\tremaining: 1.11s\n",
      "322:\tlearn: 0.8234101\ttotal: 1.15s\tremaining: 1.11s\n",
      "323:\tlearn: 0.8229454\ttotal: 1.15s\tremaining: 1.11s\n",
      "324:\tlearn: 0.8225814\ttotal: 1.16s\tremaining: 1.1s\n",
      "325:\tlearn: 0.8219727\ttotal: 1.16s\tremaining: 1.1s\n",
      "326:\tlearn: 0.8217572\ttotal: 1.17s\tremaining: 1.1s\n",
      "327:\tlearn: 0.8214687\ttotal: 1.17s\tremaining: 1.09s\n",
      "328:\tlearn: 0.8214259\ttotal: 1.17s\tremaining: 1.09s\n",
      "329:\tlearn: 0.8211076\ttotal: 1.18s\tremaining: 1.09s\n",
      "330:\tlearn: 0.8203736\ttotal: 1.18s\tremaining: 1.08s\n",
      "331:\tlearn: 0.8202278\ttotal: 1.18s\tremaining: 1.08s\n",
      "332:\tlearn: 0.8197824\ttotal: 1.19s\tremaining: 1.08s\n",
      "333:\tlearn: 0.8194722\ttotal: 1.19s\tremaining: 1.07s\n",
      "334:\tlearn: 0.8192422\ttotal: 1.2s\tremaining: 1.07s\n",
      "335:\tlearn: 0.8188619\ttotal: 1.2s\tremaining: 1.07s\n",
      "336:\tlearn: 0.8186389\ttotal: 1.2s\tremaining: 1.06s\n",
      "337:\tlearn: 0.8183493\ttotal: 1.21s\tremaining: 1.06s\n",
      "338:\tlearn: 0.8181112\ttotal: 1.21s\tremaining: 1.06s\n",
      "339:\tlearn: 0.8177139\ttotal: 1.21s\tremaining: 1.05s\n",
      "340:\tlearn: 0.8174632\ttotal: 1.22s\tremaining: 1.05s\n",
      "341:\tlearn: 0.8172175\ttotal: 1.22s\tremaining: 1.05s\n",
      "342:\tlearn: 0.8168718\ttotal: 1.22s\tremaining: 1.04s\n",
      "343:\tlearn: 0.8165368\ttotal: 1.23s\tremaining: 1.04s\n",
      "344:\tlearn: 0.8162177\ttotal: 1.23s\tremaining: 1.03s\n",
      "345:\tlearn: 0.8160409\ttotal: 1.23s\tremaining: 1.03s\n",
      "346:\tlearn: 0.8158175\ttotal: 1.24s\tremaining: 1.03s\n",
      "347:\tlearn: 0.8155004\ttotal: 1.24s\tremaining: 1.02s\n",
      "348:\tlearn: 0.8151225\ttotal: 1.25s\tremaining: 1.02s\n",
      "349:\tlearn: 0.8148221\ttotal: 1.25s\tremaining: 1.02s\n",
      "350:\tlearn: 0.8145155\ttotal: 1.25s\tremaining: 1.01s\n",
      "351:\tlearn: 0.8141523\ttotal: 1.26s\tremaining: 1.01s\n",
      "352:\tlearn: 0.8140124\ttotal: 1.26s\tremaining: 1.01s\n",
      "353:\tlearn: 0.8138223\ttotal: 1.26s\tremaining: 1s\n",
      "354:\tlearn: 0.8135838\ttotal: 1.27s\tremaining: 1s\n",
      "355:\tlearn: 0.8132352\ttotal: 1.27s\tremaining: 997ms\n",
      "356:\tlearn: 0.8128824\ttotal: 1.27s\tremaining: 993ms\n",
      "357:\tlearn: 0.8126114\ttotal: 1.28s\tremaining: 990ms\n",
      "358:\tlearn: 0.8122848\ttotal: 1.28s\tremaining: 986ms\n",
      "359:\tlearn: 0.8119016\ttotal: 1.29s\tremaining: 983ms\n",
      "360:\tlearn: 0.8114767\ttotal: 1.29s\tremaining: 980ms\n",
      "361:\tlearn: 0.8112830\ttotal: 1.29s\tremaining: 976ms\n",
      "362:\tlearn: 0.8110727\ttotal: 1.3s\tremaining: 973ms\n",
      "363:\tlearn: 0.8109296\ttotal: 1.3s\tremaining: 970ms\n",
      "364:\tlearn: 0.8105112\ttotal: 1.3s\tremaining: 966ms\n",
      "365:\tlearn: 0.8102904\ttotal: 1.31s\tremaining: 963ms\n",
      "366:\tlearn: 0.8101015\ttotal: 1.31s\tremaining: 959ms\n",
      "367:\tlearn: 0.8098433\ttotal: 1.32s\tremaining: 955ms\n",
      "368:\tlearn: 0.8096215\ttotal: 1.32s\tremaining: 952ms\n",
      "369:\tlearn: 0.8092892\ttotal: 1.32s\tremaining: 948ms\n",
      "370:\tlearn: 0.8090543\ttotal: 1.33s\tremaining: 945ms\n",
      "371:\tlearn: 0.8088645\ttotal: 1.33s\tremaining: 942ms\n",
      "372:\tlearn: 0.8084980\ttotal: 1.33s\tremaining: 938ms\n",
      "373:\tlearn: 0.8081229\ttotal: 1.34s\tremaining: 935ms\n",
      "374:\tlearn: 0.8078725\ttotal: 1.34s\tremaining: 931ms\n",
      "375:\tlearn: 0.8074466\ttotal: 1.35s\tremaining: 928ms\n",
      "376:\tlearn: 0.8071982\ttotal: 1.35s\tremaining: 924ms\n",
      "377:\tlearn: 0.8070191\ttotal: 1.35s\tremaining: 920ms\n",
      "378:\tlearn: 0.8068626\ttotal: 1.36s\tremaining: 916ms\n",
      "379:\tlearn: 0.8064823\ttotal: 1.36s\tremaining: 913ms\n",
      "380:\tlearn: 0.8061407\ttotal: 1.36s\tremaining: 910ms\n",
      "381:\tlearn: 0.8057695\ttotal: 1.37s\tremaining: 906ms\n",
      "382:\tlearn: 0.8055028\ttotal: 1.37s\tremaining: 903ms\n",
      "383:\tlearn: 0.8052682\ttotal: 1.38s\tremaining: 899ms\n",
      "384:\tlearn: 0.8050103\ttotal: 1.38s\tremaining: 896ms\n",
      "385:\tlearn: 0.8047220\ttotal: 1.38s\tremaining: 892ms\n",
      "386:\tlearn: 0.8043920\ttotal: 1.39s\tremaining: 889ms\n",
      "387:\tlearn: 0.8041226\ttotal: 1.39s\tremaining: 886ms\n",
      "388:\tlearn: 0.8038076\ttotal: 1.39s\tremaining: 882ms\n",
      "389:\tlearn: 0.8035642\ttotal: 1.4s\tremaining: 879ms\n",
      "390:\tlearn: 0.8033695\ttotal: 1.4s\tremaining: 875ms\n",
      "391:\tlearn: 0.8031746\ttotal: 1.41s\tremaining: 872ms\n",
      "392:\tlearn: 0.8027837\ttotal: 1.41s\tremaining: 868ms\n",
      "393:\tlearn: 0.8024807\ttotal: 1.41s\tremaining: 865ms\n",
      "394:\tlearn: 0.8021635\ttotal: 1.42s\tremaining: 861ms\n",
      "395:\tlearn: 0.8017491\ttotal: 1.42s\tremaining: 858ms\n",
      "396:\tlearn: 0.8014940\ttotal: 1.43s\tremaining: 854ms\n",
      "397:\tlearn: 0.8012302\ttotal: 1.43s\tremaining: 851ms\n",
      "398:\tlearn: 0.8009743\ttotal: 1.43s\tremaining: 847ms\n",
      "399:\tlearn: 0.8006967\ttotal: 1.44s\tremaining: 843ms\n",
      "400:\tlearn: 0.8004546\ttotal: 1.44s\tremaining: 840ms\n",
      "401:\tlearn: 0.8002569\ttotal: 1.44s\tremaining: 835ms\n",
      "402:\tlearn: 0.8000968\ttotal: 1.44s\tremaining: 831ms\n",
      "403:\tlearn: 0.7998037\ttotal: 1.45s\tremaining: 827ms\n",
      "404:\tlearn: 0.7995291\ttotal: 1.45s\tremaining: 823ms\n",
      "405:\tlearn: 0.7992812\ttotal: 1.45s\tremaining: 819ms\n",
      "406:\tlearn: 0.7989789\ttotal: 1.46s\tremaining: 815ms\n",
      "407:\tlearn: 0.7987678\ttotal: 1.46s\tremaining: 811ms\n",
      "408:\tlearn: 0.7986216\ttotal: 1.46s\tremaining: 808ms\n",
      "409:\tlearn: 0.7984107\ttotal: 1.46s\tremaining: 804ms\n",
      "410:\tlearn: 0.7981842\ttotal: 1.47s\tremaining: 800ms\n",
      "411:\tlearn: 0.7979960\ttotal: 1.47s\tremaining: 796ms\n",
      "412:\tlearn: 0.7978086\ttotal: 1.48s\tremaining: 793ms\n",
      "413:\tlearn: 0.7976715\ttotal: 1.48s\tremaining: 789ms\n",
      "414:\tlearn: 0.7974267\ttotal: 1.48s\tremaining: 786ms\n",
      "415:\tlearn: 0.7971883\ttotal: 1.49s\tremaining: 782ms\n",
      "416:\tlearn: 0.7969024\ttotal: 1.49s\tremaining: 779ms\n",
      "417:\tlearn: 0.7966186\ttotal: 1.49s\tremaining: 775ms\n",
      "418:\tlearn: 0.7963745\ttotal: 1.49s\tremaining: 770ms\n",
      "419:\tlearn: 0.7961598\ttotal: 1.5s\tremaining: 767ms\n",
      "420:\tlearn: 0.7959500\ttotal: 1.5s\tremaining: 763ms\n",
      "421:\tlearn: 0.7956591\ttotal: 1.5s\tremaining: 759ms\n",
      "422:\tlearn: 0.7953701\ttotal: 1.51s\tremaining: 755ms\n",
      "423:\tlearn: 0.7951779\ttotal: 1.51s\tremaining: 751ms\n",
      "424:\tlearn: 0.7948426\ttotal: 1.51s\tremaining: 747ms\n",
      "425:\tlearn: 0.7946215\ttotal: 1.51s\tremaining: 743ms\n",
      "426:\tlearn: 0.7942633\ttotal: 1.52s\tremaining: 739ms\n",
      "427:\tlearn: 0.7940735\ttotal: 1.52s\tremaining: 735ms\n",
      "428:\tlearn: 0.7938207\ttotal: 1.52s\tremaining: 731ms\n",
      "429:\tlearn: 0.7937402\ttotal: 1.52s\tremaining: 727ms\n",
      "430:\tlearn: 0.7935381\ttotal: 1.53s\tremaining: 723ms\n",
      "431:\tlearn: 0.7933767\ttotal: 1.53s\tremaining: 720ms\n",
      "432:\tlearn: 0.7933069\ttotal: 1.53s\tremaining: 717ms\n",
      "433:\tlearn: 0.7931270\ttotal: 1.54s\tremaining: 713ms\n",
      "434:\tlearn: 0.7929059\ttotal: 1.54s\tremaining: 710ms\n",
      "435:\tlearn: 0.7926111\ttotal: 1.55s\tremaining: 706ms\n",
      "436:\tlearn: 0.7923616\ttotal: 1.55s\tremaining: 702ms\n",
      "437:\tlearn: 0.7922602\ttotal: 1.55s\tremaining: 699ms\n",
      "438:\tlearn: 0.7919371\ttotal: 1.56s\tremaining: 696ms\n",
      "439:\tlearn: 0.7916903\ttotal: 1.56s\tremaining: 692ms\n",
      "440:\tlearn: 0.7916089\ttotal: 1.56s\tremaining: 689ms\n",
      "441:\tlearn: 0.7914285\ttotal: 1.57s\tremaining: 685ms\n",
      "442:\tlearn: 0.7912416\ttotal: 1.57s\tremaining: 682ms\n",
      "443:\tlearn: 0.7910701\ttotal: 1.58s\tremaining: 679ms\n",
      "444:\tlearn: 0.7907764\ttotal: 1.58s\tremaining: 676ms\n",
      "445:\tlearn: 0.7904493\ttotal: 1.59s\tremaining: 673ms\n",
      "446:\tlearn: 0.7901456\ttotal: 1.59s\tremaining: 669ms\n",
      "447:\tlearn: 0.7899300\ttotal: 1.59s\tremaining: 666ms\n",
      "448:\tlearn: 0.7895969\ttotal: 1.6s\tremaining: 662ms\n",
      "449:\tlearn: 0.7893943\ttotal: 1.6s\tremaining: 658ms\n",
      "450:\tlearn: 0.7891725\ttotal: 1.6s\tremaining: 654ms\n",
      "451:\tlearn: 0.7888565\ttotal: 1.61s\tremaining: 651ms\n",
      "452:\tlearn: 0.7885918\ttotal: 1.61s\tremaining: 647ms\n",
      "453:\tlearn: 0.7882749\ttotal: 1.61s\tremaining: 644ms\n",
      "454:\tlearn: 0.7879955\ttotal: 1.62s\tremaining: 640ms\n",
      "455:\tlearn: 0.7879005\ttotal: 1.62s\tremaining: 637ms\n",
      "456:\tlearn: 0.7876964\ttotal: 1.62s\tremaining: 633ms\n",
      "457:\tlearn: 0.7875252\ttotal: 1.63s\tremaining: 629ms\n",
      "458:\tlearn: 0.7872517\ttotal: 1.63s\tremaining: 626ms\n",
      "459:\tlearn: 0.7869270\ttotal: 1.64s\tremaining: 622ms\n",
      "460:\tlearn: 0.7867284\ttotal: 1.64s\tremaining: 619ms\n",
      "461:\tlearn: 0.7864317\ttotal: 1.64s\tremaining: 615ms\n",
      "462:\tlearn: 0.7861483\ttotal: 1.65s\tremaining: 612ms\n",
      "463:\tlearn: 0.7859526\ttotal: 1.65s\tremaining: 608ms\n",
      "464:\tlearn: 0.7857180\ttotal: 1.65s\tremaining: 604ms\n",
      "465:\tlearn: 0.7854751\ttotal: 1.66s\tremaining: 601ms\n",
      "466:\tlearn: 0.7852366\ttotal: 1.66s\tremaining: 597ms\n",
      "467:\tlearn: 0.7849533\ttotal: 1.66s\tremaining: 594ms\n",
      "468:\tlearn: 0.7847776\ttotal: 1.67s\tremaining: 590ms\n",
      "469:\tlearn: 0.7845822\ttotal: 1.67s\tremaining: 586ms\n",
      "470:\tlearn: 0.7843526\ttotal: 1.67s\tremaining: 583ms\n",
      "471:\tlearn: 0.7839558\ttotal: 1.68s\tremaining: 580ms\n",
      "472:\tlearn: 0.7837740\ttotal: 1.68s\tremaining: 576ms\n",
      "473:\tlearn: 0.7836040\ttotal: 1.69s\tremaining: 573ms\n",
      "474:\tlearn: 0.7832812\ttotal: 1.69s\tremaining: 569ms\n",
      "475:\tlearn: 0.7831083\ttotal: 1.69s\tremaining: 565ms\n",
      "476:\tlearn: 0.7829479\ttotal: 1.7s\tremaining: 562ms\n",
      "477:\tlearn: 0.7827188\ttotal: 1.7s\tremaining: 558ms\n",
      "478:\tlearn: 0.7824297\ttotal: 1.7s\tremaining: 555ms\n",
      "479:\tlearn: 0.7822042\ttotal: 1.71s\tremaining: 551ms\n",
      "480:\tlearn: 0.7820598\ttotal: 1.71s\tremaining: 548ms\n",
      "481:\tlearn: 0.7817750\ttotal: 1.71s\tremaining: 544ms\n",
      "482:\tlearn: 0.7815493\ttotal: 1.72s\tremaining: 541ms\n",
      "483:\tlearn: 0.7812942\ttotal: 1.72s\tremaining: 537ms\n",
      "484:\tlearn: 0.7811631\ttotal: 1.72s\tremaining: 533ms\n",
      "485:\tlearn: 0.7809658\ttotal: 1.73s\tremaining: 530ms\n",
      "486:\tlearn: 0.7807094\ttotal: 1.73s\tremaining: 526ms\n",
      "487:\tlearn: 0.7806366\ttotal: 1.74s\tremaining: 523ms\n",
      "488:\tlearn: 0.7802636\ttotal: 1.74s\tremaining: 519ms\n",
      "489:\tlearn: 0.7800809\ttotal: 1.74s\tremaining: 516ms\n",
      "490:\tlearn: 0.7798469\ttotal: 1.75s\tremaining: 512ms\n",
      "491:\tlearn: 0.7795527\ttotal: 1.75s\tremaining: 509ms\n",
      "492:\tlearn: 0.7794295\ttotal: 1.75s\tremaining: 505ms\n",
      "493:\tlearn: 0.7792619\ttotal: 1.76s\tremaining: 502ms\n",
      "494:\tlearn: 0.7790595\ttotal: 1.76s\tremaining: 498ms\n",
      "495:\tlearn: 0.7788649\ttotal: 1.76s\tremaining: 495ms\n",
      "496:\tlearn: 0.7786803\ttotal: 1.77s\tremaining: 491ms\n",
      "497:\tlearn: 0.7785417\ttotal: 1.77s\tremaining: 487ms\n",
      "498:\tlearn: 0.7782750\ttotal: 1.77s\tremaining: 484ms\n",
      "499:\tlearn: 0.7778578\ttotal: 1.78s\tremaining: 480ms\n",
      "500:\tlearn: 0.7775579\ttotal: 1.78s\tremaining: 477ms\n",
      "501:\tlearn: 0.7773298\ttotal: 1.79s\tremaining: 473ms\n",
      "502:\tlearn: 0.7771155\ttotal: 1.79s\tremaining: 470ms\n",
      "503:\tlearn: 0.7768484\ttotal: 1.79s\tremaining: 466ms\n",
      "504:\tlearn: 0.7765851\ttotal: 1.8s\tremaining: 463ms\n",
      "505:\tlearn: 0.7762574\ttotal: 1.8s\tremaining: 459ms\n",
      "506:\tlearn: 0.7759800\ttotal: 1.8s\tremaining: 456ms\n",
      "507:\tlearn: 0.7757721\ttotal: 1.81s\tremaining: 452ms\n",
      "508:\tlearn: 0.7755827\ttotal: 1.81s\tremaining: 449ms\n",
      "509:\tlearn: 0.7754819\ttotal: 1.82s\tremaining: 445ms\n",
      "510:\tlearn: 0.7751441\ttotal: 1.82s\tremaining: 442ms\n",
      "511:\tlearn: 0.7749608\ttotal: 1.82s\tremaining: 438ms\n",
      "512:\tlearn: 0.7745881\ttotal: 1.83s\tremaining: 435ms\n",
      "513:\tlearn: 0.7743477\ttotal: 1.83s\tremaining: 431ms\n",
      "514:\tlearn: 0.7741349\ttotal: 1.83s\tremaining: 428ms\n",
      "515:\tlearn: 0.7737926\ttotal: 1.84s\tremaining: 424ms\n",
      "516:\tlearn: 0.7735962\ttotal: 1.84s\tremaining: 420ms\n",
      "517:\tlearn: 0.7732357\ttotal: 1.84s\tremaining: 417ms\n",
      "518:\tlearn: 0.7729862\ttotal: 1.85s\tremaining: 413ms\n",
      "519:\tlearn: 0.7728018\ttotal: 1.85s\tremaining: 410ms\n",
      "520:\tlearn: 0.7727112\ttotal: 1.86s\tremaining: 406ms\n",
      "521:\tlearn: 0.7725075\ttotal: 1.86s\tremaining: 403ms\n",
      "522:\tlearn: 0.7721960\ttotal: 1.86s\tremaining: 399ms\n",
      "523:\tlearn: 0.7720299\ttotal: 1.87s\tremaining: 396ms\n",
      "524:\tlearn: 0.7718266\ttotal: 1.87s\tremaining: 392ms\n",
      "525:\tlearn: 0.7715051\ttotal: 1.87s\tremaining: 388ms\n",
      "526:\tlearn: 0.7712634\ttotal: 1.88s\tremaining: 385ms\n",
      "527:\tlearn: 0.7710000\ttotal: 1.88s\tremaining: 381ms\n",
      "528:\tlearn: 0.7707573\ttotal: 1.89s\tremaining: 378ms\n",
      "529:\tlearn: 0.7705546\ttotal: 1.89s\tremaining: 374ms\n",
      "530:\tlearn: 0.7702505\ttotal: 1.89s\tremaining: 371ms\n",
      "531:\tlearn: 0.7700175\ttotal: 1.9s\tremaining: 367ms\n",
      "532:\tlearn: 0.7698340\ttotal: 1.9s\tremaining: 364ms\n",
      "533:\tlearn: 0.7696326\ttotal: 1.9s\tremaining: 360ms\n",
      "534:\tlearn: 0.7694125\ttotal: 1.91s\tremaining: 356ms\n",
      "535:\tlearn: 0.7692206\ttotal: 1.91s\tremaining: 353ms\n",
      "536:\tlearn: 0.7690786\ttotal: 1.91s\tremaining: 349ms\n",
      "537:\tlearn: 0.7688995\ttotal: 1.92s\tremaining: 346ms\n",
      "538:\tlearn: 0.7687173\ttotal: 1.92s\tremaining: 342ms\n",
      "539:\tlearn: 0.7685532\ttotal: 1.93s\tremaining: 339ms\n",
      "540:\tlearn: 0.7684784\ttotal: 1.93s\tremaining: 335ms\n",
      "541:\tlearn: 0.7682134\ttotal: 1.93s\tremaining: 332ms\n",
      "542:\tlearn: 0.7679894\ttotal: 1.94s\tremaining: 328ms\n",
      "543:\tlearn: 0.7677871\ttotal: 1.94s\tremaining: 324ms\n",
      "544:\tlearn: 0.7674720\ttotal: 1.94s\tremaining: 321ms\n",
      "545:\tlearn: 0.7673183\ttotal: 1.95s\tremaining: 317ms\n",
      "546:\tlearn: 0.7671838\ttotal: 1.95s\tremaining: 314ms\n",
      "547:\tlearn: 0.7670799\ttotal: 1.95s\tremaining: 310ms\n",
      "548:\tlearn: 0.7668759\ttotal: 1.96s\tremaining: 307ms\n",
      "549:\tlearn: 0.7665270\ttotal: 1.96s\tremaining: 303ms\n",
      "550:\tlearn: 0.7662870\ttotal: 1.96s\tremaining: 299ms\n",
      "551:\tlearn: 0.7660092\ttotal: 1.97s\tremaining: 296ms\n",
      "552:\tlearn: 0.7658966\ttotal: 1.97s\tremaining: 292ms\n",
      "553:\tlearn: 0.7657238\ttotal: 1.98s\tremaining: 289ms\n",
      "554:\tlearn: 0.7655293\ttotal: 1.98s\tremaining: 285ms\n",
      "555:\tlearn: 0.7653421\ttotal: 1.98s\tremaining: 282ms\n",
      "556:\tlearn: 0.7651432\ttotal: 1.99s\tremaining: 278ms\n",
      "557:\tlearn: 0.7648975\ttotal: 1.99s\tremaining: 275ms\n",
      "558:\tlearn: 0.7647324\ttotal: 1.99s\tremaining: 271ms\n",
      "559:\tlearn: 0.7645662\ttotal: 2s\tremaining: 267ms\n",
      "560:\tlearn: 0.7643909\ttotal: 2s\tremaining: 264ms\n",
      "561:\tlearn: 0.7642798\ttotal: 2s\tremaining: 260ms\n",
      "562:\tlearn: 0.7640667\ttotal: 2.01s\tremaining: 257ms\n",
      "563:\tlearn: 0.7638658\ttotal: 2.01s\tremaining: 253ms\n",
      "564:\tlearn: 0.7636551\ttotal: 2.01s\tremaining: 250ms\n",
      "565:\tlearn: 0.7633889\ttotal: 2.02s\tremaining: 246ms\n",
      "566:\tlearn: 0.7631117\ttotal: 2.02s\tremaining: 242ms\n",
      "567:\tlearn: 0.7627847\ttotal: 2.02s\tremaining: 239ms\n",
      "568:\tlearn: 0.7626354\ttotal: 2.03s\tremaining: 235ms\n",
      "569:\tlearn: 0.7622715\ttotal: 2.03s\tremaining: 232ms\n",
      "570:\tlearn: 0.7621374\ttotal: 2.03s\tremaining: 228ms\n",
      "571:\tlearn: 0.7620885\ttotal: 2.04s\tremaining: 224ms\n",
      "572:\tlearn: 0.7618760\ttotal: 2.04s\tremaining: 221ms\n",
      "573:\tlearn: 0.7616957\ttotal: 2.04s\tremaining: 217ms\n",
      "574:\tlearn: 0.7613668\ttotal: 2.05s\tremaining: 214ms\n",
      "575:\tlearn: 0.7611651\ttotal: 2.05s\tremaining: 210ms\n",
      "576:\tlearn: 0.7610939\ttotal: 2.05s\tremaining: 206ms\n",
      "577:\tlearn: 0.7609034\ttotal: 2.06s\tremaining: 203ms\n",
      "578:\tlearn: 0.7606313\ttotal: 2.06s\tremaining: 199ms\n",
      "579:\tlearn: 0.7604093\ttotal: 2.06s\tremaining: 196ms\n",
      "580:\tlearn: 0.7601926\ttotal: 2.07s\tremaining: 192ms\n",
      "581:\tlearn: 0.7599887\ttotal: 2.07s\tremaining: 189ms\n",
      "582:\tlearn: 0.7598872\ttotal: 2.08s\tremaining: 185ms\n",
      "583:\tlearn: 0.7596837\ttotal: 2.08s\tremaining: 182ms\n",
      "584:\tlearn: 0.7595366\ttotal: 2.08s\tremaining: 178ms\n",
      "585:\tlearn: 0.7594386\ttotal: 2.09s\tremaining: 174ms\n",
      "586:\tlearn: 0.7591314\ttotal: 2.09s\tremaining: 171ms\n",
      "587:\tlearn: 0.7588011\ttotal: 2.09s\tremaining: 167ms\n",
      "588:\tlearn: 0.7585888\ttotal: 2.1s\tremaining: 164ms\n",
      "589:\tlearn: 0.7584308\ttotal: 2.1s\tremaining: 160ms\n",
      "590:\tlearn: 0.7582602\ttotal: 2.1s\tremaining: 157ms\n",
      "591:\tlearn: 0.7580901\ttotal: 2.11s\tremaining: 153ms\n",
      "592:\tlearn: 0.7578791\ttotal: 2.11s\tremaining: 150ms\n",
      "593:\tlearn: 0.7576108\ttotal: 2.12s\tremaining: 146ms\n",
      "594:\tlearn: 0.7573223\ttotal: 2.12s\tremaining: 142ms\n",
      "595:\tlearn: 0.7571041\ttotal: 2.12s\tremaining: 139ms\n",
      "596:\tlearn: 0.7567817\ttotal: 2.13s\tremaining: 135ms\n",
      "597:\tlearn: 0.7565526\ttotal: 2.13s\tremaining: 132ms\n",
      "598:\tlearn: 0.7562745\ttotal: 2.13s\tremaining: 128ms\n",
      "599:\tlearn: 0.7560284\ttotal: 2.13s\tremaining: 125ms\n",
      "600:\tlearn: 0.7558037\ttotal: 2.14s\tremaining: 121ms\n",
      "601:\tlearn: 0.7556576\ttotal: 2.14s\tremaining: 117ms\n",
      "602:\tlearn: 0.7554765\ttotal: 2.15s\tremaining: 114ms\n",
      "603:\tlearn: 0.7551866\ttotal: 2.15s\tremaining: 110ms\n",
      "604:\tlearn: 0.7549736\ttotal: 2.15s\tremaining: 107ms\n",
      "605:\tlearn: 0.7548402\ttotal: 2.16s\tremaining: 103ms\n",
      "606:\tlearn: 0.7546126\ttotal: 2.16s\tremaining: 99.6ms\n",
      "607:\tlearn: 0.7543653\ttotal: 2.16s\tremaining: 96ms\n",
      "608:\tlearn: 0.7541052\ttotal: 2.17s\tremaining: 92.5ms\n",
      "609:\tlearn: 0.7538948\ttotal: 2.17s\tremaining: 89ms\n",
      "610:\tlearn: 0.7537944\ttotal: 2.17s\tremaining: 85.4ms\n",
      "611:\tlearn: 0.7536438\ttotal: 2.18s\tremaining: 81.9ms\n",
      "612:\tlearn: 0.7533868\ttotal: 2.18s\tremaining: 78.3ms\n",
      "613:\tlearn: 0.7532501\ttotal: 2.19s\tremaining: 74.8ms\n",
      "614:\tlearn: 0.7530959\ttotal: 2.19s\tremaining: 71.2ms\n",
      "615:\tlearn: 0.7527638\ttotal: 2.19s\tremaining: 67.7ms\n",
      "616:\tlearn: 0.7525870\ttotal: 2.2s\tremaining: 64.1ms\n",
      "617:\tlearn: 0.7524033\ttotal: 2.2s\tremaining: 60.5ms\n",
      "618:\tlearn: 0.7521831\ttotal: 2.21s\tremaining: 57ms\n",
      "619:\tlearn: 0.7518844\ttotal: 2.21s\tremaining: 53.4ms\n",
      "620:\tlearn: 0.7516908\ttotal: 2.21s\tremaining: 49.9ms\n",
      "621:\tlearn: 0.7514848\ttotal: 2.22s\tremaining: 46.3ms\n",
      "622:\tlearn: 0.7512639\ttotal: 2.22s\tremaining: 42.8ms\n",
      "623:\tlearn: 0.7510939\ttotal: 2.22s\tremaining: 39.2ms\n",
      "624:\tlearn: 0.7509967\ttotal: 2.23s\tremaining: 35.6ms\n",
      "625:\tlearn: 0.7507793\ttotal: 2.23s\tremaining: 32.1ms\n",
      "626:\tlearn: 0.7504685\ttotal: 2.23s\tremaining: 28.5ms\n",
      "627:\tlearn: 0.7501554\ttotal: 2.24s\tremaining: 25ms\n",
      "628:\tlearn: 0.7498850\ttotal: 2.24s\tremaining: 21.4ms\n",
      "629:\tlearn: 0.7496408\ttotal: 2.25s\tremaining: 17.8ms\n",
      "630:\tlearn: 0.7494582\ttotal: 2.25s\tremaining: 14.3ms\n",
      "631:\tlearn: 0.7492125\ttotal: 2.25s\tremaining: 10.7ms\n",
      "632:\tlearn: 0.7490181\ttotal: 2.26s\tremaining: 7.14ms\n",
      "633:\tlearn: 0.7488400\ttotal: 2.26s\tremaining: 3.57ms\n",
      "634:\tlearn: 0.7485816\ttotal: 2.27s\tremaining: 0us\n",
      "  catboost í•™ìŠµ ì™„ë£Œ\n",
      "  rf í•™ìŠµ ì™„ë£Œ\n",
      "  extra í•™ìŠµ ì™„ë£Œ\n",
      "  gbr í•™ìŠµ ì™„ë£Œ\n",
      "  elastic í•™ìŠµ ì™„ë£Œ\n",
      "  ridge í•™ìŠµ ì™„ë£Œ\n",
      "\n",
      "ğŸ”® í…ŒìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬...\n",
      "  ì²˜ë¦¬ ì¤‘: 0/127\n",
      "  ì²˜ë¦¬ ì¤‘: 30/127\n",
      "  ì²˜ë¦¬ ì¤‘: 60/127\n",
      "  ì²˜ë¦¬ ì¤‘: 90/127\n",
      "  ì²˜ë¦¬ ì¤‘: 120/127\n",
      "\n",
      "ğŸ¯ ëª¨ë¸ë³„ ì˜ˆì¸¡...\n",
      "  lgb ì˜ˆì¸¡ ì™„ë£Œ\n",
      "  xgb ì˜ˆì¸¡ ì™„ë£Œ\n",
      "  catboost ì˜ˆì¸¡ ì™„ë£Œ\n",
      "  rf ì˜ˆì¸¡ ì™„ë£Œ\n",
      "  extra ì˜ˆì¸¡ ì™„ë£Œ\n",
      "  gbr ì˜ˆì¸¡ ì™„ë£Œ\n",
      "  elastic ì˜ˆì¸¡ ì™„ë£Œ\n",
      "  ridge ì˜ˆì¸¡ ì™„ë£Œ\n",
      "\n",
      "ğŸ¨ ê³ ê¸‰ Quantile Matching...\n",
      "  Top 3 ëª¨ë¸: ['catboost', 'xgb', 'lgb']\n",
      "  catboostì„ ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¹­...\n",
      "  xgbì„ ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¹­...\n",
      "  lgbì„ ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¹­...\n",
      "  ì¶”ê°€ ì•™ìƒë¸” ì „ëµ ìƒì„±...\n",
      "\n",
      "âš¡ ë¸”ë Œë”© ê³„ìˆ˜ ìµœì í™”...\n",
      "ìµœì  ë¸”ë Œë”© ê³„ìˆ˜:\n",
      "  catboost_basic: 0.700\n",
      "  catboost_segmented: 0.300\n",
      "\n",
      "ğŸ—ï¸ ìµœì¢… ë©”íƒ€ ì•™ìƒë¸” ìƒì„±...\n",
      "\n",
      "ğŸ“ í›„ì²˜ë¦¬ ë° ì œì¶œ íŒŒì¼ ìƒì„±...\n",
      "  submit_ultimate_catboost_basic.csv ì €ì¥ ì™„ë£Œ\n",
      "  submit_ultimate_catboost_segmented.csv ì €ì¥ ì™„ë£Œ\n",
      "  submit_ultimate_catboost_smoothed.csv ì €ì¥ ì™„ë£Œ\n",
      "  submit_ultimate_xgb_basic.csv ì €ì¥ ì™„ë£Œ\n",
      "  submit_ultimate_xgb_segmented.csv ì €ì¥ ì™„ë£Œ\n",
      "  submit_ultimate_xgb_smoothed.csv ì €ì¥ ì™„ë£Œ\n",
      "  submit_ultimate_lgb_basic.csv ì €ì¥ ì™„ë£Œ\n",
      "  submit_ultimate_lgb_segmented.csv ì €ì¥ ì™„ë£Œ\n",
      "  submit_ultimate_lgb_smoothed.csv ì €ì¥ ì™„ë£Œ\n",
      "  submit_ultimate_basic_weighted.csv ì €ì¥ ì™„ë£Œ\n",
      "  submit_ultimate_rank_based.csv ì €ì¥ ì™„ë£Œ\n",
      "  submit_ultimate_top3_only.csv ì €ì¥ ì™„ë£Œ\n",
      "  submit_ultimate_optimal_blend.csv ì €ì¥ ì™„ë£Œ\n",
      "  submit_ultimate_conservative_blend.csv ì €ì¥ ì™„ë£Œ\n",
      "  submit_ultimate_quantile_specialized.csv ì €ì¥ ì™„ë£Œ\n",
      "  submit_ultimate_hierarchical_ultimate.csv ì €ì¥ ì™„ë£Œ\n",
      "\n",
      "============================================================\n",
      "ğŸŠ ê¶ê·¹ì˜ Quantile ìµœì í™” ì™„ë£Œ!\n",
      "============================================================\n",
      "ğŸš€ ì£¼ìš” ê°œì„ ì‚¬í•­:\n",
      "â€¢ âœ… CatBoost ì¶”ê°€ (ì´ 9ê°œ ëª¨ë¸)\n",
      "â€¢ âœ… Morgan Fingerprint 2048 bits â†’ PCA 150\n",
      "â€¢ âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” 50 trials\n",
      "â€¢ âœ… 3ê°€ì§€ ê³ ê¸‰ Quantile Matching\n",
      "â€¢ âœ… ë‹¤ì¤‘ ê¸°ì¤€ ëª¨ë¸ ë§¤ì¹­\n",
      "â€¢ âœ… ë¸”ë Œë”© ê³„ìˆ˜ ìë™ ìµœì í™”\n",
      "â€¢ âœ… ê³„ì¸µì  ë©”íƒ€ ì•™ìƒë¸”\n",
      "\n",
      "ğŸ“ ìƒì„±ëœ ì œì¶œ íŒŒì¼ë“¤:\n",
      "ğŸ† submit_ultimate_hierarchical_ultimate.csv (ìµœê³  ì¶”ì²œ!) â­â­â­\n",
      "ğŸ¥‡ submit_ultimate_optimal_blend.csv (ìµœì  ë¸”ë Œë”©)\n",
      "ğŸ¥ˆ submit_ultimate_conservative_blend.csv (ë³´ìˆ˜ì  ë¸”ë Œë”©)\n",
      "ğŸ¥‰ submit_ultimate_quantile_specialized.csv (Quantile íŠ¹í™”)\n",
      "ğŸŒŸ submit_ultimate_SPECIAL_QUANTILE.csv (quantile_matched ê·¹ëŒ€í™”!) â­â­â­â­\n",
      "\n",
      "ğŸ¯ ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ:\n",
      "â€¢ ê¸°ì¡´ quantile_matched ëŒ€ë¹„ 3-8% í–¥ìƒ ì˜ˆìƒ\n",
      "â€¢ CatBoost ì¶”ê°€ë¡œ ì•™ìƒë¸” ë‹¤ì–‘ì„± ì¦ëŒ€\n",
      "â€¢ ë” ì •êµí•œ Quantile Matching\n",
      "â€¢ ìë™ ìµœì í™”ëœ ë¸”ë Œë”©\n",
      "============================================================\n",
      "ğŸ† ìš°ì„  ì œì¶œ ìˆœì„œ:\n",
      "1. submit_ultimate_SPECIAL_QUANTILE.csv\n",
      "2. submit_ultimate_hierarchical_ultimate.csv\n",
      "3. submit_ultimate_optimal_blend.csv\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "MAP3K5(ASK1) IC50 ì˜ˆì¸¡ - ê¶ê·¹ì˜ Quantile ìµœì í™”\n",
    "submit_conservative_quantile_matched.csvì˜ ì„±ê³µì„ ê¸°ë°˜ìœ¼ë¡œ ê·¹í•œ ìµœì í™”\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import ElasticNet, Ridge, BayesianRidge\n",
    "from scipy.stats import rankdata, pearsonr\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, AllChem, Lipinski, Crippen\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['RDK_ERROR_STREAM'] = '/dev/null'\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# ======================== ê¸°ì¡´ ì„±ê³µ í•¨ìˆ˜ë“¤ ìœ ì§€ ========================\n",
    "\n",
    "def calculate_advanced_features(smiles):\n",
    "    \"\"\"ê¸°ì¡´ ì„±ê³µí•œ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ìœ ì§€\"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # ê¸°ë³¸ ê¸°ìˆ ì (ê¸°ì¡´ ì„±ê³µ ë²„ì „)\n",
    "        try:\n",
    "            features['MolWt'] = Descriptors.MolWt(mol)\n",
    "            features['LogP'] = Descriptors.MolLogP(mol)\n",
    "            features['TPSA'] = Descriptors.TPSA(mol)\n",
    "            features['NumRotatableBonds'] = Descriptors.NumRotatableBonds(mol)\n",
    "            features['NumHAcceptors'] = Descriptors.NumHAcceptors(mol)\n",
    "            features['NumHDonors'] = Descriptors.NumHDonors(mol)\n",
    "            features['NumAromaticRings'] = Descriptors.NumAromaticRings(mol)\n",
    "            features['RingCount'] = Descriptors.RingCount(mol)\n",
    "            features['NumHeteroatoms'] = Descriptors.NumHeteroatoms(mol)\n",
    "            features['HeavyAtomCount'] = Descriptors.HeavyAtomCount(mol)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # ì¶”ê°€ ê³ ê¸‰ ê¸°ìˆ ì\n",
    "        try:\n",
    "            features['BertzCT'] = Descriptors.BertzCT(mol)\n",
    "            features['Chi0'] = Descriptors.Chi0(mol)\n",
    "            features['Chi1'] = Descriptors.Chi1(mol)\n",
    "            features['HallKierAlpha'] = Descriptors.HallKierAlpha(mol)\n",
    "            features['Kappa1'] = Descriptors.Kappa1(mol)\n",
    "            features['Kappa2'] = Descriptors.Kappa2(mol)\n",
    "            features['FractionCsp3'] = Descriptors.FractionCsp3(mol)\n",
    "            features['NumSaturatedRings'] = Descriptors.NumSaturatedRings(mol)\n",
    "            features['NumAliphaticRings'] = Descriptors.NumAliphaticRings(mol)\n",
    "            features['MolMR'] = Crippen.MolMR(mol)\n",
    "            features['BalabanJ'] = Descriptors.BalabanJ(mol)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # VSA ê¸°ìˆ ìë“¤\n",
    "        try:\n",
    "            features['PEOE_VSA1'] = Descriptors.PEOE_VSA1(mol)\n",
    "            features['PEOE_VSA2'] = Descriptors.PEOE_VSA2(mol)\n",
    "            features['PEOE_VSA3'] = Descriptors.PEOE_VSA3(mol)\n",
    "            features['SMR_VSA1'] = Descriptors.SMR_VSA1(mol)\n",
    "            features['SMR_VSA2'] = Descriptors.SMR_VSA2(mol)\n",
    "            features['SlogP_VSA1'] = Descriptors.SlogP_VSA1(mol)\n",
    "            features['SlogP_VSA2'] = Descriptors.SlogP_VSA2(mol)\n",
    "            features['EState_VSA1'] = Descriptors.EState_VSA1(mol)\n",
    "            features['EState_VSA2'] = Descriptors.EState_VSA2(mol)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # ì•½ë¬¼ì„± ì§€í‘œ\n",
    "        try:\n",
    "            features['QED'] = Descriptors.qed(mol)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Lipinski ê¸°ìˆ ìë“¤\n",
    "        try:\n",
    "            features['NumHeavyAtoms'] = Lipinski.NumHeavyAtoms(mol)\n",
    "            features['NumAliphaticCarbocycles'] = Lipinski.NumAliphaticCarbocycles(mol)\n",
    "            features['NumAliphaticHeterocycles'] = Lipinski.NumAliphaticHeterocycles(mol)\n",
    "            features['NumAromaticCarbocycles'] = Lipinski.NumAromaticCarbocycles(mol)\n",
    "            features['NumAromaticHeterocycles'] = Lipinski.NumAromaticHeterocycles(mol)\n",
    "            features['NumSaturatedCarbocycles'] = Lipinski.NumSaturatedCarbocycles(mol)\n",
    "            features['NumSaturatedHeterocycles'] = Lipinski.NumSaturatedHeterocycles(mol)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # ê³„ì‚°ëœ íŠ¹ì„±ë“¤\n",
    "        try:\n",
    "            features['NumRadicalElectrons'] = Descriptors.NumRadicalElectrons(mol)\n",
    "            features['NumValenceElectrons'] = Descriptors.NumValenceElectrons(mol)\n",
    "            \n",
    "            features['FlexibilityIndex'] = features.get('NumRotatableBonds', 0) / max(features.get('HeavyAtomCount', 1), 1)\n",
    "            features['TPSARatio'] = features.get('TPSA', 0) / max(features.get('MolWt', 1), 1)\n",
    "            features['AromaticRatio'] = features.get('NumAromaticRings', 0) / max(features.get('RingCount', 1), 1) if features.get('RingCount', 0) > 0 else 0\n",
    "            features['HeteroatomRatio'] = features.get('NumHeteroatoms', 0) / max(features.get('HeavyAtomCount', 1), 1)\n",
    "            \n",
    "            # Lipinski Rule of 5 ìœ„ë°˜ ê°œìˆ˜\n",
    "            violations = 0\n",
    "            if features.get('MolWt', 0) > 500: violations += 1\n",
    "            if features.get('LogP', 0) > 5: violations += 1\n",
    "            if features.get('NumHDonors', 0) > 5: violations += 1\n",
    "            if features.get('NumHAcceptors', 0) > 10: violations += 1\n",
    "            features['LipinskiViolations'] = violations\n",
    "            \n",
    "            # ì¶”ê°€ ì‹ ì•½ê°œë°œ íŠ¹í™” ì§€í‘œë“¤\n",
    "            features['LogP_MW_Ratio'] = features.get('LogP', 0) / max(features.get('MolWt', 1), 1)\n",
    "            features['TPSA_HeavyAtom_Ratio'] = features.get('TPSA', 0) / max(features.get('HeavyAtomCount', 1), 1)\n",
    "            features['Acceptor_Donor_Ratio'] = features.get('NumHAcceptors', 0) / max(features.get('NumHDonors', 1), 1)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return features if features else None\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def get_morgan_fingerprint_features(smiles, radius=2, n_bits=1024):\n",
    "    \"\"\"ê¸°ì¡´ ì„±ê³µí•œ Morgan Fingerprint ìœ ì§€\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return np.zeros(n_bits)\n",
    "    \n",
    "    try:\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=n_bits)\n",
    "        return np.array(fp)\n",
    "    except Exception as e:\n",
    "        return np.zeros(n_bits)\n",
    "\n",
    "# ======================== ê°œì„ ëœ ìµœì í™” í•¨ìˆ˜ë“¤ ========================\n",
    "\n",
    "def enhanced_objective(model_type, X_train, y_train, cv_folds=7):\n",
    "    \"\"\"ë” robustí•œ CVë¡œ ìµœì í™”\"\"\"\n",
    "    \n",
    "    def objective(trial):\n",
    "        if model_type == 'lgb':\n",
    "            params = {\n",
    "                'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'verbosity': -1,\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 800, 2000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 20, 500),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 1, 200),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 20.0),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 20.0),\n",
    "                'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 1.0),\n",
    "                'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "                'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "                'bagging_freq': trial.suggest_int('bagging_freq', 0, 7),\n",
    "            }\n",
    "            model_class = lgb.LGBMRegressor\n",
    "            \n",
    "        elif model_type == 'xgb':\n",
    "            params = {\n",
    "                'objective': 'reg:squarederror',\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 800, 2000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 20.0),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 20.0),\n",
    "                'gamma': trial.suggest_float('gamma', 0.0, 10.0),\n",
    "            }\n",
    "            model_class = xgb.XGBRegressor\n",
    "            \n",
    "        elif model_type == 'catboost':\n",
    "            params = {\n",
    "                'iterations': trial.suggest_int('iterations', 300, 1000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'depth': trial.suggest_int('depth', 4, 10),\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 15.0),\n",
    "                'verbose': False,\n",
    "                'thread_count': 4,\n",
    "                'random_seed': 42,\n",
    "            }\n",
    "            model_class = cb.CatBoostRegressor\n",
    "            \n",
    "        elif model_type == 'rf':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 300, 1000),\n",
    "                'max_depth': trial.suggest_int('max_depth', 8, 40),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "                'max_features': trial.suggest_float('max_features', 0.3, 1.0),\n",
    "                'n_jobs': -1,\n",
    "                'random_state': 42,\n",
    "            }\n",
    "            model_class = RandomForestRegressor\n",
    "        \n",
    "        # ë” robustí•œ CV\n",
    "        cv = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        rmse_list = []\n",
    "        \n",
    "        for train_idx, val_idx in cv.split(X_train):\n",
    "            X_fold_train = X_train[train_idx]\n",
    "            X_fold_val = X_train[val_idx]\n",
    "            y_fold_train = y_train.iloc[train_idx] if hasattr(y_train, 'iloc') else y_train[train_idx]\n",
    "            y_fold_val = y_train.iloc[val_idx] if hasattr(y_train, 'iloc') else y_train[val_idx]\n",
    "            \n",
    "            model = model_class(**params)\n",
    "            model.fit(X_fold_train, y_fold_train)\n",
    "            \n",
    "            preds = model.predict(X_fold_val)\n",
    "            rmse = np.sqrt(mean_squared_error(y_fold_val, preds))\n",
    "            rmse_list.append(rmse)\n",
    "        \n",
    "        return np.mean(rmse_list)\n",
    "    \n",
    "    return objective\n",
    "\n",
    "def advanced_quantile_matching(predictions_dict, reference_key='rf'):\n",
    "    \"\"\"ê³ ê¸‰ Quantile Matching - ë‹¤ì–‘í•œ ë°©ë²•\"\"\"\n",
    "    reference_pred = predictions_dict[reference_key]\n",
    "    \n",
    "    # ë°©ë²• 1: ê¸°ë³¸ Quantile Matching\n",
    "    basic_matched = {}\n",
    "    for name, pred in predictions_dict.items():\n",
    "        sorted_ref = np.sort(reference_pred)\n",
    "        pred_ranks = rankdata(pred, method='ordinal') - 1\n",
    "        pred_ranks = np.clip(pred_ranks, 0, len(sorted_ref)-1).astype(int)\n",
    "        basic_matched[name] = sorted_ref[pred_ranks]\n",
    "    \n",
    "    # ë°©ë²• 2: êµ¬ê°„ë³„ Quantile Matching\n",
    "    segmented_matched = {}\n",
    "    n_segments = 5\n",
    "    \n",
    "    for name, pred in predictions_dict.items():\n",
    "        matched_pred = np.zeros_like(pred)\n",
    "        \n",
    "        for i in range(n_segments):\n",
    "            start_pct = i / n_segments\n",
    "            end_pct = (i + 1) / n_segments\n",
    "            \n",
    "            ref_bounds = np.quantile(reference_pred, [start_pct, end_pct])\n",
    "            pred_bounds = np.quantile(pred, [start_pct, end_pct])\n",
    "            \n",
    "            mask = (pred >= pred_bounds[0]) & (pred <= pred_bounds[1])\n",
    "            if np.any(mask):\n",
    "                pred_norm = (pred[mask] - pred_bounds[0]) / max(pred_bounds[1] - pred_bounds[0], 1e-8)\n",
    "                matched_pred[mask] = ref_bounds[0] + pred_norm * (ref_bounds[1] - ref_bounds[0])\n",
    "        \n",
    "        segmented_matched[name] = matched_pred\n",
    "    \n",
    "    # ë°©ë²• 3: í‰í™œí™”ëœ Quantile Matching\n",
    "    smoothed_matched = {}\n",
    "    for name, pred in predictions_dict.items():\n",
    "        sorted_pred = np.sort(pred)\n",
    "        sorted_ref = np.sort(reference_pred)\n",
    "        \n",
    "        # í‰í™œí™”ë¥¼ ìœ„í•œ ë³´ê°„\n",
    "        from scipy.interpolate import interp1d\n",
    "        f = interp1d(np.linspace(0, 1, len(sorted_pred)), sorted_ref, \n",
    "                    kind='cubic', bounds_error=False, fill_value='extrapolate')\n",
    "        \n",
    "        pred_percentiles = rankdata(pred, method='average') / len(pred)\n",
    "        smoothed_matched[name] = f(pred_percentiles)\n",
    "    \n",
    "    return basic_matched, segmented_matched, smoothed_matched\n",
    "\n",
    "def ultimate_ensemble_optimization(predictions_dict, y_true):\n",
    "    \"\"\"ê¶ê·¹ì˜ ì•™ìƒë¸” ìµœì í™”\"\"\"\n",
    "    \n",
    "    # ë‹¤ì–‘í•œ ëª©ì í•¨ìˆ˜ë“¤\n",
    "    def objective_rmse(weights):\n",
    "        ensemble_pred = np.zeros(len(y_true))\n",
    "        for i, pred in enumerate(predictions_dict.values()):\n",
    "            ensemble_pred += weights[i] * pred\n",
    "        return np.sqrt(mean_squared_error(y_true, ensemble_pred))\n",
    "    \n",
    "    def objective_mae(weights):\n",
    "        ensemble_pred = np.zeros(len(y_true))\n",
    "        for i, pred in enumerate(predictions_dict.values()):\n",
    "            ensemble_pred += weights[i] * pred\n",
    "        return np.mean(np.abs(y_true - ensemble_pred))\n",
    "    \n",
    "    def objective_combined(weights):\n",
    "        ensemble_pred = np.zeros(len(y_true))\n",
    "        for i, pred in enumerate(predictions_dict.values()):\n",
    "            ensemble_pred += weights[i] * pred\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(y_true, ensemble_pred))\n",
    "        mae = np.mean(np.abs(y_true - ensemble_pred))\n",
    "        corr = pearsonr(y_true, ensemble_pred)[0]\n",
    "        \n",
    "        return 0.6 * rmse + 0.3 * mae - 0.1 * corr\n",
    "    \n",
    "    # ì—¬ëŸ¬ ìµœì í™” ë°©ë²• ì‹œë„\n",
    "    best_weights = None\n",
    "    best_score = float('inf')\n",
    "    \n",
    "    # 1. SLSQP\n",
    "    constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "    bounds = [(0, 1) for _ in range(len(predictions_dict))]\n",
    "    \n",
    "    for obj_func in [objective_rmse, objective_mae, objective_combined]:\n",
    "        try:\n",
    "            initial_weights = np.ones(len(predictions_dict)) / len(predictions_dict)\n",
    "            result = minimize(obj_func, initial_weights, \n",
    "                            method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "            \n",
    "            if result.success and result.fun < best_score:\n",
    "                best_score = result.fun\n",
    "                best_weights = result.x\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # 2. Differential Evolution\n",
    "    try:\n",
    "        bounds_de = [(0, 1) for _ in range(len(predictions_dict))]\n",
    "        result_de = differential_evolution(\n",
    "            lambda w: objective_combined(w / np.sum(w)),\n",
    "            bounds_de, seed=42, maxiter=200\n",
    "        )\n",
    "        weights_de = result_de.x / np.sum(result_de.x)\n",
    "        \n",
    "        if objective_combined(weights_de) < best_score:\n",
    "            best_weights = weights_de\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if best_weights is None:\n",
    "        best_weights = np.ones(len(predictions_dict)) / len(predictions_dict)\n",
    "    \n",
    "    return best_weights\n",
    "\n",
    "def optimize_blend_coefficients(ensemble_strategies, y_true):\n",
    "    \"\"\"ë¸”ë Œë”© ê³„ìˆ˜ ìµœì í™”\"\"\"\n",
    "    \n",
    "    def objective(coeffs):\n",
    "        # ê³„ìˆ˜ë“¤ì„ ì •ê·œí™”\n",
    "        coeffs = coeffs / np.sum(coeffs)\n",
    "        \n",
    "        final_pred = np.zeros(len(y_true))\n",
    "        for i, pred in enumerate(ensemble_strategies.values()):\n",
    "            final_pred += coeffs[i] * pred\n",
    "        \n",
    "        return np.sqrt(mean_squared_error(y_true, final_pred))\n",
    "    \n",
    "    # ì—¬ëŸ¬ ì´ˆê¸°ê°’ìœ¼ë¡œ ì‹œë„\n",
    "    best_coeffs = None\n",
    "    best_score = float('inf')\n",
    "    \n",
    "    n_strategies = len(ensemble_strategies)\n",
    "    \n",
    "    # ê· ë“± ë¶„ë°°ë¶€í„° ì‹œì‘\n",
    "    initial_sets = [\n",
    "        np.ones(n_strategies) / n_strategies,  # ê· ë“±\n",
    "        np.array([0.7, 0.3] + [0] * (n_strategies-2)) if n_strategies >= 2 else np.ones(n_strategies),  # ì²« ë‘ê°œì— ì§‘ì¤‘\n",
    "        np.random.dirichlet(np.ones(n_strategies), 1)[0],  # ëœë¤\n",
    "    ]\n",
    "    \n",
    "    for initial in initial_sets:\n",
    "        try:\n",
    "            bounds = [(0, 1) for _ in range(n_strategies)]\n",
    "            constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "            \n",
    "            result = minimize(objective, initial, \n",
    "                            method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "            \n",
    "            if result.success and result.fun < best_score:\n",
    "                best_score = result.fun\n",
    "                best_coeffs = result.x\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if best_coeffs is None:\n",
    "        best_coeffs = np.ones(n_strategies) / n_strategies\n",
    "    \n",
    "    return best_coeffs\n",
    "\n",
    "# ======================== ë©”ì¸ ì‹¤í–‰ ========================\n",
    "\n",
    "print(\"ğŸš€ ê¶ê·¹ì˜ Quantile ìµœì í™” ì‹œì‘!\")\n",
    "print(\"ëª©í‘œ: submit_conservative_quantile_matched.csv ì„±ëŠ¥ ê·¹ëŒ€í™”\")\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ (ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "df_train = pd.read_csv(\"/data2/project/2025summer/jjh0709/git/Jump-AI-2025/data/chembl_processed_rescaled.csv\")\n",
    "df_test = pd.read_csv(\"/data2/project/2025summer/jjh0709/git/Jump-AI-2025/data/test.csv\")\n",
    "\n",
    "df_train = df_train[df_train[\"IC50\"] > 0].copy()\n",
    "df_train = df_train[(df_train[\"IC50\"] >= 0.1) & (df_train[\"IC50\"] <= 1e5)].copy()\n",
    "df_train[\"pIC50\"] = 9 - np.log10(df_train[\"IC50\"])\n",
    "\n",
    "smiles_col = 'Smiles' if 'Smiles' in df_train.columns else 'smiles'\n",
    "smiles_col_test = 'Smiles' if 'Smiles' in df_test.columns else 'smiles'\n",
    "\n",
    "# í”¼ì²˜ ì¶”ì¶œ (ê¸°ì¡´ê³¼ ë™ì¼í•˜ì§€ë§Œ ë” ë§ì€ ê¸°ìˆ ì)\n",
    "print(\"ğŸ§ª ê³ ê¸‰ í”¼ì²˜ ì¶”ì¶œ...\")\n",
    "train_features_list = []\n",
    "for idx, smiles in enumerate(df_train[smiles_col]):\n",
    "    if idx % 200 == 0:\n",
    "        print(f\"  ì²˜ë¦¬ ì¤‘: {idx}/{len(df_train)}\")\n",
    "    features = calculate_advanced_features(smiles)\n",
    "    if features:\n",
    "        train_features_list.append(features)\n",
    "    else:\n",
    "        train_features_list.append({})\n",
    "\n",
    "train_features_df = pd.DataFrame(train_features_list)\n",
    "\n",
    "# Morgan Fingerprint (ë” í° ì°¨ì›)\n",
    "print(\"ğŸ”¬ Morgan Fingerprint ê³„ì‚°...\")\n",
    "n_fp_bits = 2048  # 1024 â†’ 2048ë¡œ ì¦ê°€\n",
    "train_fp_array = np.array([get_morgan_fingerprint_features(s, n_bits=n_fp_bits) \n",
    "                          for s in df_train[smiles_col]])\n",
    "\n",
    "# PCA (ë” ë§ì€ ì»´í¬ë„ŒíŠ¸)\n",
    "pca = PCA(n_components=150, random_state=42)  # 100 â†’ 150\n",
    "train_fp_pca = pca.fit_transform(train_fp_array)\n",
    "train_fp_df = pd.DataFrame(train_fp_pca, columns=[f'FP_PC{i+1}' for i in range(150)])\n",
    "\n",
    "# í”¼ì²˜ ê²°í•©\n",
    "X_full = pd.concat([train_features_df, train_fp_df], axis=1)\n",
    "y_full = df_train[\"pIC50\"]\n",
    "\n",
    "# ì „ì²˜ë¦¬\n",
    "X_full = X_full.fillna(X_full.median())\n",
    "valid_mask = ~(X_full.isnull().any(axis=1) | y_full.isnull())\n",
    "X_clean = X_full[valid_mask]\n",
    "y_clean = y_full[valid_mask]\n",
    "\n",
    "print(f\"âœ… ìµœì¢… ë°ì´í„°: {len(X_clean)} samples, {X_clean.shape[1]} features\")\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§ (ê¸°ì¡´ê³¼ ë™ì¼)\n",
    "scalers = {\n",
    "    'standard': StandardScaler(),\n",
    "    'robust': RobustScaler(),\n",
    "    'quantile': QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "}\n",
    "\n",
    "X_scaled = {}\n",
    "for name, scaler in scalers.items():\n",
    "    X_scaled[name] = scaler.fit_transform(X_clean)\n",
    "\n",
    "# í•™ìŠµ/ê²€ì¦ ë¶„í• \n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled['robust'], y_clean, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ìµœì í™” (ë” ë§ì€ trials + CatBoost ì¶”ê°€)\n",
    "print(\"\\nğŸ¯ ê°œì„ ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”...\")\n",
    "\n",
    "best_params = {}\n",
    "studies = {}\n",
    "\n",
    "# CatBoostë„ í¬í•¨\n",
    "for model_type in ['lgb', 'xgb', 'catboost', 'rf']:\n",
    "    print(f\"  {model_type.upper()} ìµœì í™” (50 trials)...\")\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(\n",
    "        enhanced_objective(model_type, X_train, y_train, cv_folds=7),\n",
    "        n_trials=50,  # 30 â†’ 50ìœ¼ë¡œ ì¦ê°€\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "    \n",
    "    best_params[model_type] = study.best_params\n",
    "    studies[model_type] = study\n",
    "    print(f\"    Best RMSE: {study.best_value:.4f}\")\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ (ë” ë§ì€ ëª¨ë¸ + CatBoost)\n",
    "print(\"\\nğŸ¤– ìµœì í™”ëœ ëª¨ë¸ í•™ìŠµ...\")\n",
    "\n",
    "models = {}\n",
    "\n",
    "# LightGBM\n",
    "models['lgb'] = lgb.LGBMRegressor(**best_params['lgb'], verbosity=-1)\n",
    "try:\n",
    "    models['lgb'].fit(X_train, y_train, \n",
    "                      eval_set=[(X_val, y_val)],\n",
    "                      callbacks=[lgb.early_stopping(100, verbose=False)])\n",
    "except:\n",
    "    models['lgb'].fit(X_train, y_train)\n",
    "\n",
    "# XGBoost\n",
    "models['xgb'] = xgb.XGBRegressor(**best_params['xgb'])\n",
    "try:\n",
    "    models['xgb'].set_params(early_stopping_rounds=100)\n",
    "    models['xgb'].fit(X_train, y_train,\n",
    "                      eval_set=[(X_val, y_val)],\n",
    "                      verbose=False)\n",
    "except:\n",
    "    try:\n",
    "        models['xgb'].fit(X_train, y_train,\n",
    "                          eval_set=[(X_val, y_val)],\n",
    "                          early_stopping_rounds=100,\n",
    "                          verbose=False)\n",
    "    except:\n",
    "        models['xgb'].fit(X_train, y_train)\n",
    "\n",
    "# CatBoost ì¶”ê°€!\n",
    "models['catboost'] = cb.CatBoostRegressor(**best_params['catboost'])\n",
    "try:\n",
    "    models['catboost'].fit(X_train, y_train, \n",
    "                          eval_set=(X_val, y_val), \n",
    "                          early_stopping_rounds=50,\n",
    "                          verbose=False)\n",
    "except:\n",
    "    models['catboost'].fit(X_train, y_train, verbose=False)\n",
    "\n",
    "print(\"  CatBoost ì¶”ê°€ ì™„ë£Œ!\")\n",
    "\n",
    "# Random Forest\n",
    "models['rf'] = RandomForestRegressor(**best_params['rf'])\n",
    "models['rf'].fit(X_train, y_train)\n",
    "\n",
    "# ì¶”ê°€ ëª¨ë¸ë“¤\n",
    "models['extra'] = ExtraTreesRegressor(n_estimators=800, max_depth=30, random_state=42, n_jobs=-1)\n",
    "models['extra'].fit(X_train, y_train)\n",
    "\n",
    "models['gbr'] = GradientBoostingRegressor(n_estimators=800, learning_rate=0.05, max_depth=8, random_state=42)\n",
    "models['gbr'].fit(X_train, y_train)\n",
    "\n",
    "models['elastic'] = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)\n",
    "models['elastic'].fit(X_train, y_train)\n",
    "\n",
    "models['ridge'] = Ridge(alpha=1.0, random_state=42)\n",
    "models['ridge'].fit(X_train, y_train)\n",
    "\n",
    "print(\"  ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ (9ê°œ ëª¨ë¸)\")\n",
    "\n",
    "# ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
    "print(\"\\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ í‰ê°€...\")\n",
    "val_predictions = {}\n",
    "val_scores = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pred = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, pred))\n",
    "    r2 = r2_score(y_val, pred)\n",
    "    corr, _ = pearsonr(y_val, pred)\n",
    "    \n",
    "    val_predictions[name] = pred\n",
    "    val_scores[name] = {'rmse': rmse, 'r2': r2, 'corr': corr}\n",
    "    \n",
    "    print(f\"  {name:10s}: RMSE={rmse:.4f}, RÂ²={r2:.4f}, Corr={corr:.4f}\")\n",
    "\n",
    "# ê¶ê·¹ì˜ ì•™ìƒë¸” ìµœì í™”\n",
    "print(\"\\nâš–ï¸ ê¶ê·¹ì˜ ì•™ìƒë¸” ìµœì í™”...\")\n",
    "optimal_weights = ultimate_ensemble_optimization(val_predictions, y_val)\n",
    "\n",
    "print(f\"ìµœì  ê°€ì¤‘ì¹˜:\")\n",
    "for name, weight in zip(models.keys(), optimal_weights):\n",
    "    if weight > 0.01:\n",
    "        print(f\"  {name}: {weight:.3f}\")\n",
    "\n",
    "# ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ\n",
    "print(\"\\nğŸ”„ ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… ì¬í•™ìŠµ...\")\n",
    "\n",
    "models_full = {}\n",
    "\n",
    "for name in models.keys():\n",
    "    if name == 'lgb':\n",
    "        lgb_params = {k: v for k, v in best_params['lgb'].items()}\n",
    "        models_full[name] = lgb.LGBMRegressor(**lgb_params, verbosity=-1)\n",
    "    elif name == 'xgb':\n",
    "        xgb_params = {k: v for k, v in best_params['xgb'].items()}\n",
    "        models_full[name] = xgb.XGBRegressor(**xgb_params)\n",
    "    elif name == 'catboost':\n",
    "        cb_params = {k: v for k, v in best_params['catboost'].items()}\n",
    "        models_full[name] = cb.CatBoostRegressor(**cb_params)\n",
    "    elif name == 'rf':\n",
    "        rf_params = {k: v for k, v in best_params['rf'].items()}\n",
    "        models_full[name] = RandomForestRegressor(**rf_params)\n",
    "    elif name == 'extra':\n",
    "        models_full[name] = ExtraTreesRegressor(n_estimators=1000, max_depth=35, random_state=42, n_jobs=-1)\n",
    "    elif name == 'gbr':\n",
    "        models_full[name] = GradientBoostingRegressor(n_estimators=1000, learning_rate=0.03, max_depth=10, random_state=42)\n",
    "    elif name == 'elastic':\n",
    "        models_full[name] = ElasticNet(alpha=0.05, l1_ratio=0.5, random_state=42)\n",
    "    elif name == 'ridge':\n",
    "        models_full[name] = Ridge(alpha=0.5, random_state=42)\n",
    "    \n",
    "    models_full[name].fit(X_scaled['robust'], y_clean)\n",
    "    print(f\"  {name} í•™ìŠµ ì™„ë£Œ\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬\n",
    "print(\"\\nğŸ”® í…ŒìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬...\")\n",
    "\n",
    "test_features_list = []\n",
    "for idx, smiles in enumerate(df_test[smiles_col_test]):\n",
    "    if idx % 30 == 0:\n",
    "        print(f\"  ì²˜ë¦¬ ì¤‘: {idx}/{len(df_test)}\")\n",
    "    features = calculate_advanced_features(smiles)\n",
    "    if features:\n",
    "        test_features_list.append(features)\n",
    "    else:\n",
    "        test_features_list.append({})\n",
    "\n",
    "test_features_df = pd.DataFrame(test_features_list)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ Morgan Fingerprint\n",
    "test_fp_array = np.array([get_morgan_fingerprint_features(s, n_bits=n_fp_bits) \n",
    "                          for s in df_test[smiles_col_test]])\n",
    "test_fp_pca = pca.transform(test_fp_array)\n",
    "test_fp_df = pd.DataFrame(test_fp_pca, columns=[f'FP_PC{i+1}' for i in range(150)])\n",
    "\n",
    "# ê²°í•© ë° ì „ì²˜ë¦¬\n",
    "X_test_full = pd.concat([test_features_df, test_fp_df], axis=1)\n",
    "X_test_full = X_test_full.fillna(X_test_full.median())\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„°ì™€ ë™ì¼í•œ ì»¬ëŸ¼ ìˆœì„œ ë³´ì¥\n",
    "missing_cols = set(X_clean.columns) - set(X_test_full.columns)\n",
    "for col in missing_cols:\n",
    "    X_test_full[col] = 0\n",
    "\n",
    "X_test_full = X_test_full[X_clean.columns]\n",
    "X_test_scaled = scalers['robust'].transform(X_test_full)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡\n",
    "print(\"\\nğŸ¯ ëª¨ë¸ë³„ ì˜ˆì¸¡...\")\n",
    "test_predictions = {}\n",
    "for name, model in models_full.items():\n",
    "    test_predictions[name] = model.predict(X_test_scaled)\n",
    "    print(f\"  {name} ì˜ˆì¸¡ ì™„ë£Œ\")\n",
    "\n",
    "# ê³ ê¸‰ Quantile Matching\n",
    "print(\"\\nğŸ¨ ê³ ê¸‰ Quantile Matching...\")\n",
    "\n",
    "# ê¸°ì¤€ ëª¨ë¸ë“¤ ì‹œë„ (ê°€ì¥ ì„±ëŠ¥ ì¢‹ì€ ëª¨ë¸ë“¤)\n",
    "top_3_models = sorted(val_scores.items(), key=lambda x: x[1]['rmse'])[:3]\n",
    "print(f\"  Top 3 ëª¨ë¸: {[name for name, _ in top_3_models]}\")\n",
    "\n",
    "all_ensemble_results = {}\n",
    "\n",
    "# ê° ê¸°ì¤€ ëª¨ë¸ì— ëŒ€í•´ 3ê°€ì§€ ë§¤ì¹­ ë°©ë²• ì ìš©\n",
    "for reference_model, _ in top_3_models:\n",
    "    print(f\"  {reference_model}ì„ ê¸°ì¤€ìœ¼ë¡œ ë§¤ì¹­...\")\n",
    "    \n",
    "    basic_matched, segmented_matched, smoothed_matched = advanced_quantile_matching(\n",
    "        test_predictions, reference_model\n",
    "    )\n",
    "    \n",
    "    # ê° ë§¤ì¹­ ë°©ë²•ì— ëŒ€í•´ ì•™ìƒë¸”\n",
    "    for match_type, matched_preds in [\n",
    "        ('basic', basic_matched), \n",
    "        ('segmented', segmented_matched), \n",
    "        ('smoothed', smoothed_matched)\n",
    "    ]:\n",
    "        # ê°€ì¤‘ ì•™ìƒë¸”\n",
    "        ensemble_pred = np.zeros(len(X_test_scaled))\n",
    "        for i, name in enumerate(models.keys()):\n",
    "            ensemble_pred += optimal_weights[i] * matched_preds[name]\n",
    "        \n",
    "        all_ensemble_results[f'{reference_model}_{match_type}'] = ensemble_pred\n",
    "\n",
    "# ì¶”ê°€ ì•™ìƒë¸” ì „ëµë“¤\n",
    "print(\"  ì¶”ê°€ ì•™ìƒë¸” ì „ëµ ìƒì„±...\")\n",
    "\n",
    "# 1. ê¸°ë³¸ ê°€ì¤‘ ì•™ìƒë¸” (ë§¤ì¹­ ì—†ìŒ)\n",
    "basic_ensemble = np.zeros(len(X_test_scaled))\n",
    "for i, name in enumerate(models.keys()):\n",
    "    basic_ensemble += optimal_weights[i] * test_predictions[name]\n",
    "\n",
    "all_ensemble_results['basic_weighted'] = basic_ensemble\n",
    "\n",
    "# 2. ìˆœìœ„ ê¸°ë°˜ ì•™ìƒë¸”\n",
    "rank_ensemble = np.zeros(len(X_test_scaled))\n",
    "for name, pred in test_predictions.items():\n",
    "    ranks = rankdata(pred) / len(pred)\n",
    "    rank_ensemble += ranks / len(test_predictions)\n",
    "\n",
    "# ìˆœìœ„ë¥¼ ì‹¤ì œ ê°’ìœ¼ë¡œ ë³€í™˜\n",
    "sorted_basic = np.sort(basic_ensemble)\n",
    "rank_indices = (rank_ensemble * (len(sorted_basic) - 1)).astype(int)\n",
    "rank_indices = np.clip(rank_indices, 0, len(sorted_basic) - 1)\n",
    "rank_converted = sorted_basic[rank_indices]\n",
    "\n",
    "all_ensemble_results['rank_based'] = rank_converted\n",
    "\n",
    "# 3. Top ëª¨ë¸ë“¤ë§Œ ì‚¬ìš©í•œ ì•™ìƒë¸”\n",
    "top_models = [name for name, _ in top_3_models]\n",
    "if all(model in test_predictions for model in top_models):\n",
    "    top_weights = optimal_weights[:len(top_models)]\n",
    "    top_weights = top_weights / np.sum(top_weights)  # ì •ê·œí™”\n",
    "    \n",
    "    top_ensemble = np.zeros(len(X_test_scaled))\n",
    "    for i, model in enumerate(top_models):\n",
    "        top_ensemble += top_weights[i] * test_predictions[model]\n",
    "    \n",
    "    all_ensemble_results['top3_only'] = top_ensemble\n",
    "\n",
    "# ë¸”ë Œë”© ê³„ìˆ˜ ìµœì í™”\n",
    "print(\"\\nâš¡ ë¸”ë Œë”© ê³„ìˆ˜ ìµœì í™”...\")\n",
    "\n",
    "# ê²€ì¦ ë°ì´í„°ì—ì„œ ê° ì „ëµì˜ ì„±ëŠ¥ ì¸¡ì •ì„ ìœ„í•œ validation ì•™ìƒë¸” ìƒì„±\n",
    "val_ensemble_results = {}\n",
    "\n",
    "for strategy_name in all_ensemble_results.keys():\n",
    "    if 'basic' in strategy_name:\n",
    "        # ê¸°ë³¸ ê°€ì¤‘ ì•™ìƒë¸”\n",
    "        val_pred = np.zeros(len(y_val))\n",
    "        for i, name in enumerate(models.keys()):\n",
    "            val_pred += optimal_weights[i] * val_predictions[name]\n",
    "        val_ensemble_results[strategy_name] = val_pred\n",
    "    elif 'rank' in strategy_name:\n",
    "        # ìˆœìœ„ ê¸°ë°˜\n",
    "        val_rank = np.zeros(len(y_val))\n",
    "        for name, pred in val_predictions.items():\n",
    "            ranks = rankdata(pred) / len(pred)\n",
    "            val_rank += ranks / len(val_predictions)\n",
    "        \n",
    "        sorted_val_basic = np.sort(val_ensemble_results.get('basic_weighted', val_pred))\n",
    "        val_rank_indices = (val_rank * (len(sorted_val_basic) - 1)).astype(int)\n",
    "        val_rank_indices = np.clip(val_rank_indices, 0, len(sorted_val_basic) - 1)\n",
    "        val_ensemble_results[strategy_name] = sorted_val_basic[val_rank_indices]\n",
    "    else:\n",
    "        # Quantile matching ê¸°ë°˜ - ê°„ë‹¨íˆ ê¸°ë³¸ ì•™ìƒë¸”ë¡œ ê·¼ì‚¬\n",
    "        val_pred = np.zeros(len(y_val))\n",
    "        for i, name in enumerate(models.keys()):\n",
    "            val_pred += optimal_weights[i] * val_predictions[name]\n",
    "        val_ensemble_results[strategy_name] = val_pred\n",
    "\n",
    "# ìµœì  ë¸”ë Œë”© ê³„ìˆ˜ ì°¾ê¸°\n",
    "optimal_blend_coeffs = optimize_blend_coefficients(val_ensemble_results, y_val)\n",
    "\n",
    "print(f\"ìµœì  ë¸”ë Œë”© ê³„ìˆ˜:\")\n",
    "for strategy, coeff in zip(all_ensemble_results.keys(), optimal_blend_coeffs):\n",
    "    if coeff > 0.01:\n",
    "        print(f\"  {strategy}: {coeff:.3f}\")\n",
    "\n",
    "# ìµœì¢… ë©”íƒ€ ì•™ìƒë¸”ë“¤ ìƒì„±\n",
    "print(\"\\nğŸ—ï¸ ìµœì¢… ë©”íƒ€ ì•™ìƒë¸” ìƒì„±...\")\n",
    "\n",
    "final_ensemble_strategies = {}\n",
    "\n",
    "# 1. ìµœì  ë¸”ë Œë”©\n",
    "optimal_blend = np.zeros(len(X_test_scaled))\n",
    "for i, (strategy_name, pred) in enumerate(all_ensemble_results.items()):\n",
    "    optimal_blend += optimal_blend_coeffs[i] * pred\n",
    "\n",
    "final_ensemble_strategies['optimal_blend'] = optimal_blend\n",
    "\n",
    "# 2. ë³´ìˆ˜ì  ë¸”ë Œë”© (ìƒìœ„ 3ê°œ ì „ëµë§Œ)\n",
    "top_3_strategies = sorted(\n",
    "    [(name, coeff) for name, coeff in zip(all_ensemble_results.keys(), optimal_blend_coeffs)],\n",
    "    key=lambda x: x[1], reverse=True\n",
    ")[:3]\n",
    "\n",
    "conservative_blend = np.zeros(len(X_test_scaled))\n",
    "total_weight = sum(coeff for _, coeff in top_3_strategies)\n",
    "for strategy_name, coeff in top_3_strategies:\n",
    "    conservative_blend += (coeff / total_weight) * all_ensemble_results[strategy_name]\n",
    "\n",
    "final_ensemble_strategies['conservative_blend'] = conservative_blend\n",
    "\n",
    "# 3. Quantile íŠ¹í™” ë¸”ë Œë”© (Quantile ë§¤ì¹­ ì „ëµë“¤ë§Œ)\n",
    "quantile_strategies = {k: v for k, v in all_ensemble_results.items() \n",
    "                      if any(ref in k for ref, _ in top_3_models)}\n",
    "\n",
    "if quantile_strategies:\n",
    "    quantile_blend = np.mean(list(quantile_strategies.values()), axis=0)\n",
    "    final_ensemble_strategies['quantile_specialized'] = quantile_blend\n",
    "\n",
    "# 4. ê³„ì¸µì  ë¸”ë Œë”©\n",
    "hierarchical_blend = (0.4 * final_ensemble_strategies['optimal_blend'] + \n",
    "                     0.35 * final_ensemble_strategies['conservative_blend'] + \n",
    "                     0.25 * final_ensemble_strategies.get('quantile_specialized', optimal_blend))\n",
    "\n",
    "final_ensemble_strategies['hierarchical_ultimate'] = hierarchical_blend\n",
    "\n",
    "# í›„ì²˜ë¦¬ ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "print(\"\\nğŸ“ í›„ì²˜ë¦¬ ë° ì œì¶œ íŒŒì¼ ìƒì„±...\")\n",
    "\n",
    "output_dir = \"/data2/project/2025summer/jjh0709/git/Jump-AI-2025/submissions/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ëª¨ë“  ì „ëµì— ëŒ€í•´ ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "all_strategies = {**all_ensemble_results, **final_ensemble_strategies}\n",
    "\n",
    "for strategy_name, pred in all_strategies.items():\n",
    "    # í´ë¦¬í•‘\n",
    "    pred_clipped = np.clip(pred, y_clean.min(), y_clean.max())\n",
    "    \n",
    "    # IC50 ì—­ë³€í™˜\n",
    "    ic50_pred = 10 ** (9 - pred_clipped)\n",
    "    ic50_pred = np.clip(ic50_pred, 0.1, 100000)\n",
    "    \n",
    "    # ì´ìƒì¹˜ ì œê±° (ë” ì •êµí•˜ê²Œ)\n",
    "    q1, q3 = np.percentile(ic50_pred, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = max(q1 - 1.5 * iqr, 0.1)\n",
    "    upper_bound = min(q3 + 1.5 * iqr, 100000)\n",
    "    ic50_pred = np.clip(ic50_pred, lower_bound, upper_bound)\n",
    "    \n",
    "    # ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "    submission = pd.DataFrame({\n",
    "        \"ID\": df_test[\"ID\"],\n",
    "        \"ASK1_IC50_nM\": ic50_pred\n",
    "    })\n",
    "    \n",
    "    filename = f\"submit_ultimate_{strategy_name}.csv\"\n",
    "    submission.to_csv(output_dir + filename, index=False)\n",
    "    \n",
    "    print(f\"  {filename} ì €ì¥ ì™„ë£Œ\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸŠ ê¶ê·¹ì˜ Quantile ìµœì í™” ì™„ë£Œ!\")\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸš€ ì£¼ìš” ê°œì„ ì‚¬í•­:\")\n",
    "print(\"â€¢ âœ… CatBoost ì¶”ê°€ (ì´ 9ê°œ ëª¨ë¸)\")\n",
    "print(\"â€¢ âœ… Morgan Fingerprint 2048 bits â†’ PCA 150\")\n",
    "print(\"â€¢ âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” 50 trials\")\n",
    "print(\"â€¢ âœ… 3ê°€ì§€ ê³ ê¸‰ Quantile Matching\")\n",
    "print(\"â€¢ âœ… ë‹¤ì¤‘ ê¸°ì¤€ ëª¨ë¸ ë§¤ì¹­\")\n",
    "print(\"â€¢ âœ… ë¸”ë Œë”© ê³„ìˆ˜ ìë™ ìµœì í™”\")\n",
    "print(\"â€¢ âœ… ê³„ì¸µì  ë©”íƒ€ ì•™ìƒë¸”\")\n",
    "\n",
    "print(\"\\nğŸ“ ìƒì„±ëœ ì œì¶œ íŒŒì¼ë“¤:\")\n",
    "print(\"ğŸ† submit_ultimate_hierarchical_ultimate.csv (ìµœê³  ì¶”ì²œ!) â­â­â­\")\n",
    "print(\"ğŸ¥‡ submit_ultimate_optimal_blend.csv (ìµœì  ë¸”ë Œë”©)\")\n",
    "print(\"ğŸ¥ˆ submit_ultimate_conservative_blend.csv (ë³´ìˆ˜ì  ë¸”ë Œë”©)\")\n",
    "print(\"ğŸ¥‰ submit_ultimate_quantile_specialized.csv (Quantile íŠ¹í™”)\")\n",
    "\n",
    "# íŠ¹ë³„ ì¶”ì²œ: quantile_matched ìŠ¤íƒ€ì¼ ê·¹ëŒ€í™”\n",
    "best_quantile_strategy = None\n",
    "best_strategy_name = None\n",
    "\n",
    "for strategy_name, pred in all_ensemble_results.items():\n",
    "    if any(top_model in strategy_name for top_model, _ in top_3_models):\n",
    "        if 'basic' in strategy_name:  # ê¸°ë³¸ ë§¤ì¹­ì´ ê°€ì¥ ì•ˆì •ì \n",
    "            best_quantile_strategy = pred\n",
    "            best_strategy_name = strategy_name\n",
    "            break\n",
    "\n",
    "if best_quantile_strategy is not None:\n",
    "    pred_clipped = np.clip(best_quantile_strategy, y_clean.min(), y_clean.max())\n",
    "    ic50_pred = 10 ** (9 - pred_clipped)\n",
    "    ic50_pred = np.clip(ic50_pred, 0.1, 100000)\n",
    "    \n",
    "    submission_special = pd.DataFrame({\n",
    "        \"ID\": df_test[\"ID\"],\n",
    "        \"ASK1_IC50_nM\": ic50_pred\n",
    "    })\n",
    "    \n",
    "    submission_special.to_csv(output_dir + \"submit_ultimate_SPECIAL_QUANTILE.csv\", index=False)\n",
    "    print(\"ğŸŒŸ submit_ultimate_SPECIAL_QUANTILE.csv (quantile_matched ê·¹ëŒ€í™”!) â­â­â­â­\")\n",
    "\n",
    "print(\"\\nğŸ¯ ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ:\")\n",
    "print(\"â€¢ ê¸°ì¡´ quantile_matched ëŒ€ë¹„ 3-8% í–¥ìƒ ì˜ˆìƒ\")\n",
    "print(\"â€¢ CatBoost ì¶”ê°€ë¡œ ì•™ìƒë¸” ë‹¤ì–‘ì„± ì¦ëŒ€\")\n",
    "print(\"â€¢ ë” ì •êµí•œ Quantile Matching\")\n",
    "print(\"â€¢ ìë™ ìµœì í™”ëœ ë¸”ë Œë”©\")\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ† ìš°ì„  ì œì¶œ ìˆœì„œ:\")\n",
    "print(\"1. submit_ultimate_SPECIAL_QUANTILE.csv\")\n",
    "print(\"2. submit_ultimate_hierarchical_ultimate.csv\") \n",
    "print(\"3. submit_ultimate_optimal_blend.csv\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8312f8ab-fb71-4fe2-a0d1-dd46c05ec328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì™„ë²½í•œ No-Leakage íŒŒì´í”„ë¼ì¸ ì‹œì‘!\n",
      "ëª©í‘œ: ëª¨ë“  ê°œì„ ì‚¬í•­ ë°˜ì˜ìœ¼ë¡œ ìµœê³  ì„±ëŠ¥ ë‹¬ì„±\n",
      "ğŸ§ª í”¼ì²˜ ì¶”ì¶œ...\n",
      "  ì²˜ë¦¬ ì¤‘: 0/806\n",
      "  ì²« ë²ˆì§¸ ìƒ˜í”Œ í”¼ì²˜ ìˆ˜: 44\n",
      "  ì²« ë²ˆì§¸ í”¼ì²˜ë“¤: ['MolWt', 'LogP', 'TPSA', 'NumRotatableBonds', 'NumHAcceptors']\n",
      "  ì²˜ë¦¬ ì¤‘: 200/806\n",
      "  ì²˜ë¦¬ ì¤‘: 400/806\n",
      "  ì²˜ë¦¬ ì¤‘: 600/806\n",
      "  ì²˜ë¦¬ ì¤‘: 800/806\n",
      "ğŸ“Š í”¼ì²˜ DataFrame í¬ê¸°: (806, 44)\n",
      "ğŸ“Š í”¼ì²˜ ì»¬ëŸ¼ë“¤: ['MolWt', 'LogP', 'TPSA', 'NumRotatableBonds', 'NumHAcceptors', 'NumHDonors', 'NumAromaticRings', 'RingCount', 'NumHeteroatoms', 'HeavyAtomCount']\n",
      "ğŸ“Š ìœ íš¨í•œ í”¼ì²˜ ìˆ˜: 44\n",
      "ğŸ”¬ Morgan Fingerprint ê³„ì‚°...\n",
      "ğŸ“ í¬ê¸° í™•ì¸: features=806, fp=806, target=806\n",
      "ğŸ“ ìµœì†Œ ê¸¸ì´ë¡œ ì •ë ¬: 806 samples\n",
      "ğŸ“Š ìµœì¢… í¬ê¸° í™•ì¸: X_features=806, y_full=806, FP=806\n",
      "ğŸ“Š Valid mask í¬ê¸°: 806, ì‹¤ì œ True ê°œìˆ˜: 806\n",
      "âœ… ìœ íš¨ ë°ì´í„°: 806 samples, 44 features\n",
      "âœ… ìœ íš¨ ë°ì´í„°: 806 samples\n",
      "ğŸ“Š í•™ìŠµ/ê²€ì¦ ë¶„í• : 644/162\n",
      "ğŸ“Š í”¼ì²˜ í™•ì¸: í•™ìŠµ=(644, 44), ê²€ì¦=(162, 44)\n",
      "ğŸ›ï¸ í”¼ì²˜ ë³€í™˜ (No Leakage)...\n",
      "  íŒŒì´í”„ë¼ì¸ 1 (PCA FP): 144 features\n",
      "  íŒŒì´í”„ë¼ì¸ 2 (ì›ë³¸ FP): 1068 features\n",
      "\n",
      "ğŸ¯ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (ë‹¤ì¤‘ ë©”íŠ¸ë¦­)...\n",
      "  LGB ìµœì í™”...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-08-17 20:23:40,540] Trial 2 failed with parameters: {'n_estimators': 1133, 'learning_rate': 0.03400569245284995, 'max_depth': 18, 'num_leaves': 201, 'min_child_samples': 193, 'subsample': 0.9970112758454612, 'colsample_bytree': 0.8774773243301985, 'reg_alpha': 9.037564056932778, 'reg_lambda': 15.99154883511293, 'min_split_gain': 0.20668101601355415, 'feature_fraction': 0.7167456343081775, 'bagging_fraction': 0.5878927617102399, 'bagging_freq': 5} because of the following error: The value nan is not acceptable.\n",
      "[W 2025-08-17 20:23:40,541] Trial 2 failed with value np.float64(nan).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Best Score: 0.5515\n",
      "  XGB ìµœì í™”...\n",
      "    Best Score: 0.5461\n",
      "  CATBOOST ìµœì í™”...\n",
      "    Best Score: 0.5419\n",
      "  RF ìµœì í™”...\n",
      "    Best Score: 0.5415\n",
      "\n",
      "ğŸ”„ OOF ì˜ˆì¸¡ ìƒì„±...\n",
      "  lgb OOF ìƒì„±...\n",
      "    OOF RMSE=0.9012, MAE=0.7052, Spearman=0.6047\n",
      "  xgb OOF ìƒì„±...\n",
      "    OOF RMSE=0.9049, MAE=0.7107, Spearman=0.6022\n",
      "  catboost OOF ìƒì„±...\n",
      "    OOF RMSE=0.9052, MAE=0.7084, Spearman=0.6010\n",
      "  rf OOF ìƒì„±...\n",
      "    OOF RMSE=0.9090, MAE=0.7068, Spearman=0.6018\n",
      "  extra OOF ìƒì„±...\n",
      "    OOF RMSE=1.0092, MAE=0.7557, Spearman=0.5484\n",
      "  gbr OOF ìƒì„±...\n",
      "    OOF RMSE=1.0017, MAE=0.7643, Spearman=0.5513\n",
      "\n",
      "ğŸ—ï¸ ë©”íƒ€ ìŠ¤íƒœí‚¹...\n",
      "\n",
      "ğŸ“Š ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥:\n",
      "  ridge     : RMSE=0.8960, Spearman=0.6045\n",
      "  elastic   : RMSE=0.9040, Spearman=0.6065\n",
      "  lasso     : RMSE=0.9101, Spearman=0.6065\n",
      "  lgb_meta  : RMSE=0.7793, Spearman=0.7378\n",
      "  bayesian  : RMSE=0.8967, Spearman=0.6049\n",
      "\n",
      "ğŸ”„ ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… í•™ìŠµ...\n",
      "  lgb ìµœì¢… í•™ìŠµ...\n",
      "  xgb ìµœì¢… í•™ìŠµ...\n",
      "  catboost ìµœì¢… í•™ìŠµ...\n",
      "  rf ìµœì¢… í•™ìŠµ...\n",
      "  extra ìµœì¢… í•™ìŠµ...\n",
      "  gbr ìµœì¢… í•™ìŠµ...\n",
      "  ëª¨ë“  ëª¨ë¸ ìµœì¢… í•™ìŠµ ì™„ë£Œ\n",
      "\n",
      "ğŸ”® í…ŒìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬...\n",
      "  ì²˜ë¦¬ ì¤‘: 0/127\n",
      "  ì²˜ë¦¬ ì¤‘: 30/127\n",
      "  ì²˜ë¦¬ ì¤‘: 60/127\n",
      "  ì²˜ë¦¬ ì¤‘: 90/127\n",
      "  ì²˜ë¦¬ ì¤‘: 120/127\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'median'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 773\u001b[39m\n\u001b[32m    768\u001b[39m test_fp_array = np.array([get_morgan_fingerprint_features(s, n_bits=n_fp_bits) \n\u001b[32m    769\u001b[39m                           \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m df_test[smiles_col_test]])\n\u001b[32m    771\u001b[39m \u001b[38;5;66;03m# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë³€í™˜ (ê¸°ì¡´ fitëœ ë³€í™˜ê¸° ì‚¬ìš©)\u001b[39;00m\n\u001b[32m    772\u001b[39m \u001b[38;5;66;03m# ëˆ„ë½ëœ ì»¬ëŸ¼ ì²˜ë¦¬ (í•™ìŠµ ë°ì´í„°ì˜ ì¤‘ê°„ê°’ìœ¼ë¡œ ì±„ì›€)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m train_feature_medians = X_features_clean.median()\n\u001b[32m    774\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m X_features_clean.columns:\n\u001b[32m    775\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m test_features_df.columns:\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'median'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "MAP3K5(ASK1) IC50 ì˜ˆì¸¡ - ì™„ë²½í•œ No-Leakage íŒŒì´í”„ë¼ì¸\n",
    "ëª¨ë“  ê°œì„ ì‚¬í•­ ë°˜ì˜:\n",
    "1. ë°ì´í„° ëˆ„ìˆ˜ ì™„ì „ ë°©ì§€\n",
    "2. OOF ê¸°ë°˜ ë¸”ë Œë”©\n",
    "3. ë©”íƒ€ ìŠ¤íƒœí‚¹\n",
    "4. CatBoost í¬í•¨\n",
    "5. ë‹¤ì¤‘ ë©”íŠ¸ë¦­ ìµœì í™”\n",
    "6. FP ì›ë³¸/PCA ì´ì¤‘ íŒŒì´í”„ë¼ì¸\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import ElasticNet, Ridge, BayesianRidge, Lasso\n",
    "from scipy.stats import rankdata, pearsonr, spearmanr\n",
    "from scipy.optimize import minimize\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, AllChem, Lipinski, Crippen\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['RDK_ERROR_STREAM'] = '/dev/null'\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# ======================== í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ í•¨ìˆ˜ë“¤ ========================\n",
    "\n",
    "def calculate_advanced_features(smiles):\n",
    "    \"\"\"í™•ì¥ëœ ë¶„ì ê¸°ìˆ ì ê³„ì‚° - ë²„ì „ í˜¸í™˜ì„± ê°œì„ \"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return {\n",
    "                'MolWt': 0, 'LogP': 0, 'TPSA': 0, 'NumHDonors': 0, \n",
    "                'NumHAcceptors': 0, 'HeavyAtomCount': 0\n",
    "            }\n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # ê¸°ë³¸ ê¸°ìˆ ì - ì•ˆì „í•˜ê²Œ í•˜ë‚˜ì”©\n",
    "        basic_descriptors = [\n",
    "            ('MolWt', 'MolWt'),\n",
    "            ('LogP', 'MolLogP'),\n",
    "            ('TPSA', 'TPSA'),\n",
    "            ('NumRotatableBonds', 'NumRotatableBonds'),\n",
    "            ('NumHAcceptors', 'NumHAcceptors'),\n",
    "            ('NumHDonors', 'NumHDonors'),\n",
    "            ('NumAromaticRings', 'NumAromaticRings'),\n",
    "            ('RingCount', 'RingCount'),\n",
    "            ('NumHeteroatoms', 'NumHeteroatoms'),\n",
    "            ('HeavyAtomCount', 'HeavyAtomCount'),\n",
    "        ]\n",
    "        \n",
    "        for name, desc_name in basic_descriptors:\n",
    "            try:\n",
    "                if hasattr(Descriptors, desc_name):\n",
    "                    func = getattr(Descriptors, desc_name)\n",
    "                    value = func(mol)\n",
    "                    features[name] = float(value) if value is not None and not np.isnan(value) else 0.0\n",
    "                else:\n",
    "                    features[name] = 0.0\n",
    "            except:\n",
    "                features[name] = 0.0\n",
    "        \n",
    "        # ì¶”ê°€ ê¸°ìˆ ìë“¤ - ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ\n",
    "        additional_descriptors = [\n",
    "            ('BertzCT', 'BertzCT'),\n",
    "            ('Chi0', 'Chi0'),\n",
    "            ('Chi1', 'Chi1'),\n",
    "            ('HallKierAlpha', 'HallKierAlpha'),\n",
    "            ('Kappa1', 'Kappa1'),\n",
    "            ('Kappa2', 'Kappa2'),\n",
    "            ('NumSaturatedRings', 'NumSaturatedRings'),\n",
    "            ('NumAliphaticRings', 'NumAliphaticRings'),\n",
    "            ('BalabanJ', 'BalabanJ'),\n",
    "            ('NumRadicalElectrons', 'NumRadicalElectrons'),\n",
    "            ('NumValenceElectrons', 'NumValenceElectrons'),\n",
    "        ]\n",
    "        \n",
    "        for name, desc_name in additional_descriptors:\n",
    "            try:\n",
    "                if hasattr(Descriptors, desc_name):\n",
    "                    func = getattr(Descriptors, desc_name)\n",
    "                    value = func(mol)\n",
    "                    features[name] = float(value) if value is not None and not np.isnan(value) else 0.0\n",
    "                else:\n",
    "                    features[name] = 0.0\n",
    "            except:\n",
    "                features[name] = 0.0\n",
    "        \n",
    "        # ë²„ì „ë³„ ê¸°ìˆ ìë“¤ (ì¡´ì¬í•  ë•Œë§Œ)\n",
    "        version_specific = [\n",
    "            ('FractionCsp3', 'FractionCsp3'),\n",
    "            ('MaxEStateIndex', 'MaxEStateIndex'),\n",
    "            ('MinEStateIndex', 'MinEStateIndex'),\n",
    "        ]\n",
    "        \n",
    "        for name, desc_name in version_specific:\n",
    "            try:\n",
    "                if hasattr(Descriptors, desc_name):\n",
    "                    func = getattr(Descriptors, desc_name)\n",
    "                    value = func(mol)\n",
    "                    features[name] = float(value) if value is not None and not np.isnan(value) else 0.0\n",
    "            except:\n",
    "                pass  # ì—†ì–´ë„ ê´œì°®ìŒ\n",
    "        \n",
    "        # VSA ê¸°ìˆ ìë“¤\n",
    "        vsa_descriptors = [\n",
    "            ('PEOE_VSA1', 'PEOE_VSA1'),\n",
    "            ('PEOE_VSA2', 'PEOE_VSA2'),\n",
    "            ('SMR_VSA1', 'SMR_VSA1'),\n",
    "            ('SlogP_VSA1', 'SlogP_VSA1'),\n",
    "            ('EState_VSA1', 'EState_VSA1'),\n",
    "        ]\n",
    "        \n",
    "        for name, desc_name in vsa_descriptors:\n",
    "            try:\n",
    "                if hasattr(Descriptors, desc_name):\n",
    "                    func = getattr(Descriptors, desc_name)\n",
    "                    value = func(mol)\n",
    "                    features[name] = float(value) if value is not None and not np.isnan(value) else 0.0\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # ì•½ë¬¼ì„± ì§€í‘œ\n",
    "        try:\n",
    "            if hasattr(Descriptors, 'qed'):\n",
    "                qed_value = Descriptors.qed(mol)\n",
    "                features['QED'] = float(qed_value) if qed_value is not None and not np.isnan(qed_value) else 0.0\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            molmr_value = Crippen.MolMR(mol)\n",
    "            features['MolMR'] = float(molmr_value) if molmr_value is not None and not np.isnan(molmr_value) else 0.0\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Lipinski ê¸°ìˆ ìë“¤\n",
    "        lipinski_descriptors = [\n",
    "            ('NumHeavyAtoms', 'NumHeavyAtoms'),\n",
    "            ('NumAliphaticCarbocycles', 'NumAliphaticCarbocycles'),\n",
    "            ('NumAliphaticHeterocycles', 'NumAliphaticHeterocycles'),\n",
    "            ('NumAromaticCarbocycles', 'NumAromaticCarbocycles'),\n",
    "            ('NumAromaticHeterocycles', 'NumAromaticHeterocycles'),\n",
    "            ('NumSaturatedCarbocycles', 'NumSaturatedCarbocycles'),\n",
    "            ('NumSaturatedHeterocycles', 'NumSaturatedHeterocycles'),\n",
    "        ]\n",
    "        \n",
    "        for name, desc_name in lipinski_descriptors:\n",
    "            try:\n",
    "                if hasattr(Lipinski, desc_name):\n",
    "                    func = getattr(Lipinski, desc_name)\n",
    "                    value = func(mol)\n",
    "                    features[name] = float(value) if value is not None and not np.isnan(value) else 0.0\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # ê³„ì‚°ëœ íŠ¹ì„±ë“¤ (ì•ˆì „í•˜ê²Œ)\n",
    "        try:\n",
    "            mw = features.get('MolWt', 1)\n",
    "            hac = features.get('HeavyAtomCount', 1)\n",
    "            rc = features.get('RingCount', 1)\n",
    "            \n",
    "            features['FlexibilityIndex'] = features.get('NumRotatableBonds', 0) / max(hac, 1)\n",
    "            features['TPSARatio'] = features.get('TPSA', 0) / max(mw, 1)\n",
    "            features['AromaticRatio'] = features.get('NumAromaticRings', 0) / max(rc, 1) if rc > 0 else 0\n",
    "            features['HeteroatomRatio'] = features.get('NumHeteroatoms', 0) / max(hac, 1)\n",
    "            features['LogP_MW_Ratio'] = features.get('LogP', 0) / max(mw, 1)\n",
    "            features['TPSA_HeavyAtom_Ratio'] = features.get('TPSA', 0) / max(hac, 1)\n",
    "            features['Acceptor_Donor_Ratio'] = features.get('NumHAcceptors', 0) / max(features.get('NumHDonors', 1), 1)\n",
    "            \n",
    "            # Lipinski Rule of 5 ìœ„ë°˜ ê°œìˆ˜\n",
    "            violations = 0\n",
    "            if features.get('MolWt', 0) > 500: violations += 1\n",
    "            if features.get('LogP', 0) > 5: violations += 1\n",
    "            if features.get('NumHDonors', 0) > 5: violations += 1\n",
    "            if features.get('NumHAcceptors', 0) > 10: violations += 1\n",
    "            features['LipinskiViolations'] = violations\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # ìµœì†Œ 6ê°œ ê¸°ë³¸ í”¼ì²˜ëŠ” ë³´ì¥\n",
    "        required_features = ['MolWt', 'LogP', 'TPSA', 'NumHDonors', 'NumHAcceptors', 'HeavyAtomCount']\n",
    "        for feat in required_features:\n",
    "            if feat not in features:\n",
    "                features[feat] = 0.0\n",
    "        \n",
    "        return features\n",
    "        \n",
    "    except Exception as e:\n",
    "        # ìµœì¢… í´ë°±\n",
    "        return {\n",
    "            'MolWt': 0, 'LogP': 0, 'TPSA': 0, 'NumHDonors': 0, \n",
    "            'NumHAcceptors': 0, 'HeavyAtomCount': 0\n",
    "        }\n",
    "\n",
    "def get_morgan_fingerprint_features(smiles, radius=2, n_bits=1024):\n",
    "    \"\"\"Morgan Fingerprint ê³„ì‚°\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return np.zeros(n_bits)\n",
    "    \n",
    "    try:\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=radius, nBits=n_bits)\n",
    "        return np.array(fp)\n",
    "    except:\n",
    "        return np.zeros(n_bits)\n",
    "\n",
    "# ======================== ë‹¤ì¤‘ ë©”íŠ¸ë¦­ ìµœì í™” ========================\n",
    "\n",
    "def create_multi_metric_objective(model_type, cv_folds=5):\n",
    "    \"\"\"ë‹¤ì¤‘ ë©”íŠ¸ë¦­ ìµœì í™” ëª©ì í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    def objective(trial):\n",
    "        if model_type == 'lgb':\n",
    "            params = {\n",
    "                'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'verbosity': -1,\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 500, 2000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 20, 500),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 1, 200),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 20.0),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 20.0),\n",
    "                'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 1.0),\n",
    "                'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "                'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "                'bagging_freq': trial.suggest_int('bagging_freq', 0, 7),\n",
    "            }\n",
    "            model_class = lgb.LGBMRegressor\n",
    "            \n",
    "        elif model_type == 'xgb':\n",
    "            params = {\n",
    "                'objective': 'reg:squarederror',\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 500, 2000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 20),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 20.0),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 20.0),\n",
    "                'gamma': trial.suggest_float('gamma', 0.0, 10.0),\n",
    "            }\n",
    "            model_class = xgb.XGBRegressor\n",
    "            \n",
    "        elif model_type == 'catboost':\n",
    "            params = {\n",
    "                'iterations': trial.suggest_int('iterations', 300, 1500),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "                'depth': trial.suggest_int('depth', 4, 10),\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1.0, 15.0),\n",
    "                'verbose': False,\n",
    "                'thread_count': 4,\n",
    "                'random_seed': 42,\n",
    "            }\n",
    "            model_class = cb.CatBoostRegressor\n",
    "            \n",
    "        elif model_type == 'rf':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 200, 1000),\n",
    "                'max_depth': trial.suggest_int('max_depth', 8, 40),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "                'max_features': trial.suggest_float('max_features', 0.3, 1.0),\n",
    "                'n_jobs': -1,\n",
    "                'random_state': 42,\n",
    "            }\n",
    "            model_class = RandomForestRegressor\n",
    "        \n",
    "        # Global variables will be set by main function\n",
    "        X_train_global = trial.user_attrs.get('X_train')\n",
    "        y_train_global = trial.user_attrs.get('y_train')\n",
    "        \n",
    "        if X_train_global is None or y_train_global is None:\n",
    "            return float('inf')\n",
    "        \n",
    "        cv = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        rmse_list, mae_list, spearman_list = [], [], []\n",
    "        \n",
    "        for train_idx, val_idx in cv.split(X_train_global):\n",
    "            X_fold_train = X_train_global[train_idx]\n",
    "            X_fold_val = X_train_global[val_idx]\n",
    "            y_fold_train = y_train_global[train_idx]\n",
    "            y_fold_val = y_train_global[val_idx]\n",
    "            \n",
    "            model = model_class(**params)\n",
    "            model.fit(X_fold_train, y_fold_train)\n",
    "            \n",
    "            preds = model.predict(X_fold_val)\n",
    "            \n",
    "            rmse = np.sqrt(mean_squared_error(y_fold_val, preds))\n",
    "            mae = mean_absolute_error(y_fold_val, preds)\n",
    "            spearman_corr = spearmanr(y_fold_val, preds)[0]\n",
    "            \n",
    "            rmse_list.append(rmse)\n",
    "            mae_list.append(mae)\n",
    "            spearman_list.append(spearman_corr)\n",
    "        \n",
    "        # ë‹¤ì¤‘ ë©”íŠ¸ë¦­ ì¡°í•©: RMSE + MAE - Spearman\n",
    "        combined_score = 0.5 * np.mean(rmse_list) + 0.3 * np.mean(mae_list) - 0.2 * np.mean(spearman_list)\n",
    "        return combined_score\n",
    "    \n",
    "    return objective\n",
    "\n",
    "# ======================== OOF ì˜ˆì¸¡ ìƒì„± ========================\n",
    "\n",
    "def generate_oof_predictions(models_params, X_train, y_train, cv_folds=5):\n",
    "    \"\"\"Out-of-Fold ì˜ˆì¸¡ ìƒì„± (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)\"\"\"\n",
    "    \n",
    "    cv = KFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    oof_predictions = {}\n",
    "    \n",
    "    for model_name, params in models_params.items():\n",
    "        print(f\"  {model_name} OOF ìƒì„±...\")\n",
    "        oof_pred = np.zeros(len(X_train))\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(cv.split(X_train)):\n",
    "            X_fold_train = X_train[train_idx]\n",
    "            X_fold_val = X_train[val_idx]\n",
    "            y_fold_train = y_train[train_idx]\n",
    "            \n",
    "            # ëª¨ë¸ ìƒì„±\n",
    "            if model_name == 'lgb':\n",
    "                model = lgb.LGBMRegressor(**params, verbosity=-1)\n",
    "                try:\n",
    "                    model.fit(X_fold_train, y_fold_train,\n",
    "                             eval_set=[(X_fold_val, y_train[val_idx])],\n",
    "                             callbacks=[lgb.early_stopping(100, verbose=False)])\n",
    "                except:\n",
    "                    model.fit(X_fold_train, y_fold_train)\n",
    "                    \n",
    "            elif model_name == 'xgb':\n",
    "                model = xgb.XGBRegressor(**params)\n",
    "                try:\n",
    "                    model.set_params(early_stopping_rounds=100)\n",
    "                    model.fit(X_fold_train, y_fold_train,\n",
    "                             eval_set=[(X_fold_val, y_train[val_idx])],\n",
    "                             verbose=False)\n",
    "                except:\n",
    "                    try:\n",
    "                        model.fit(X_fold_train, y_fold_train,\n",
    "                                 eval_set=[(X_fold_val, y_train[val_idx])],\n",
    "                                 early_stopping_rounds=100, verbose=False)\n",
    "                    except:\n",
    "                        model.fit(X_fold_train, y_fold_train)\n",
    "                        \n",
    "            elif model_name == 'catboost':\n",
    "                model = cb.CatBoostRegressor(**params)\n",
    "                try:\n",
    "                    model.fit(X_fold_train, y_fold_train,\n",
    "                             eval_set=(X_fold_val, y_train[val_idx]),\n",
    "                             early_stopping_rounds=50, verbose=False)\n",
    "                except:\n",
    "                    model.fit(X_fold_train, y_fold_train, verbose=False)\n",
    "                    \n",
    "            elif model_name == 'rf':\n",
    "                model = RandomForestRegressor(**params)\n",
    "                model.fit(X_fold_train, y_fold_train)\n",
    "                \n",
    "            elif model_name == 'extra':\n",
    "                model = ExtraTreesRegressor(**params)\n",
    "                model.fit(X_fold_train, y_fold_train)\n",
    "                \n",
    "            elif model_name == 'gbr':\n",
    "                model = GradientBoostingRegressor(**params)\n",
    "                model.fit(X_fold_train, y_fold_train)\n",
    "            \n",
    "            # OOF ì˜ˆì¸¡\n",
    "            oof_pred[val_idx] = model.predict(X_fold_val)\n",
    "        \n",
    "        oof_predictions[model_name] = oof_pred\n",
    "        \n",
    "        # OOF ì„±ëŠ¥ í‰ê°€\n",
    "        rmse = np.sqrt(mean_squared_error(y_train, oof_pred))\n",
    "        mae = mean_absolute_error(y_train, oof_pred)\n",
    "        spearman_corr = spearmanr(y_train, oof_pred)[0]\n",
    "        print(f\"    OOF RMSE={rmse:.4f}, MAE={mae:.4f}, Spearman={spearman_corr:.4f}\")\n",
    "    \n",
    "    return oof_predictions\n",
    "\n",
    "# ======================== ë©”íƒ€ ìŠ¤íƒœí‚¹ ========================\n",
    "\n",
    "def create_meta_stacking_models(oof_predictions, y_train):\n",
    "    \"\"\"ë©”íƒ€ ìŠ¤íƒœí‚¹ ëª¨ë¸ë“¤ ìƒì„±\"\"\"\n",
    "    \n",
    "    # OOF ì˜ˆì¸¡ë“¤ì„ featureë¡œ ì‚¬ìš©\n",
    "    oof_features = np.column_stack(list(oof_predictions.values()))\n",
    "    \n",
    "    meta_models = {}\n",
    "    \n",
    "    # 1. Ridge íšŒê·€\n",
    "    meta_models['ridge'] = Ridge(alpha=1.0, random_state=42)\n",
    "    meta_models['ridge'].fit(oof_features, y_train)\n",
    "    \n",
    "    # 2. Elastic Net\n",
    "    meta_models['elastic'] = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)\n",
    "    meta_models['elastic'].fit(oof_features, y_train)\n",
    "    \n",
    "    # 3. Lasso\n",
    "    meta_models['lasso'] = Lasso(alpha=0.1, random_state=42)\n",
    "    meta_models['lasso'].fit(oof_features, y_train)\n",
    "    \n",
    "    # 4. LightGBM ë©”íƒ€\n",
    "    meta_models['lgb_meta'] = lgb.LGBMRegressor(\n",
    "        n_estimators=100, learning_rate=0.1, max_depth=3,\n",
    "        num_leaves=10, min_child_samples=20, verbosity=-1, random_state=42\n",
    "    )\n",
    "    meta_models['lgb_meta'].fit(oof_features, y_train)\n",
    "    \n",
    "    # 5. Bayesian Ridge (random_state ì—†ìŒ)\n",
    "    meta_models['bayesian'] = BayesianRidge()\n",
    "    meta_models['bayesian'].fit(oof_features, y_train)\n",
    "    \n",
    "    # ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
    "    print(\"\\nğŸ“Š ë©”íƒ€ ëª¨ë¸ ì„±ëŠ¥:\")\n",
    "    for name, model in meta_models.items():\n",
    "        pred = model.predict(oof_features)\n",
    "        rmse = np.sqrt(mean_squared_error(y_train, pred))\n",
    "        spearman_corr = spearmanr(y_train, pred)[0]\n",
    "        print(f\"  {name:10s}: RMSE={rmse:.4f}, Spearman={spearman_corr:.4f}\")\n",
    "    \n",
    "    return meta_models\n",
    "\n",
    "# ======================== ë©”ì¸ ì‹¤í–‰ ========================\n",
    "\n",
    "print(\"ğŸš€ ì™„ë²½í•œ No-Leakage íŒŒì´í”„ë¼ì¸ ì‹œì‘!\")\n",
    "print(\"ëª©í‘œ: ëª¨ë“  ê°œì„ ì‚¬í•­ ë°˜ì˜ìœ¼ë¡œ ìµœê³  ì„±ëŠ¥ ë‹¬ì„±\")\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "df_train = pd.read_csv(\"/data2/project/2025summer/jjh0709/git/Jump-AI-2025/data/chembl_processed_rescaled.csv\")\n",
    "df_test = pd.read_csv(\"/data2/project/2025summer/jjh0709/git/Jump-AI-2025/data/test.csv\")\n",
    "\n",
    "df_train = df_train[df_train[\"IC50\"] > 0].copy()\n",
    "df_train = df_train[(df_train[\"IC50\"] >= 0.1) & (df_train[\"IC50\"] <= 1e5)].copy()\n",
    "df_train[\"pIC50\"] = 9 - np.log10(df_train[\"IC50\"])\n",
    "\n",
    "smiles_col = 'Smiles' if 'Smiles' in df_train.columns else 'smiles'\n",
    "smiles_col_test = 'Smiles' if 'Smiles' in df_test.columns else 'smiles'\n",
    "\n",
    "# í”¼ì²˜ ì¶”ì¶œ\n",
    "print(\"ğŸ§ª í”¼ì²˜ ì¶”ì¶œ...\")\n",
    "train_features_list = []\n",
    "for idx, smiles in enumerate(df_train[smiles_col]):\n",
    "    if idx % 200 == 0:\n",
    "        print(f\"  ì²˜ë¦¬ ì¤‘: {idx}/{len(df_train)}\")\n",
    "    features = calculate_advanced_features(smiles)\n",
    "    train_features_list.append(features)\n",
    "    \n",
    "    # ì²« ë²ˆì§¸ ìƒ˜í”Œ ë””ë²„ê¹…\n",
    "    if idx == 0:\n",
    "        print(f\"  ì²« ë²ˆì§¸ ìƒ˜í”Œ í”¼ì²˜ ìˆ˜: {len(features) if features else 0}\")\n",
    "        if features:\n",
    "            print(f\"  ì²« ë²ˆì§¸ í”¼ì²˜ë“¤: {list(features.keys())[:5]}\")\n",
    "\n",
    "train_features_df = pd.DataFrame(train_features_list)\n",
    "print(f\"ğŸ“Š í”¼ì²˜ DataFrame í¬ê¸°: {train_features_df.shape}\")\n",
    "print(f\"ğŸ“Š í”¼ì²˜ ì»¬ëŸ¼ë“¤: {list(train_features_df.columns)[:10]}\")\n",
    "\n",
    "# NaNì´ ì•„ë‹Œ í”¼ì²˜ë“¤ë§Œ í™•ì¸\n",
    "non_null_features = train_features_df.columns[train_features_df.notna().any()].tolist()\n",
    "print(f\"ğŸ“Š ìœ íš¨í•œ í”¼ì²˜ ìˆ˜: {len(non_null_features)}\")\n",
    "\n",
    "if len(non_null_features) == 0:\n",
    "    print(\"âš ï¸ ëª¨ë“  í”¼ì²˜ê°€ NaNì…ë‹ˆë‹¤. í”¼ì²˜ ì¶”ì¶œ í•¨ìˆ˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\")\n",
    "    # ê°„ë‹¨í•œ ëŒ€ì²´ í”¼ì²˜ ìƒì„±\n",
    "    simple_features = []\n",
    "    for idx, smiles in enumerate(df_train[smiles_col]):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            simple_features.append({\n",
    "                'MolWt': Descriptors.MolWt(mol),\n",
    "                'LogP': Descriptors.MolLogP(mol),\n",
    "                'TPSA': Descriptors.TPSA(mol),\n",
    "                'NumHDonors': Descriptors.NumHDonors(mol),\n",
    "                'NumHAcceptors': Descriptors.NumHAcceptors(mol),\n",
    "                'HeavyAtomCount': Descriptors.HeavyAtomCount(mol)\n",
    "            })\n",
    "        else:\n",
    "            simple_features.append({\n",
    "                'MolWt': 0, 'LogP': 0, 'TPSA': 0,\n",
    "                'NumHDonors': 0, 'NumHAcceptors': 0, 'HeavyAtomCount': 0\n",
    "            })\n",
    "    \n",
    "    train_features_df = pd.DataFrame(simple_features)\n",
    "    print(f\"ğŸ“Š ëŒ€ì²´ í”¼ì²˜ DataFrame í¬ê¸°: {train_features_df.shape}\")\n",
    "    print(f\"ğŸ“Š ëŒ€ì²´ í”¼ì²˜ ì»¬ëŸ¼ë“¤: {list(train_features_df.columns)}\")\n",
    "\n",
    "# Morgan Fingerprint ê³„ì‚° (ì›ë³¸ ë°ì´í„°)\n",
    "print(\"ğŸ”¬ Morgan Fingerprint ê³„ì‚°...\")\n",
    "n_fp_bits = 1024\n",
    "train_fp_array = np.array([get_morgan_fingerprint_features(s, n_bits=n_fp_bits) \n",
    "                          for s in df_train[smiles_col]])\n",
    "\n",
    "# ê¸°ë³¸ í”¼ì²˜ ê²°í•© - í¬ê¸° í™•ì¸ ë° ì •ë ¬\n",
    "print(f\"ğŸ“ í¬ê¸° í™•ì¸: features={len(train_features_df)}, fp={len(train_fp_array)}, target={len(df_train)}\")\n",
    "\n",
    "# ëª¨ë“  ë°ì´í„°ë¥¼ ë™ì¼í•œ ê¸¸ì´ë¡œ ë§ì¶¤\n",
    "min_length = min(len(train_features_df), len(train_fp_array), len(df_train))\n",
    "print(f\"ğŸ“ ìµœì†Œ ê¸¸ì´ë¡œ ì •ë ¬: {min_length} samples\")\n",
    "\n",
    "# ì•ˆì „í•œ ì¸ë±ì‹±ìœ¼ë¡œ í¬ê¸° ë§ì¶¤\n",
    "train_features_df = train_features_df.iloc[:min_length].reset_index(drop=True)\n",
    "train_fp_array = train_fp_array[:min_length]\n",
    "df_train_aligned = df_train.iloc[:min_length].reset_index(drop=True)\n",
    "\n",
    "# í”¼ì²˜ ì „ì²˜ë¦¬\n",
    "X_features = train_features_df.fillna(train_features_df.median())\n",
    "y_full = df_train_aligned[\"pIC50\"]\n",
    "\n",
    "print(f\"ğŸ“Š ìµœì¢… í¬ê¸° í™•ì¸: X_features={len(X_features)}, y_full={len(y_full)}, FP={len(train_fp_array)}\")\n",
    "\n",
    "# ì•ˆì „í•œ valid_mask ìƒì„±\n",
    "valid_mask = ~(X_features.isnull().any(axis=1) | y_full.isnull())\n",
    "print(f\"ğŸ“Š Valid mask í¬ê¸°: {len(valid_mask)}, ì‹¤ì œ True ê°œìˆ˜: {valid_mask.sum()}\")\n",
    "\n",
    "# DataFrame í˜•íƒœ ìœ ì§€í•˜ì—¬ í”¼ì²˜ ì†ì‹¤ ë°©ì§€\n",
    "X_features_clean_df = X_features[valid_mask].reset_index(drop=True)\n",
    "train_fp_clean = train_fp_array[valid_mask_array]\n",
    "y_clean = y_full_array[valid_mask_array]\n",
    "\n",
    "print(f\"âœ… ìœ íš¨ ë°ì´í„°: {len(X_features_clean_df)} samples, {X_features_clean_df.shape[1]} features\")\n",
    "\n",
    "print(f\"âœ… ìœ íš¨ ë°ì´í„°: {len(X_features_clean)} samples\")\n",
    "\n",
    "# ======================== 1. ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ ë¶„í•  ========================\n",
    "\n",
    "# ë¨¼ì € ì›ë³¸ ë°ì´í„°ë¥¼ train/valë¡œ ë¶„í• \n",
    "indices = np.arange(len(X_features_clean_df))\n",
    "train_indices, val_indices = train_test_split(\n",
    "    indices, test_size=0.2, random_state=42, \n",
    "    stratify=pd.cut(y_clean, bins=5, labels=False)\n",
    ")\n",
    "\n",
    "# Raw í”¼ì²˜ë“¤ (DataFrame ìœ ì§€)\n",
    "X_features_train_raw = X_features_clean_df.iloc[train_indices]\n",
    "X_features_val_raw = X_features_clean_df.iloc[val_indices]\n",
    "\n",
    "# Raw Fingerprints\n",
    "train_fp_train_raw = train_fp_clean[train_indices]\n",
    "train_fp_val_raw = train_fp_clean[val_indices]\n",
    "\n",
    "# Target\n",
    "y_train = y_clean[train_indices]\n",
    "y_val = y_clean[val_indices]\n",
    "\n",
    "print(f\"ğŸ“Š í•™ìŠµ/ê²€ì¦ ë¶„í• : {len(train_indices)}/{len(val_indices)}\")\n",
    "print(f\"ğŸ“Š í”¼ì²˜ í™•ì¸: í•™ìŠµ={X_features_train_raw.shape}, ê²€ì¦={X_features_val_raw.shape}\")\n",
    "\n",
    "# ======================== 2. í”¼ì²˜ ë³€í™˜ (í•™ìŠµ ë°ì´í„°ì—ë§Œ fit) ========================\n",
    "\n",
    "print(\"ğŸ›ï¸ í”¼ì²˜ ë³€í™˜ (No Leakage)...\")\n",
    "\n",
    "# PCA (í•™ìŠµ ë°ì´í„°ì—ë§Œ fit)\n",
    "pca = PCA(n_components=100, random_state=42)\n",
    "train_fp_pca = pca.fit_transform(train_fp_train_raw)\n",
    "val_fp_pca = pca.transform(train_fp_val_raw)\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ëŸ¬ (í•™ìŠµ ë°ì´í„°ì—ë§Œ fit)\n",
    "scaler_features = RobustScaler()\n",
    "X_features_train_scaled = scaler_features.fit_transform(X_features_train_raw)\n",
    "X_features_val_scaled = scaler_features.transform(X_features_val_raw)\n",
    "\n",
    "scaler_fp = RobustScaler()\n",
    "train_fp_train_scaled = scaler_fp.fit_transform(train_fp_pca)\n",
    "train_fp_val_scaled = scaler_fp.transform(val_fp_pca)\n",
    "\n",
    "# ë‘ ê°€ì§€ íŒŒì´í”„ë¼ì¸ ì¤€ë¹„\n",
    "# íŒŒì´í”„ë¼ì¸ 1: í”¼ì²˜ + PCA FP (ì‹ ê²½ë§/ì„ í˜• ëª¨ë¸ìš©)\n",
    "X_train_pipeline1 = np.hstack([X_features_train_scaled, train_fp_train_scaled])\n",
    "X_val_pipeline1 = np.hstack([X_features_val_scaled, train_fp_val_scaled])\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ 2: í”¼ì²˜ + ì›ë³¸ FP (íŠ¸ë¦¬ ëª¨ë¸ìš©)\n",
    "# ì›ë³¸ FPëŠ” ìŠ¤ì¼€ì¼ë§ ì—†ì´ ì‚¬ìš©\n",
    "X_train_pipeline2 = np.hstack([X_features_train_scaled, train_fp_train_raw])\n",
    "X_val_pipeline2 = np.hstack([X_features_val_scaled, train_fp_val_raw])\n",
    "\n",
    "print(f\"  íŒŒì´í”„ë¼ì¸ 1 (PCA FP): {X_train_pipeline1.shape[1]} features\")\n",
    "print(f\"  íŒŒì´í”„ë¼ì¸ 2 (ì›ë³¸ FP): {X_train_pipeline2.shape[1]} features\")\n",
    "\n",
    "# ======================== 3. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ========================\n",
    "\n",
    "print(\"\\nğŸ¯ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (ë‹¤ì¤‘ ë©”íŠ¸ë¦­)...\")\n",
    "\n",
    "best_params = {}\n",
    "\n",
    "# íŠ¸ë¦¬ ëª¨ë¸ë“¤ì€ íŒŒì´í”„ë¼ì¸ 2 ì‚¬ìš©\n",
    "tree_models = ['lgb', 'xgb', 'catboost', 'rf']\n",
    "for model_type in tree_models:\n",
    "    print(f\"  {model_type.upper()} ìµœì í™”...\")\n",
    "    \n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    \n",
    "    # Global variables ì„¤ì •\n",
    "    study.set_user_attr('X_train', X_train_pipeline2)\n",
    "    study.set_user_attr('y_train', y_train)\n",
    "    \n",
    "    objective_func = create_multi_metric_objective(model_type)\n",
    "    \n",
    "    # user_attrsë¥¼ trialì— ì „ë‹¬\n",
    "    def wrapped_objective(trial):\n",
    "        trial.set_user_attr('X_train', X_train_pipeline2)\n",
    "        trial.set_user_attr('y_train', y_train)\n",
    "        return objective_func(trial)\n",
    "    \n",
    "    study.optimize(wrapped_objective, n_trials=30, show_progress_bar=False)\n",
    "    \n",
    "    best_params[model_type] = study.best_params\n",
    "    print(f\"    Best Score: {study.best_value:.4f}\")\n",
    "\n",
    "# ======================== 4. OOF ì˜ˆì¸¡ ìƒì„± ========================\n",
    "\n",
    "print(\"\\nğŸ”„ OOF ì˜ˆì¸¡ ìƒì„±...\")\n",
    "\n",
    "# ìµœì í™”ëœ íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ ì„¤ì •\n",
    "models_params = {}\n",
    "\n",
    "for model_type in tree_models:\n",
    "    models_params[model_type] = best_params[model_type]\n",
    "\n",
    "# ì¶”ê°€ ëª¨ë¸ë“¤ (ê³ ì • íŒŒë¼ë¯¸í„°)\n",
    "models_params['extra'] = {\n",
    "    'n_estimators': 500, 'max_depth': 25, 'min_samples_split': 5,\n",
    "    'max_features': 0.8, 'n_jobs': -1, 'random_state': 42\n",
    "}\n",
    "\n",
    "models_params['gbr'] = {\n",
    "    'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 8,\n",
    "    'subsample': 0.8, 'random_state': 42\n",
    "}\n",
    "\n",
    "# OOF ì˜ˆì¸¡ ìƒì„± (íŠ¸ë¦¬ ëª¨ë¸ìš© íŒŒì´í”„ë¼ì¸ 2 ì‚¬ìš©)\n",
    "oof_predictions = generate_oof_predictions(models_params, X_train_pipeline2, y_train)\n",
    "\n",
    "# ======================== 5. ë©”íƒ€ ìŠ¤íƒœí‚¹ ========================\n",
    "\n",
    "print(\"\\nğŸ—ï¸ ë©”íƒ€ ìŠ¤íƒœí‚¹...\")\n",
    "meta_models = create_meta_stacking_models(oof_predictions, y_train)\n",
    "\n",
    "# ======================== 6. ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… í•™ìŠµ ========================\n",
    "\n",
    "print(\"\\nğŸ”„ ì „ì²´ ë°ì´í„°ë¡œ ìµœì¢… í•™ìŠµ...\")\n",
    "\n",
    "# ì „ì²´ ë°ì´í„° ë³€í™˜ (ê¸°ì¡´ fitëœ ë³€í™˜ê¸° ì‚¬ìš©)\n",
    "X_features_full_scaled = scaler_features.transform(X_features_clean_df)\n",
    "train_fp_full_pca = pca.transform(train_fp_clean)\n",
    "train_fp_full_scaled = scaler_fp.transform(train_fp_full_pca)\n",
    "\n",
    "# ì „ì²´ ë°ì´í„° íŒŒì´í”„ë¼ì¸\n",
    "X_full_pipeline1 = np.hstack([X_features_full_scaled, train_fp_full_scaled])\n",
    "X_full_pipeline2 = np.hstack([X_features_full_scaled, train_fp_clean])\n",
    "\n",
    "# ìµœì¢… ëª¨ë¸ë“¤ í•™ìŠµ\n",
    "final_models = {}\n",
    "\n",
    "for model_name, params in models_params.items():\n",
    "    print(f\"  {model_name} ìµœì¢… í•™ìŠµ...\")\n",
    "    \n",
    "    if model_name == 'lgb':\n",
    "        # í•™ìŠµ ë°ì´í„°ì˜ 20%ë¥¼ ê²€ì¦ìš©ìœ¼ë¡œ ì‚¬ìš© (Early Stopping)\n",
    "        X_train_es, X_val_es, y_train_es, y_val_es = train_test_split(\n",
    "            X_full_pipeline2, y_clean, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        model = lgb.LGBMRegressor(**params, verbosity=-1)\n",
    "        try:\n",
    "            model.fit(X_train_es, y_train_es,\n",
    "                     eval_set=[(X_val_es, y_val_es)],\n",
    "                     callbacks=[lgb.early_stopping(100, verbose=False)])\n",
    "            # best_iterationìœ¼ë¡œ ì „ì²´ ë°ì´í„° ì¬í•™ìŠµ\n",
    "            best_iter = model.best_iteration if hasattr(model, 'best_iteration') else params.get('n_estimators', 1000)\n",
    "            final_params = {**params, 'n_estimators': int(best_iter * 1.1)}  # 10% ì—¬ìœ \n",
    "            final_model = lgb.LGBMRegressor(**final_params, verbosity=-1)\n",
    "            final_model.fit(X_full_pipeline2, y_clean)\n",
    "            final_models[model_name] = final_model\n",
    "        except:\n",
    "            model.fit(X_full_pipeline2, y_clean)\n",
    "            final_models[model_name] = model\n",
    "            \n",
    "    elif model_name == 'xgb':\n",
    "        X_train_es, X_val_es, y_train_es, y_val_es = train_test_split(\n",
    "            X_full_pipeline2, y_clean, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        try:\n",
    "            model.set_params(early_stopping_rounds=100)\n",
    "            model.fit(X_train_es, y_train_es,\n",
    "                     eval_set=[(X_val_es, y_val_es)],\n",
    "                     verbose=False)\n",
    "            # best_iterationìœ¼ë¡œ ì „ì²´ ë°ì´í„° ì¬í•™ìŠµ\n",
    "            best_iter = model.best_iteration if hasattr(model, 'best_iteration') else params.get('n_estimators', 1000)\n",
    "            final_params = {**params, 'n_estimators': int(best_iter * 1.1)}\n",
    "            final_model = xgb.XGBRegressor(**final_params)\n",
    "            final_model.fit(X_full_pipeline2, y_clean)\n",
    "            final_models[model_name] = final_model\n",
    "        except:\n",
    "            model.fit(X_full_pipeline2, y_clean)\n",
    "            final_models[model_name] = model\n",
    "            \n",
    "    elif model_name == 'catboost':\n",
    "        X_train_es, X_val_es, y_train_es, y_val_es = train_test_split(\n",
    "            X_full_pipeline2, y_clean, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        model = cb.CatBoostRegressor(**params)\n",
    "        try:\n",
    "            model.fit(X_train_es, y_train_es,\n",
    "                     eval_set=(X_val_es, y_val_es),\n",
    "                     early_stopping_rounds=50, verbose=False)\n",
    "            # best_iterationìœ¼ë¡œ ì „ì²´ ë°ì´í„° ì¬í•™ìŠµ\n",
    "            best_iter = model.best_iteration_ if hasattr(model, 'best_iteration_') else params.get('iterations', 800)\n",
    "            final_params = {**params, 'iterations': int(best_iter * 1.1)}\n",
    "            final_model = cb.CatBoostRegressor(**final_params)\n",
    "            final_model.fit(X_full_pipeline2, y_clean, verbose=False)\n",
    "            final_models[model_name] = final_model\n",
    "        except:\n",
    "            model.fit(X_full_pipeline2, y_clean, verbose=False)\n",
    "            final_models[model_name] = model\n",
    "            \n",
    "    else:\n",
    "        # RF, Extra Trees, GBRì€ Early Stopping ì—†ìŒ\n",
    "        if model_name == 'rf':\n",
    "            model = RandomForestRegressor(**params)\n",
    "        elif model_name == 'extra':\n",
    "            model = ExtraTreesRegressor(**params)\n",
    "        elif model_name == 'gbr':\n",
    "            model = GradientBoostingRegressor(**params)\n",
    "        \n",
    "        model.fit(X_full_pipeline2, y_clean)\n",
    "        final_models[model_name] = model\n",
    "\n",
    "print(\"  ëª¨ë“  ëª¨ë¸ ìµœì¢… í•™ìŠµ ì™„ë£Œ\")\n",
    "\n",
    "# ======================== 7. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬ ========================\n",
    "\n",
    "print(\"\\nğŸ”® í…ŒìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬...\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ í”¼ì²˜ ì¶”ì¶œ\n",
    "test_features_list = []\n",
    "for idx, smiles in enumerate(df_test[smiles_col_test]):\n",
    "    if idx % 30 == 0:\n",
    "        print(f\"  ì²˜ë¦¬ ì¤‘: {idx}/{len(df_test)}\")\n",
    "    features = calculate_advanced_features(smiles)\n",
    "    test_features_list.append(features)\n",
    "\n",
    "test_features_df = pd.DataFrame(test_features_list)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ Morgan Fingerprint\n",
    "test_fp_array = np.array([get_morgan_fingerprint_features(s, n_bits=n_fp_bits) \n",
    "                          for s in df_test[smiles_col_test]])\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë³€í™˜ (ê¸°ì¡´ fitëœ ë³€í™˜ê¸° ì‚¬ìš©)\n",
    "# ëˆ„ë½ëœ ì»¬ëŸ¼ ì²˜ë¦¬ (í•™ìŠµ ë°ì´í„°ì˜ ì¤‘ê°„ê°’ìœ¼ë¡œ ì±„ì›€)\n",
    "train_feature_medians = X_features_clean.median()\n",
    "for col in X_features_clean.columns:\n",
    "    if col not in test_features_df.columns:\n",
    "        test_features_df[col] = train_feature_medians[col]\n",
    "\n",
    "test_features_df = test_features_df[X_features_clean.columns]\n",
    "test_features_df = test_features_df.fillna(train_feature_medians)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ìŠ¤ì¼€ì¼ë§\n",
    "test_features_scaled = scaler_features.transform(test_features_df)\n",
    "test_fp_pca = pca.transform(test_fp_array)\n",
    "test_fp_scaled = scaler_fp.transform(test_fp_pca)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸\n",
    "X_test_pipeline1 = np.hstack([test_features_scaled, test_fp_scaled])\n",
    "X_test_pipeline2 = np.hstack([test_features_scaled, test_fp_array])\n",
    "\n",
    "# ======================== 8. í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ========================\n",
    "\n",
    "print(\"\\nğŸ¯ í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡...\")\n",
    "\n",
    "# ê¸°ë³¸ ëª¨ë¸ ì˜ˆì¸¡\n",
    "test_predictions = {}\n",
    "for model_name, model in final_models.items():\n",
    "    # íŠ¸ë¦¬ ëª¨ë¸ì€ íŒŒì´í”„ë¼ì¸ 2 ì‚¬ìš©\n",
    "    test_predictions[model_name] = model.predict(X_test_pipeline2)\n",
    "    print(f\"  {model_name} ì˜ˆì¸¡ ì™„ë£Œ\")\n",
    "\n",
    "# ë©”íƒ€ ìŠ¤íƒœí‚¹ ì˜ˆì¸¡\n",
    "test_meta_features = np.column_stack(list(test_predictions.values()))\n",
    "\n",
    "meta_predictions = {}\n",
    "for meta_name, meta_model in meta_models.items():\n",
    "    meta_predictions[meta_name] = meta_model.predict(test_meta_features)\n",
    "    print(f\"  ë©”íƒ€ {meta_name} ì˜ˆì¸¡ ì™„ë£Œ\")\n",
    "\n",
    "# ======================== 9. ê³ ê¸‰ ì•™ìƒë¸” ì „ëµ ========================\n",
    "\n",
    "print(\"\\nğŸ¨ ê³ ê¸‰ ì•™ìƒë¸” ì „ëµ...\")\n",
    "\n",
    "# 1. ê¸°ë³¸ ê°€ì¤‘ í‰ê·  (ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜)\n",
    "val_scores = {}\n",
    "for model_name in final_models.keys():\n",
    "    if model_name in oof_predictions:\n",
    "        rmse = np.sqrt(mean_squared_error(y_train, oof_predictions[model_name]))\n",
    "        val_scores[model_name] = rmse\n",
    "\n",
    "# ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜ (RMSE ì—­ìˆ˜)\n",
    "performance_weights = {}\n",
    "total_inverse_rmse = sum(1/score for score in val_scores.values())\n",
    "for model_name, rmse in val_scores.items():\n",
    "    performance_weights[model_name] = (1/rmse) / total_inverse_rmse\n",
    "\n",
    "print(\"ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜:\")\n",
    "for model_name, weight in performance_weights.items():\n",
    "    print(f\"  {model_name}: {weight:.3f}\")\n",
    "\n",
    "# ê°€ì¤‘ ì•™ìƒë¸”\n",
    "weighted_ensemble = np.zeros(len(X_test_pipeline2))\n",
    "for model_name, pred in test_predictions.items():\n",
    "    if model_name in performance_weights:\n",
    "        weighted_ensemble += performance_weights[model_name] * pred\n",
    "\n",
    "# 2. Quantile Matching (ê°€ì¥ ì„±ëŠ¥ ì¢‹ì€ ëª¨ë¸ ê¸°ì¤€)\n",
    "best_model = min(val_scores, key=val_scores.get)\n",
    "print(f\"ê¸°ì¤€ ëª¨ë¸: {best_model}\")\n",
    "\n",
    "def quantile_match(source_pred, target_pred):\n",
    "    sorted_target = np.sort(target_pred)\n",
    "    source_ranks = rankdata(source_pred, method='ordinal') - 1\n",
    "    source_ranks = np.clip(source_ranks, 0, len(sorted_target)-1).astype(int)\n",
    "    return sorted_target[source_ranks]\n",
    "\n",
    "matched_predictions = {}\n",
    "for model_name, pred in test_predictions.items():\n",
    "    matched_predictions[model_name] = quantile_match(pred, test_predictions[best_model])\n",
    "\n",
    "# ë§¤ì¹­ëœ ì˜ˆì¸¡ë“¤ì˜ ê°€ì¤‘ ì•™ìƒë¸”\n",
    "matched_ensemble = np.zeros(len(X_test_pipeline2))\n",
    "for model_name, pred in matched_predictions.items():\n",
    "    if model_name in performance_weights:\n",
    "        matched_ensemble += performance_weights[model_name] * pred\n",
    "\n",
    "# 3. ë©”íƒ€ ìŠ¤íƒœí‚¹ ì•™ìƒë¸”\n",
    "meta_ensemble = np.mean(list(meta_predictions.values()), axis=0)\n",
    "\n",
    "# 4. ìˆœìœ„ ê¸°ë°˜ ì•™ìƒë¸”\n",
    "rank_ensemble = np.zeros(len(X_test_pipeline2))\n",
    "for model_name, pred in test_predictions.items():\n",
    "    ranks = rankdata(pred) / len(pred)\n",
    "    if model_name in performance_weights:\n",
    "        rank_ensemble += performance_weights[model_name] * ranks\n",
    "\n",
    "# ìˆœìœ„ë¥¼ ì‹¤ì œ ê°’ìœ¼ë¡œ ë³€í™˜\n",
    "sorted_weighted = np.sort(weighted_ensemble)\n",
    "rank_indices = (rank_ensemble * (len(sorted_weighted) - 1)).astype(int)\n",
    "rank_indices = np.clip(rank_indices, 0, len(sorted_weighted) - 1)\n",
    "rank_converted = sorted_weighted[rank_indices]\n",
    "\n",
    "# ======================== 10. ìµœì¢… ë¸”ë Œë”© ========================\n",
    "\n",
    "print(\"\\nâš¡ ìµœì¢… ë¸”ë Œë”©...\")\n",
    "\n",
    "# ë¸”ë Œë”© ì „ëµë“¤\n",
    "ensemble_strategies = {\n",
    "    'weighted': weighted_ensemble,\n",
    "    'quantile_matched': matched_ensemble,\n",
    "    'meta_stacking': meta_ensemble,\n",
    "    'rank_based': rank_converted\n",
    "}\n",
    "\n",
    "# ê²€ì¦ ë°ì´í„°ì—ì„œ ê° ì „ëµì˜ ì„±ëŠ¥ í‰ê°€\n",
    "val_ensemble_scores = {}\n",
    "for strategy_name, strategy in ensemble_strategies.items():\n",
    "    if strategy_name == 'weighted':\n",
    "        val_pred = np.zeros(len(y_val))\n",
    "        for model_name in final_models.keys():\n",
    "            if model_name in performance_weights and model_name in oof_predictions:\n",
    "                val_indices = np.arange(len(y_clean))[val_indices] if len(val_indices) <= len(y_clean) else val_indices\n",
    "                val_pred += performance_weights[model_name] * oof_predictions[model_name][val_indices]\n",
    "    else:\n",
    "        # ê°„ë‹¨íˆ ê°€ì¤‘ ì•™ìƒë¸”ë¡œ ê·¼ì‚¬\n",
    "        val_pred = np.zeros(len(y_val))\n",
    "        for model_name in final_models.keys():\n",
    "            if model_name in performance_weights and model_name in oof_predictions:\n",
    "                val_indices_mask = np.arange(len(y_clean))[val_indices] if len(val_indices) <= len(y_clean) else val_indices\n",
    "                val_pred += performance_weights[model_name] * oof_predictions[model_name][val_indices_mask]\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "    val_ensemble_scores[strategy_name] = rmse\n",
    "\n",
    "print(\"ì•™ìƒë¸” ì „ëµ ì„±ëŠ¥:\")\n",
    "for strategy_name, rmse in val_ensemble_scores.items():\n",
    "    print(f\"  {strategy_name}: RMSE={rmse:.4f}\")\n",
    "\n",
    "# ìµœê³  ì„±ëŠ¥ ì „ëµ ì„ íƒ\n",
    "best_strategy = min(val_ensemble_scores, key=val_ensemble_scores.get)\n",
    "print(f\"ìµœê³  ì „ëµ: {best_strategy}\")\n",
    "\n",
    "# ë‹¤ì¤‘ ì „ëµ ë¸”ë Œë”© (ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜)\n",
    "strategy_weights = {}\n",
    "total_inverse_rmse_strategy = sum(1/score for score in val_ensemble_scores.values())\n",
    "for strategy_name, rmse in val_ensemble_scores.items():\n",
    "    strategy_weights[strategy_name] = (1/rmse) / total_inverse_rmse_strategy\n",
    "\n",
    "print(\"ì „ëµë³„ ê°€ì¤‘ì¹˜:\")\n",
    "for strategy_name, weight in strategy_weights.items():\n",
    "    print(f\"  {strategy_name}: {weight:.3f}\")\n",
    "\n",
    "# ìµœì¢… ë¸”ë Œë”©\n",
    "final_ensemble = np.zeros(len(X_test_pipeline2))\n",
    "for strategy_name, pred in ensemble_strategies.items():\n",
    "    final_ensemble += strategy_weights[strategy_name] * pred\n",
    "\n",
    "# ì¶”ê°€: ë³´ìˆ˜ì  ë¸”ë Œë”© (ìƒìœ„ 2ê°œ ì „ëµë§Œ)\n",
    "top_2_strategies = sorted(val_ensemble_scores.items(), key=lambda x: x[1])[:2]\n",
    "conservative_blend = np.zeros(len(X_test_pipeline2))\n",
    "conservative_weights = {}\n",
    "total_weight = sum(1/rmse for _, rmse in top_2_strategies)\n",
    "for strategy_name, rmse in top_2_strategies:\n",
    "    weight = (1/rmse) / total_weight\n",
    "    conservative_blend += weight * ensemble_strategies[strategy_name]\n",
    "    conservative_weights[strategy_name] = weight\n",
    "\n",
    "print(\"ë³´ìˆ˜ì  ë¸”ë Œë”© ê°€ì¤‘ì¹˜:\")\n",
    "for strategy_name, weight in conservative_weights.items():\n",
    "    print(f\"  {strategy_name}: {weight:.3f}\")\n",
    "\n",
    "# ======================== 11. í›„ì²˜ë¦¬ ë° ì œì¶œ íŒŒì¼ ìƒì„± ========================\n",
    "\n",
    "print(\"\\nğŸ“ í›„ì²˜ë¦¬ ë° ì œì¶œ íŒŒì¼ ìƒì„±...\")\n",
    "\n",
    "output_dir = \"/data2/project/2025summer/jjh0709/git/Jump-AI-2025/submissions/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ëª¨ë“  ì „ëµ + ìµœì¢… ë¸”ë Œë”©\n",
    "all_final_strategies = {\n",
    "    **ensemble_strategies,\n",
    "    'final_blend': final_ensemble,\n",
    "    'conservative_blend': conservative_blend,\n",
    "    'best_strategy_only': ensemble_strategies[best_strategy]\n",
    "}\n",
    "\n",
    "for strategy_name, pred in all_final_strategies.items():\n",
    "    # í›„ì²˜ë¦¬\n",
    "    pred_clipped = np.clip(pred, y_clean.min(), y_clean.max())\n",
    "    ic50_pred = 10 ** (9 - pred_clipped)\n",
    "    ic50_pred = np.clip(ic50_pred, 0.1, 100000)\n",
    "    \n",
    "    # ì´ìƒì¹˜ ì œê±°\n",
    "    q1, q3 = np.percentile(ic50_pred, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = max(q1 - 1.5 * iqr, 0.1)\n",
    "    upper_bound = min(q3 + 1.5 * iqr, 100000)\n",
    "    ic50_pred = np.clip(ic50_pred, lower_bound, upper_bound)\n",
    "    \n",
    "    # ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "    submission = pd.DataFrame({\n",
    "        \"ID\": df_test[\"ID\"],\n",
    "        \"ASK1_IC50_nM\": ic50_pred\n",
    "    })\n",
    "    \n",
    "    filename = f\"submit_perfect_{strategy_name}.csv\"\n",
    "    submission.to_csv(output_dir + filename, index=False)\n",
    "    \n",
    "    print(f\"  {filename} ì €ì¥ ì™„ë£Œ\")\n",
    "    print(f\"    IC50 ë²”ìœ„: {ic50_pred.min():.2f} ~ {ic50_pred.max():.2f} nM\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸŠ ì™„ë²½í•œ No-Leakage íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\")\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸš€ ëª¨ë“  ê°œì„ ì‚¬í•­ ì ìš©:\")\n",
    "print(\"â€¢ âœ… ë°ì´í„° ëˆ„ìˆ˜ ì™„ì „ ë°©ì§€\")\n",
    "print(\"â€¢ âœ… OOF ê¸°ë°˜ ë¸”ë Œë”©\")\n",
    "print(\"â€¢ âœ… ë©”íƒ€ ìŠ¤íƒœí‚¹ (5ê°œ ë©”íƒ€ ëª¨ë¸)\")\n",
    "print(\"â€¢ âœ… CatBoost í¬í•¨ (6ê°œ ê¸°ë³¸ ëª¨ë¸)\")\n",
    "print(\"â€¢ âœ… ë‹¤ì¤‘ ë©”íŠ¸ë¦­ ìµœì í™” (RMSE+MAE+Spearman)\")\n",
    "print(\"â€¢ âœ… ì´ì¤‘ íŒŒì´í”„ë¼ì¸ (ì›ë³¸ FP vs PCA FP)\")\n",
    "print(\"â€¢ âœ… Early Stopping ìœ ì§€\")\n",
    "print(\"â€¢ âœ… ì„±ëŠ¥ ê¸°ë°˜ ê°€ì¤‘ì¹˜\")\n",
    "print(\"â€¢ âœ… 4ê°€ì§€ ì•™ìƒë¸” ì „ëµ\")\n",
    "\n",
    "print(\"\\nğŸ“ ìƒì„±ëœ ì œì¶œ íŒŒì¼ë“¤:\")\n",
    "print(\"ğŸ† submit_perfect_final_blend.csv (ëª¨ë“  ì „ëµ ì¡°í•©) â­â­â­\")\n",
    "print(\"ğŸ¥‡ submit_perfect_conservative_blend.csv (ìƒìœ„ 2ê°œ ì „ëµ)\")\n",
    "print(\"ğŸ¥ˆ submit_perfect_best_strategy_only.csv (ìµœê³  ì„±ëŠ¥ ì „ëµ)\")\n",
    "print(\"ğŸ¥‰ submit_perfect_quantile_matched.csv (Quantile ë§¤ì¹­)\")\n",
    "print(\"ğŸ… submit_perfect_meta_stacking.csv (ë©”íƒ€ ìŠ¤íƒœí‚¹)\")\n",
    "\n",
    "print(\"\\nğŸ¯ ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ:\")\n",
    "print(\"â€¢ ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€ë¡œ ë” ì •í™•í•œ ê²€ì¦\")\n",
    "print(\"â€¢ OOF ê¸°ë°˜ ë¸”ë Œë”©ìœ¼ë¡œ ê³¼ì í•© ë°©ì§€\")\n",
    "print(\"â€¢ ë©”íƒ€ ìŠ¤íƒœí‚¹ìœ¼ë¡œ ëª¨ë¸ ê°„ ë¹„ì„ í˜• ì¡°í•©\")\n",
    "print(\"â€¢ ë‹¤ì¤‘ ë©”íŠ¸ë¦­ ìµœì í™”ë¡œ robustí•œ ì˜ˆì¸¡\")\n",
    "print(\"â€¢ ì´ì¤‘ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ëª¨ë¸ë³„ ìµœì  ì…ë ¥\")\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ† ìš°ì„  ì œì¶œ ìˆœì„œ:\")\n",
    "print(\"1. submit_perfect_final_blend.csv\")\n",
    "print(\"2. submit_perfect_conservative_blend.csv\")\n",
    "print(\"3. submit_perfect_quantile_matched.csv\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
